
Anarchism.
Anarchism is a political philosophy which considers the state undesirable, unnecessary and harmful, and instead promotes a stateless society, or anarchy. It seeks to diminish or even abolish authority in the conduct of human relations. Anarchists may widely disagree on what additional criteria are required in anarchism. "The Oxford Companion to Philosophy" says, "there is no single defining position that all anarchists hold, and those considered anarchists at best share a certain family resemblance."
There are many types and traditions of anarchism, not all of which are mutually exclusive. Strains of anarchism have been divided into the categories of social and individualist anarchism or similar dual classifications. Anarchism is often considered to be a radical left-wing ideology, and much of anarchist economics and anarchist legal philosophy reflect anti-statist interpretations of communism, collectivism, syndicalism or participatory economics. However, anarchism has always included an individualist strain supporting a market economy and private property, or unrestrained egoism that bases right on might.
Others, such as panarchists and anarchists without adjectives, neither advocate nor object to any particular form of organization as long as it is not compulsory. Differing fundamentally, some anarchist schools of thought support anything from extreme individualism to complete collectivism. The central tendency of anarchism as a social movement have been represented by communist anarchism, with individualist anarchism being primarily a philosophical or literary phenomenon. Some anarchists fundamentally oppose all forms of aggression, supporting self-defense or non-violence, while others have supported the use of some coercive measures, including violent revolution and terrorism, on the path to an anarchist society.
Etymology and terminology.
The term "anarchism" derives from the Greek ἄναρχος, "anarchos", meaning "without rulers", from the prefix ἀν- ("an-", "without") + ἀρχή ("archê", "sovereignty, realm, magistracy") + -ισμός ("-ismos", from the suffix -ιζειν, "-izein" "-izing"). There is some ambiguity with the use of the terms "libertarianism" and "libertarian" in writings about anarchism. Since the 1890s from France, the term "libertarianism" has often been used as a synonym for anarchism and was used almost exclusively in this sense until the 1950s in the United States; its use as a synonym is still common outside the United States. Accordingly, "libertarian socialism" is sometimes used as a synonym for socialist anarchism, to distinguish it from "individualist libertarianism" (individualist anarchism). On the other hand, some use "libertarianism" to refer to individualistic free-market philosophy only, referring to free-market anarchism as "libertarian anarchism."
Origins.
Some claim anarchist themes can be found in the works of Taoist sages Laozi and Zhuangzi. The latter has been translated, "There has been such a thing as letting mankind alone; there has never been such a thing as governing mankind [with success]," and "A petty thief is put in jail. A great brigand becomes a ruler of a Nation." Diogenes of Sinope and the Cynics, and their contemporary Zeno of Citium, the founder of Stoicism, also introduced similar topics.
Modern anarchism, however, sprang from the secular or religious thought of the Enlightenment, particularly Jean-Jacques Rousseau's arguments for the moral centrality of freedom. Although by the turn of the 19th century the term "anarchist" had lost its initial negative connotation, it first entered the English language in 1642 during the English Civil War as a term of abuse used by Royalists to damn those who were fomenting disorder. By the time of the French Revolution some, such as the "Enragés", began to use the term positively, in opposition to Jacobin centralisation of power, seeing "revolutionary government" as oxymoronic.
From this climate William Godwin developed what many consider the first expression of modern anarchist thought. Godwin was, according to Peter Kropotkin, "the first to formulate the political and economical conceptions of anarchism, even though he did not give that name to the ideas developed in his work", while Godwin attached his anarchist ideas to an early Edmund Burke. Benjamin Tucker instead credits Josiah Warren, an American who promoted stateless and voluntary communities where all goods and services were private, with being "the first man to expound and formulate the doctrine now known as Anarchism." The first to describe himself as an anarchist was Pierre-Joseph Proudhon, a French philosopher and politician, which led some to call him the founder of modern anarchist theory.
Social movement.
Anarchism as a social movement has regularly endured fluctuations in popularity. Its classical period, which scholars demarcate as from 1860 to 1939, is associated with the working-class movements of the nineteenth century and the Spanish Civil War-era struggles against fascism. Anarchists were heavilly involved in the abolition of slavery, and continue to be active in the labour movement, civil rights, women's liberation, both anti-capitalism and pro-capitalism (with varying definitions of capitalism), the anti-war movement, LGBT rights, both anti-globalization and pro-globalization (with varying definitions of globalization), tax resistance, and other areas.
The First International.
In Europe, harsh reaction followed the revolutions of 1848, during which ten countries had experienced brief or long-term social upheaval as groups carried out nationalist uprisings. After most of these attempts at systematic change ended in failure, conservative elements took advantage of the divided groups of socialists, anarchists, liberals, and nationalists, to prevent further revolt. In 1864 the International Workingmen's Association (sometimes called the "First International") united diverse revolutionary currents including French followers of Proudhon, Blanquists, Philadelphes, English trade unionists, socialists and social democrats.
Due to its links to active workers' movements, the International became a significant organization. Karl Marx became a leading figure in the International and a member of its General Council. Proudhon's followers, the mutualists, opposed Marx's state socialism, advocating political abstentionism and small property holdings.
In 1868, following their unsuccessful participation in the League of Peace and Freedom (LPF), Russian revolutionary Mikhail Bakunin and his collectivist anarchist associates and joined the First International (which had decided not to get involved with the LPF). They allied themselves with the federalist socialist sections of the International, who advocated the revolutionary overthrow of the state and the collectivization of property.
At first, the collectivists worked with the Marxists to push the First International in a more revolutionary socialist direction. Subsequently, the International became polarised into two camps, with Marx and Bakunin as their respective figureheads. Bakunin characterised Marx's ideas as centralist and predicted that, if a Marxist party came to power, its leaders would simply take the place of the ruling class they had fought against.
In 1872, the conflict climaxed with a final split between the two groups at the Hague Congress, where Bakunin and James Guillaume were expelled from the International and its headquarters were transferred to New York. In response, the federalist sections formed their own International at the St. Imier Congress, adopting a revolutionary anarchist program.
Organised labour.
The anti-authoritarian sections of the First International were the precursors of the anarcho-syndicalists, seeking to "replace the privilege and authority of the State" with the "free and spontaneous organization of labor." In 1886, the Federation of Organized Trades and Labor Unions (FOTLU) of the United States and Canada unanimously set 1 May 1886, as the date by which the eight-hour work day would become standard.
In response, unions across America prepared a general strike in support of the event. On 3 May, in Chicago, a fight broke out when strikebreakers attempted to cross the picket line, and two workers died when police opened fire upon the crowd. The next day, 4 May, anarchists staged a rally at Chicago's Haymarket Square. A bomb was thrown by an unknown party near the conclusion of the rally, killing an officer. In the ensuing panic, police opened fire on the crowd and each other. Seven police officers and at least four workers were killed. Eight anarchists directly and indirectly related to the organisers of the rally were arrested and charged with the murder of the deceased officer. The men became international political celebrities among the labour movement. Four of the men were executed and a fifth committed suicide prior to his own execution. The incident became known as the Haymarket affair, and was a setback for the labour movement and the struggle for the eight hour day. In 1890 a second attempt, this time international in scope, to organise for the eight hour day was made. The event also had the secondary purpose of memorializing workers killed as a result of the Haymarket affair. Although it had initially been conceived as a once-off event, by the following year the celebration of International Workers' Day on May Day had become firmly established as an international worker's holiday.
In 1907, the International Anarchist Congress of Amsterdam gathered delegates from 14 different countries, among which important figures of the anarchist movement, including Errico Malatesta, Pierre Monatte, Luigi Fabbri, Benoît Broutchoux, Emma Goldman, Rudolf Rocker, and Christiaan Cornelissen. Various themes were treated during the Congress, in particular concerning the organisation of the anarchist movement, popular education issues, the general strike or antimilitarism. A central debate concerned the relation between anarchism and syndicalism (or trade unionism). Malatesta and Monatte were in particular disagreement themselves on this issue, as the latter thought that syndicalism was revolutionary and would create the conditions of a social revolution, while Malatesta did not consider syndicalism by itself sufficient. He thought that the trade-union movement was reformist and even conservative, citing as essentially bourgeois and anti-worker the phenomenon of professional union officials. Malatesta warned that the syndicalists aims were in perpetuating syndicalism itself, whereas anarchists must always have anarchy as their end and consequently refrain from committing to any particular method of achieving it.
The Spanish Workers Federation in 1881 was the first major anarcho-syndicalist movement; anarchist trade union federations were of special importance in Spain. The most successful was the Confederación Nacional del Trabajo (National Confederation of Labour: CNT), founded in 1910. Before the 1940s, the CNT was the major force in Spanish working class politics, attracting 1.58 million members at one point and playing a major role in the Spanish Civil War. The CNT was affiliated with the International Workers Association, a federation of anarcho-syndicalist trade unions founded in 1922, with delegates representing two million workers from 15 countries in Europe and Latin America. The largest organised anarchist movement today is in Spain, in the form of the Confederación General del Trabajo (CGT) and the CNT. CGT membership was estimated to be around 100,000 for the year 2003. Other active syndicalist movements include the US Workers Solidarity Alliance and the UK Solidarity Federation. The revolutionary industrial unionist Industrial Workers of the World, claiming 2,000 paying members, and the International Workers Association, an anarcho-syndicalist successor to the First International, also remain active.
Russian Revolution.
Anarchists participated alongside the Bolsheviks in both February and October revolutions, and were initially enthusiastic about the Bolshevik coup. However, the Bolsheviks soon turned against the anarchists and other left-wing opposition, a conflict that culminated in the 1921 Kronstadt rebellion which the new government repressed. Anarchists in central Russia were either imprisoned, driven underground or joined the victorious Bolsheviks; the anarchists from Petrograd and Moscow fled to the Ukraine. There, in the Free Territory, they fought in the civil war against the Whites (a Western-backed grouping of monarchists and other opponents of the October Revolution) and then the Bolsheviks as part of the Revolutionary Insurrectionary Army of Ukraine led by Nestor Makhno, who established an anarchist society in the region for a number of months.
Expelled American anarchists Emma Goldman and Alexander Berkman were amongst those agitating in response to Bolshevik policy and the suppression of the Kronstadt uprising, before they left Russia. Both wrote accounts of their experiences in Russia, criticizing the amount of control the Bolsheviks exercised. For them, Bakunin's predictions about the consequences of Marxist rule that the rulers of the new "socialist” Marxist state would become a new elite had proved all too true.
The victory of the Bolsheviks in the October Revolution and the resulting Russian Civil War did serious damage to anarchist movements internationally. Many workers and activists saw Bolshevik success as setting an example; Communist parties grew at the expense of anarchism and other socialist movements. In France and the United States, for example, members of the major syndicalist movements of the CGT and IWW left the organizations and joined the Communist International.
In Paris, the Dielo Truda group of Russian anarchist exiles, which included Nestor Makhno, concluded that anarchists needed to develop new forms of organisation in response to the structures of Bolshevism. Their 1926 manifesto, called the "Organizational Platform of the General Union of Anarchists (Draft)", was supported. Platformist groups active today include the Workers Solidarity Movement in Ireland and the North Eastern Federation of Anarchist Communists of North America.
Fight against fascism.
In the 1920s and 1930s, the rise of fascism in Europe transformed anarchism's conflict with the state. Italy saw the first struggles between anarchists and fascists. Italian anarchists played a key role in the anti-fascist organisation "Arditi del Popolo", which was strongest in areas with anarchist traditions, and achieved some success in their activism, such as repelling Blackshirts in the anarchist stronghold of Parma in August 1922. In France, where the far right leagues came close to insurrection in the February 1934 riots, anarchists divided over a united front policy.
In Spain, the CNT initially refused to join a popular front electoral alliance, and abstention by CNT supporters led to a right wing election victory. But in 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power. Months later, the former ruling class responded with an attempted coup causing the Spanish Civil War (1936–1939). In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivised the land. But even before the fascist victory in 1939, the anarchists were losing ground in a bitter struggle with the Stalinists, who controlled the distribution of military aid to the Republican cause from the Soviet Union. Stalinist-led troops suppressed the collectives and persecuted both dissident Marxists and anarchists.
Contemporary anarchism.
A surge of popular interest in anarchism occurred during the 1960s and 1970s. In the United Kingdom this was associated with the punk rock movement, as exemplified by bands such as Crass and the Sex Pistols. The housing and employment crisis in most of Western Europe led to the formation of communes and squatter movements like that of Barcelona, Spain. In Denmark, squatters occupied a disused military base and declared the Freetown Christiania, an autonomous haven in central Copenhagen.
Since the revival of anarchism in the mid 20th century, a number of new movements and schools of thought emerged. Although feminist tendencies have always been a part of the anarchist movement in the form of anarcha-feminism, they returned with vigour during the second wave of feminism in the 1960s. The American Civil Rights Movement and the movement against the war in Vietnam also contributed to the revival of North American anarchism. European anarchism of the late 20th century drew much of its strength from the labour movement, and both have incorporated animal rights activism. Anarchist anthropologist David Graeber has posited a rupture between generations of anarchism, with those "who often still have not shaken the sectarian habits" of the nineteenth century contrasted with the younger activists who are "much more informed, among other elements, by indigenous, feminist, ecological and cultural-critical ideas", and who by the turn of the 21st century formed "by far the majority" of anarchists.
Around the turn of the 21st century, anarchism grew in popularity and influence as part of the anti-war, anti-capitalist, and anti-globalisation movements. Anarchists became known for their involvement in protests against the meetings of the World Trade Organization (WTO), Group of Eight, and the World Economic Forum. Some anarchist factions at these protests engaged in rioting, property destruction, and violent confrontations with police, and the confrontations were selectively portrayed in mainstream media coverage as violent riots. These actions were precipitated by ad hoc, leaderless, anonymous cadres known as "black blocs"; other organisational tactics pioneered in this time include security culture, affinity groups and the use of decentralised technologies such as the internet. A landmark struggle of this period was the confrontations at WTO conference in Seattle in 1999.
Anarchist schools of thought.
Anarchist ideas have only occasionally inspired political movements of any size, and "the tradition is mainly one of individual thinkers, but they have produced an important body of theory." Anarchist schools of thought had been generally grouped in two main historical traditions, individualist anarchism and social anarchism, which have some different origins, values and evolution. The individualist wing of anarchism emphasises negative liberty, i.e. opposition to state or social control over the individual, while those in the social wing emphasise positive liberty to achieve one's potential and argue that humans have needs that society ought to fulfill, "recognizing equality of entitlement". In chronological and theoretical sense there are classical — those created throughout the 19th century — and post-classical anarchist schools — those created since the mid-20th century and after.
Beyond the specific factions of anarchist thought is philosophical anarchism, which embodies the theoretical stance that the State lacks moral legitimacy without accepting the imperative of revolution to eliminate it. A component especially of individualist anarchism philosophical anarchism may accept the existence of a minimal state as unfortunate, and usually temporary, "necessary evil" but argue that citizens do not have a moral obligation to obey the state when its laws conflict with individual autonomy. One reaction against sectarianism within the anarchist milieu was "anarchism without adjectives", a call for toleration first adopted by Fernando Tarrida del Mármol in 1889 in response to the "bitter debates" of anarchist theory at the time. In abandoning the hyphenated anarchisms (i.e. collectivist-, communist-, mutualist- and individualist-anarchism), it sought to emphasise the anti-authoritarian beliefs common to all anarchist schools of thought.
Mutualism.
Mutualism began in 18th century English and French labour movements before taking an anarchist form associated with Pierre-Joseph Proudhon in France and others in the United States. Proudhon proposed spontaneous order, whereby organization emerges without central authority, a "positive anarchy" where order arises when everybody does “what he wishes and only what he wishes" and where "business transactions alone produce the social order." Mutualist anarchism is concerned with reciprocity, free association, voluntary contract, federation, and credit and currency reform. According to William Batchelder Greene, each worker in the mutualist system would receive "just and exact pay for his work; services equivalent in cost being exchangeable for services equivalent in cost, without profit or discount." Mutualism has been retrospectively characterised as ideologically situated between individualist and collectivist forms of anarchism. Proudhon first characterised his goal as a "third form of society, the synthesis of communism and property."
Individualist anarchism.
Individualist anarchism refers to several traditions of thought within the anarchist movement that emphasise the individual and their will over any kinds of external determinants such as groups, society, traditions, and ideological systems. Individualist anarchism is not a single philosophy but refers to a group of individualistic philosophies that sometimes are in conflict.
In 1793, William Godwin, who has often been cited as the first anarchist, wrote "Political Justice", which some consider to be the first expression of anarchism. Godwin, a philosophical anarchist, from a rationalist and utilitarian basis opposed revolutionary action and saw a minimal state as a present "necessary evil" that would become increasingly irrelevant and powerless by the gradual spread of knowledge. Godwin advocated extreme individualism, proposing that all cooperation in labour be eliminated on the premise that this would be most conducive with the general good. Godwin was a utilitarian who believed that all individuals are not of equal value, with some of us "of more worth and importance" than others depending on our utility in bringing about social good. Therefore he does not believe in equal rights, but the person's life that should be favoured that is most conducive to the general good. Godwin opposed government because he saw it as infringing on the individual's right to "private judgement" to determine which actions most maximise utility, but also makes a critique of all authority over the individual's judgement. This aspect of Godwin's philosophy, stripped of utilitarian motivations, was developed into a more extreme form later by Stirner.
The most extreme form of individualist anarchism, called "egoism," or egoist anarchism, was expounded by one of the earliest and best-known proponents of individualist anarchism, Max Stirner. Stirner's "The Ego and Its Own", published in 1844, is a founding text of the philosophy. According to Stirner, the only limitation on the rights of the individual is their power to obtain what they desire, without regard for God, state, or morality. To Stirner, rights were "spooks" in the mind, and he held that society does not exist but "the individuals are its reality". Stirner advocated self-assertion and foresaw Unions of Egoists, non-systematic associations continually renewed by all parties' support through an act of will, which Stirner proposed as a form of organization in place of the state. Egoist anarchists claim that egoism will foster genuine and spontaneous union between individuals. "Egoism" has inspired many interpretations of Stirner's philosophy. It was re-discovered and promoted by German philosophical anarchist and LGBT activist John Henry Mackay. Individualist anarchism inspired by Stirner attracted a small following of European bohemian artists and intellectuals (see European individualist anarchism). Stirner's philosophy has been seen as a precedent of existentialism with other thinkers like Friedrich Nietzsche and Sören Kierkegaard.
Social anarchism.
Social anarchism calls for a system with public ownership of means of production and democratic control of all organizations, without any government authority or coercion. It is the largest school of anarchism. Social anarchism rejects private property, seeing it as a source of social inequality, and emphasises cooperation and mutual aid.
Collectivist anarchism, also referred to as "revolutionary socialism" or a form of such, is a revolutionary form of anarchism, commonly associated with Mikhail Bakunin and Johann Most. Collectivist anarchists oppose all private ownership of the means of production, instead advocating that ownership be collectivised. This was to be achieved through violent revolution, first starting with a small cohesive group through acts of violence, or "propaganda by the deed," which would inspire the workers as a whole to revolt and forcibly collectivise the means of production. However, collectivization was not to be extended to the distribution of income, as workers would be paid according to time worked, rather than receiving goods being distributed "according to need" as in anarcho-communism. This position was criticised by anarchist communists as effectively "uphold[ing] the wages system". Collectivist anarchism arose contemporaneously with Marxism but opposed the Marxist dictatorship of the proletariat, despite the stated Marxist goal of a collectivist stateless society. Anarchist communist and collectivist ideas are not mutually exclusive; although the collectivist anarchists advocated compensation for labour, some held out the possibility of a post-revolutionary transition to a communist system of distribution according to need.
Anarchist communism proposes that the freest form of social organisation would be a society composed of self-managing communes with collective use of the means of production, organised democratically, and related to other communes through federation. While some anarchist communists favour direct democracy, others feel that its majoritarianism can impede individual liberty and favour consensus democracy instead. In anarchist communism, as money would be abolished, individuals would not receive direct compensation for labour (through sharing of profits or payment) but would have free access to the resources and surplus of the commune. Anarchist communism does not always have a communitarian philosophy. Some forms of anarchist communism are egoist and strongly influenced by radical individualism, believing that anarchist communism does not require a communitarian nature at all.
In the early 20th century, anarcho-syndicalism arose as a distinct school of thought within anarchism. With greater focus on the labour movement than previous forms of anarchism, syndicalism posits radical trade unions as a potential force for revolutionary social change, replacing capitalism and the state with a new society, democratically self-managed by the workers. It is often combined with other branches of anarchism, and anarcho-syndicalists often subscribe to anarchist communist or collectivist anarchist economic systems. An early leading anarcho-syndicalist thinker was Rudolf Rocker, whose 1938 pamphlet "Anarchosyndicalism" outlined a view of the movement's origin, aims and importance to the future of labour.
Post-classical currents.
Anarchism continues to generate many philosophies and movements, at times eclectic, drawing upon various sources, and syncretic, combining disparate and contrary concepts to create new philosophical approaches. Since the revival of anarchism in the United States in the 1960s, a number of new movements and schools have emerged. Anarcho-capitalism developed from radical anti-state libertarianism and individualist anarchism, drawing from Austrian School economics, study of law and economics and public choice theory, while the burgeoning feminist and environmentalist movements also produced anarchist offshoots. Anarcha-feminism developed as a synthesis of radical feminism and anarchism that views patriarchy (male domination over women) as a fundamental manifestation of compulsory government. It was inspired by the late 19th century writings of early feminist anarchists such as Lucy Parsons, Emma Goldman, Voltairine de Cleyre, and Dora Marsden. Anarcha-feminists, like other radical feminists, criticise and advocate the abolition of traditional conceptions of family, education and gender roles. Green anarchism (or eco-anarchism) is a school of thought within anarchism which puts an emphasis on environmental issues, and whose main contemporary currents are anarcho-primitivism and social ecology. Post-left anarchy is a tendency which seeks to distance itself from traditional left-wing politics and to escape the confines of ideology in general. Post-anarchism is a theoretical move towards a synthesis of classical anarchist theory and poststructuralist thought drawing from diverse ideas including post-modernism, autonomist marxism, post-left anarchy, situationism and postcolonialism. Another recent form of anarchism critical of formal anarchist movements is insurrectionary anarchism, which advocates informal organization and active resistance to the state; its proponents include Wolfi Landstreicher and Alfredo M. Bonanno.
Topics of interest in anarchist theory.
Intersecting and overlapping between various schools of thought, certain topics of interest and internal disputes have proven perennial within anarchist theory.
Free love.
An important current within anarchism is Free love. Free love advocates sometimes traced their roots back to Josiah Warren and to experimental communities, viewed sexual freedom as a clear, direct expression of an individual's self-ownership. Free love particularly stressed women's rights since most sexual laws discriminated against women: for example, marriage laws and anti-birth control measures. The most important American free love journal was "Lucifer the Lightbearer" (1883–1907) edited by Moses Harman and Lois Waisbrooker, but also there existed Ezra Heywood and Angela Heywood's 'The Word' (1872–1890, 1892–1893). Also M. E. Lazarus was an important American individualist anarchist who promoted free love.
In New York's Greenwich Village, bohemian feminists and socialists advocated self-realisation and pleasure for women (and also men) in the here and now. They encouraged playing with sexual roles and sexuality, and the openly bisexual radical Edna St. Vincent Millay and the lesbian anarchist Margaret Anderson were prominent among them. Discussion groups organised by the Villagers were frequented by Emma Goldman, among others. Magnus Hirschfeld noted in 1923 that Goldman "has campaigned boldly and steadfastly for individual rights, and especially for those deprived of their rights. Thus it came about that she was the first and only woman, indeed the first and only American, to take up the defense of homosexual love before the general public." In fact, before Goldman, heterosexual anarchist Robert Reitzel (1849–98) spoke positively of homosexuality from the beginning of the 1890s in his Detroit-based German language journal "Der arme Teufel".
In Europe the main propagandist of free love within individualist anarchism was Emile Armand. He proposed the concept of "la camaraderie amoureuse" to speak of free love as the possibility of voluntary sexual encounter between consenting adults. He was also a consistent proponent of polyamory. In Germany the stirnerists Adolf Brand and John Henry Mackay were pioneering campaigners for the acceptance of male bisexuality and homosexuality.
More recently, the British anarcho-pacifist Alex Comfort gained notoriety during the sexual revolution for writing the bestseller sex manual "The Joy of Sex". The issue of free love has a dedicated treatment in the work of french anarcho-hedonist philosopher Michel Onfray in such works as "Théorie du corps amoureux: pour une érotique solaire" (2000) and "L'invention du plaisir: fragments cyréaniques" (2002).
Libertarian education.
In 1901, Spanish anarchist and free-thinker Francesc Ferrer i Guàrdia established "modern" or progressive schools in Barcelona in defiance of an educational system controlled by the Catholic Church. The schools' stated goal was to "educate the working class in a rational, secular and non-coercive setting". Fiercely anti-clerical, Ferrer believed in "freedom in education", education free from the authority of church and state. Murray Bookchin wrote: "This period [1890s] was the heyday of libertarian schools and pedagogical projects in all areas of the country where Anarchists exercised some degree of influence. Perhaps the best-known effort in this field was Francisco Ferrer's Modern School (Escuela Moderna), a project which exercised a considerable influence on Catalan education and on experimental techniques of teaching generally." La Escuela Moderna, and Ferrer's ideas generally, formed the inspiration for a series of "Modern Schools" in the United States, Cuba, South America and London. The first of these was started in New York City in 1911. It also inspired the Italian newspaper "Università popolare", founded in 1901.
Another libertarian tradition is that of unschooling and the free school in which child-led activity replaces pedagogic approaches. Experiments in Germany led to A. S. Neill founding what became Summerhill School in 1921. Summerhill is often cited as an example of anarchism in practice. However, although Summerhill and other free schools are radically libertarian, they differ in principle from those of Ferrer by not advocating an overtly-political class struggle-approach.
In addition to organizing schools according to libertarian principles, anarchists have also questioned the concept of schooling per se. The term deschooling was popularized by Ivan Illich, who argued that the school as an institution is dysfunctional for self-determined learning and serves the creation of a consumer society instead.
Internal issues and debates.
Anarchism is a philosophy which embodies many diverse attitudes, tendencies and schools of thought; as such, disagreement over questions of values, ideology and tactics is common. The compatibility of capitalism, nationalism and religion with anarchism is widely disputed. Similarly, anarchism enjoys complex relationships with ideologies such as Marxism, communism and capitalism. Anarchists may be motivated by humanism, divine authority, enlightened self-interest or any number of alternative ethical doctrines.
Phenomena such as civilization, technology (e.g. within anarcho-primitivism and insurrectionary anarchism), and the democratic process may be sharply criticised within some anarchist tendencies and simultaneously lauded in others. Anarchist attitudes towards race, gender and the environment have changed significantly since the modern origin of the philosophy in the 18th century.
On a tactical level, while propaganda of the deed was a tactic used by anarchists in the 19th century (e.g. the Nihilist movement), contemporary anarchists espouse alternative direct action methods such as nonviolence, counter-economics and anti-state cryptography to bring about an anarchist society. About the scope of an anarchist society, some anarchists advocate a global one, while others do so by local ones. The diversity in anarchism has led to widely different use of identical terms among different anarchist traditions, which has led to many definitional concerns in anarchist theory.
---END.OF.DOCUMENT---
Autism.
Autism is a disorder of neural development characterized by impaired social interaction and communication, and by restricted and repetitive behavior. These signs all begin before a child is three years old. Autism affects information processing in the brain by altering how nerve cells and their synapses connect and organize; how this occurs is not well understood. The two other autism spectrum disorders (ASD) are Asperger syndrome, which lacks delays in cognitive development and language, and PDD-NOS, diagnosed when full criteria for the other two disorders are not met.
Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations, or by rare combinations of common genetic variants. In rare cases, autism is strongly associated with agents that cause birth defects. Controversies surround other proposed environmental causes, such as heavy metals, pesticides or childhood vaccines; the vaccine hypotheses are biologically implausible and lack convincing scientific evidence. The prevalence of autism is about 1–2 per 1,000 people; the prevalence of ASD is about 6 per 1,000, with about four times as many males as females. The number of people diagnosed with autism has increased dramatically since the 1980s, partly due to changes in diagnostic practice; the question of whether actual prevalence has increased is unresolved.
Parents usually notice signs in the first two years of their child's life. The signs usually develop gradually, but some autistic children first develop more normally and then regress. Although early behavioral or cognitive intervention can help autistic children gain self-care, social, and communication skills, there is no known cure. Not many children with autism live independently after reaching adulthood, though some become successful. An autistic culture has developed, with some individuals seeking a cure and others believing autism should be tolerated as a difference and not treated as a disorder.
Characteristics.
Autism is a highly variable neurodevelopmental disorder that first appears during infancy or childhood, and generally follows a steady course without remission. Overt symptoms gradually begin after the age of six months, become established by age two or three years, and tend to continue through adulthood, although often in more muted form. It is distinguished not by a single symptom, but by a characteristic triad of symptoms: impairments in social interaction; impairments in communication; and restricted interests and repetitive behavior. Other aspects, such as atypical eating, are also common but are not essential for diagnosis. Autism's individual symptoms occur in the general population and appear not to associate highly, without a sharp line separating pathologically severe from common traits.
Social development.
Social deficits distinguish autism and the related autism spectrum disorders (ASD; see "Classification") from other developmental disorders. People with autism have social impairments and often lack the intuition about others that many people take for granted. Noted autistic Temple Grandin described her inability to understand the social communication of neurotypicals, or people with normal neural development, as leaving her feeling "like an anthropologist on Mars".
Unusual social development becomes apparent early in childhood. Autistic infants show less attention to social stimuli, smile and look at others less often, and respond less to their own name. Autistic toddlers differ more strikingly from social norms; for example, they have less eye contact and turn taking, and are more likely to communicate by manipulating another person's hand. Three- to five-year-old autistic children are less likely to exhibit social understanding, approach others spontaneously, imitate and respond to emotions, communicate nonverbally, and take turns with others. However, they do form attachments to their primary caregivers. Most autistic children display moderately less attachment security than non-autistic children, although this difference disappears in children with higher mental development or less severe ASD. Older children and adults with ASD perform worse on tests of face and emotion recognition.
Contrary to a common belief, autistic children do not prefer being alone. Making and maintaining friendships often proves to be difficult for those with autism. For them, the quality of friendships, not the number of friends, predicts how lonely they feel. Functional friendships, such as those resulting in invitations to parties, may affect the quality of life more deeply.
There are many anecdotal reports, but few systematic studies, of aggression and violence in individuals with ASD. The limited data suggest that, in children with mental retardation, autism is associated with aggression, destruction of property, and tantrums. A 2007 study interviewed parents of 67 children with ASD and reported that about two-thirds of the children had periods of severe tantrums and about one-third had a history of aggression, with tantrums significantly more common than in non-autistic children with language impairments. A 2008 Swedish study found that, of individuals aged 15 or older discharged from hospital with a diagnosis of ASD, those who committed violent crimes were significantly more likely to have other psychopathological conditions such as psychosis.
Communication.
About a third to a half of individuals with autism do not develop enough natural speech to meet their daily communication needs. Differences in communication may be present from the first year of life, and may include delayed onset of babbling, unusual gestures, diminished responsiveness, and vocal patterns that are not synchronized with the caregiver. In the second and third years, autistic children have less frequent and less diverse babbling, consonants, words, and word combinations; their gestures are less often integrated with words. Autistic children are less likely to make requests or share experiences, and are more likely to simply repeat others' words (echolalia) or reverse pronouns. Joint attention seems to be necessary for functional speech, and deficits in joint attention seem to distinguish infants with ASD: for example, they may look at a pointing hand instead of the pointed-at object, and they consistently fail to point at objects in order to comment on or share an experience. Autistic children may have difficulty with imaginative play and with developing symbols into language.
In a pair of studies, high-functioning autistic children aged 8–15 performed equally well as, and adults better than, individually matched controls at basic language tasks involving vocabulary and spelling. Both autistic groups performed worse than controls at complex language tasks such as figurative language, comprehension and inference. As people are often sized up initially from their basic language skills, these studies suggest that people speaking to autistic individuals are more likely to overestimate what their audience comprehends.
Repetitive behavior.
Autistic individuals display many forms of repetitive or restricted behavior, which the Repetitive Behavior Scale-Revised (RBS-R) categorizes as follows.
No single repetitive behavior seems to be specific to autism, but only autism appears to have an elevated pattern of occurrence and severity of these behaviors.
Other symptoms.
Autistic individuals may have symptoms that are independent of the diagnosis, but that can affect the individual or the family.
An estimated 0.5% to 10% of individuals with ASD show unusual abilities, ranging from splinter skills such as the memorization of trivia to the extraordinarily rare talents of prodigious autistic savants. Many individuals with ASD show superior skills in perception and attention, relative to the general population.
Sensory abnormalities are found in over 90% of those with autism, and are considered core features by some, although there is no good evidence that sensory symptoms differentiate autism from other developmental disorders. Differences are greater for under-responsivity (for example, walking into things) than for over-responsivity (for example, distress from loud noises) or for sensation seeking (for example, rhythmic movements).
An estimated 60%–80% of autistic people have motor signs that include poor muscle tone, poor motor planning, and toe walking;; deficits in motor coordination are pervasive across ASD and are greater in autism proper.
Unusual eating behavior occurs in about three-quarters of children with ASD, to the extent that it was formerly a diagnostic indicator. Selectivity is the most common problem, although eating rituals and food refusal also occur; this does not appear to result in malnutrition. Although some children with autism also have gastrointestinal (GI) symptoms, there is a lack of published rigorous data to support the theory that autistic children have more or different GI symptoms than usual; studies report conflicting results, and the relationship between GI problems and ASD is unclear.
Parents of children with ASD have higher levels of stress. Siblings of children with ASD report greater admiration of and less conflict with the affected sibling than siblings of unaffected children or those with Down syndrome; siblings of individuals with ASD have greater risk of negative well-being and poorer sibling relationships as adults.
Classification.
Autism is one of the five pervasive developmental disorders (PDD), which are characterized by widespread abnormalities of social interactions and communication, and severely restricted interests and highly repetitive behavior. These symptoms do not imply sickness, fragility, or emotional disturbance.
Of the five PDD forms, Asperger syndrome is closest to autism in signs and likely causes; Rett syndrome and childhood disintegrative disorder share several signs with autism, but may have unrelated causes; PDD not otherwise specified (PDD-NOS; also called "atypical autism") is diagnosed when the criteria are not met for a more specific disorder. Unlike with autism, people with Asperger syndrome have no substantial delay in language development. The terminology of autism can be bewildering, with autism, Asperger syndrome and PDD-NOS often called the "autism spectrum disorders" (ASD) or sometimes the "autistic disorders", whereas autism itself is often called "autistic disorder", "childhood autism", or "infantile autism". In this article, "autism" refers to the classic autistic disorder; in clinical practice, though, "autism", "ASD", and "PDD" are often used interchangeably. ASD, in turn, is a subset of the broader autism phenotype, which describes individuals who may not have ASD but do have autistic-like traits, such as avoiding eye contact.
The manifestations of autism cover a wide spectrum, ranging from individuals with severe impairments—who may be silent, mentally disabled, and locked into hand flapping and rocking—to high functioning individuals who may have active but distinctly odd social approaches, narrowly focused interests, and verbose, pedantic communication. Because the behavior spectrum is continuous, boundaries between diagnostic categories are necessarily somewhat arbitrary. Sometimes the syndrome is divided into low-, medium- or high-functioning autism (LFA, MFA, and HFA), based on IQ thresholds, or on how much support the individual requires in daily life; these subdivisions are not standardized and are controversial. Autism can also be divided into syndromal and non-syndromal autism; the syndromal autism is associated with severe or profound mental retardation or a congenital syndrome with physical symptoms, such as tuberous sclerosis. Although individuals with Asperger syndrome tend to perform better cognitively than those with autism, the extent of the overlap between Asperger syndrome, HFA, and non-syndromal autism is unclear.
Some studies have reported diagnoses of autism in children due to a loss of language or social skills, as opposed to a failure to make progress, typically from 15 to 30 months of age. The validity of this distinction remains controversial; it is possible that regressive autism is a specific subtype, or that there is a continuum of behaviors between autism with and without regression.
Research into causes has been hampered by the inability to identify biologically meaningful subpopulations and by the traditional boundaries between the disciplines of psychiatry, psychology, neurology and pediatrics. Newer technologies such as fMRI and diffusion tensor imaging can help identify biologically relevant phenotypes (observable traits) that can be viewed on brain scans, to help further neurogenetic studies of autism; one example is lowered activity in the fusiform face area of the brain, which is associated with impaired perception of people versus objects. It has been proposed to classify autism using genetics as well as behavior.
Causes.
It has long been presumed that there is a common cause at the genetic, cognitive, and neural levels for autism's characteristic triad of symptoms. However, there is increasing suspicion that autism is instead a complex disorder whose core aspects have distinct causes that often co-occur.
Autism has a strong genetic basis, although the genetics of autism are complex and it is unclear whether ASD is explained more by rare mutations with major effects, or by rare multigene interactions of common genetic variants. Complexity arises due to interactions among multiple genes, the environment, and epigenetic factors which do not change DNA but are heritable and influence gene expression. Studies of twins suggest that heritability is 0.7 for autism and as high as 0.9 for ASD, and siblings of those with autism are about 25 times more likely to be autistic than the general population. However, most of the mutations that increase autism risk have not been identified. Typically, autism cannot be traced to a Mendelian (single-gene) mutation or to a single chromosome abnormality like fragile X syndrome, and none of the genetic syndromes associated with ASDs has been shown to selectively cause ASD. Numerous candidate genes have been located, with only small effects attributable to any particular gene. The large number of autistic individuals with unaffected family members may result from copy number variations—spontaneous deletions or duplications in genetic material during meiosis. Hence, a substantial fraction of autism cases may be traceable to genetic causes that are highly heritable but not inherited: that is, the mutation that causes the autism is not present in the parental genome.
Several lines of evidence point to synaptic dysfunction as a cause of autism. Some rare mutations may lead to autism by disrupting some synaptic pathways, such as those involved with cell adhesion. Gene replacement studies in mice suggest that autistic symptoms are closely related to later developmental steps that depend on activity in synapses and on activity-dependent changes. All known teratogens (agents that cause birth defects) related to the risk of autism appear to act during the first eight weeks from conception, and though this does not exclude the possibility that autism can be initiated or affected later, it is strong evidence that autism arises very early in development. Although evidence for other environmental causes is anecdotal and has not been confirmed by reliable studies, extensive searches are underway. Environmental factors that have been claimed to contribute to or exacerbate autism, or may be important in future research, include certain foods, infectious disease, heavy metals, solvents, diesel exhaust, PCBs, phthalates and phenols used in plastic products, pesticides, brominated flame retardants, alcohol, smoking, illicit drugs, vaccines, and prenatal stress. Parents may first become aware of autistic symptoms in their child around the time of a routine vaccination, and this has given rise to theories that vaccines or their preservatives cause autism. Although these theories lack convincing scientific evidence and are biologically implausible, parental concern about autism has led to lower rates of childhood immunizations and higher likelihood of measles outbreaks.
Mechanism.
Autism's symptoms result from maturation-related changes in various systems of the brain. How autism occurs is not well understood. Its mechanism can be divided into two areas: the pathophysiology of brain structures and processes associated with autism, and the neuropsychological linkages between brain structures and behaviors. The behaviors appear to have multiple pathophysiologies.
Pathophysiology.
Interactions between the immune system and the nervous system begin early during the embryonic stage of life, and successful neurodevelopment depends on a balanced immune response. It is possible that aberrant immune activity during critical periods of neurodevelopment is part of the mechanism of some forms of ASD. Although some abnormalities in the immune system have been found in specific subgroups of autistic individuals, it is not known whether these abnormalities are relevant to or secondary to autism's disease processes. As autoantibodies are found in conditions other than ASD, and are not always present in ASD, the relationship between immune disturbances and autism remains unclear and controversial.
The relationship of neurochemicals to autism is not well understood; several have been investigated, with the most evidence for the role of serotonin and of genetic differences in its transport. Some data suggest an increase in several growth hormones; other data argue for diminished growth factors. Also, some inborn errors of metabolism are associated with autism but probably account for less than 5% of cases.
The mirror neuron system (MNS) theory of autism hypothesizes that distortion in the development of the MNS interferes with imitation and leads to autism's core features of social impairment and communication difficulties. The MNS operates when an animal performs an action or observes another animal perform the same action. The MNS may contribute to an individual's understanding of other people by enabling the modeling of their behavior via embodied simulation of their actions, intentions, and emotions. Several studies have tested this hypothesis by demonstrating structural abnormalities in MNS regions of individuals with ASD, delay in the activation in the core circuit for imitation in individuals with Asperger syndrome, and a correlation between reduced MNS activity and severity of the syndrome in children with ASD. However, individuals with autism also have abnormal brain activation in many circuits outside the MNS and the MNS theory does not explain the normal performance of autistic children on imitation tasks that involve a goal or object.
ASD-related patterns of low function and aberrant activation in the brain differ depending on whether the brain is doing social or nonsocial tasks.
In autism there is evidence for reduced functional connectivity of the default network, a large-scale brain network involved in social and emotional processing, with intact connectivity of the task-positive network, used in sustained attention and goal-directed thinking. In people with autism the two networks are not negatively correlated in time, suggesting an imbalance in toggling between the two networks, possibly reflecting a disturbance of self-referential thought. A 2008 brain-imaging study found a specific pattern of signals in the cingulate cortex which differs in individuals with ASD.
The underconnectivity theory of autism hypothesizes that autism is marked by underfunctioning high-level neural connections and synchronization, along with an excess of low-level processes. Evidence for this theory has been found in functional neuroimaging studies on autistic individuals and by a brain wave study that suggested that adults with ASD have local overconnectivity in the cortex and weak functional connections between the frontal lobe and the rest of the cortex. Other evidence suggests the underconnectivity is mainly within each hemisphere of the cortex and that autism is a disorder of the association cortex.
From studies based on event-related potentials, transient changes to the brain's electrical activity in response to stimuli, there is considerable evidence for differences in autistic individuals with respect to attention, orientiation to auditory and visual stimuli, novelty detection, language and face processing, and information storage; several studies have found a preference for non-social stimuli. For example, magnetoencephalography studies have found evidence in autistic children of delayed responses in the brain's processing of auditory signals.
Neuropsychology.
Two major categories of cognitive theories have been proposed about the links between autistic brains and behavior.
The first category focuses on deficits in social cognition. The empathizing–systemizing theory postulates that autistic individuals can systemize—that is, they can develop internal rules of operation to handle events inside the brain—but are less effective at empathizing by handling events generated by other agents. An extension, the extreme male brain theory, hypothesizes that autism is an extreme case of the male brain, defined psychometrically as individuals in whom systemizing is better than empathizing; this extension is controversial, as many studies contradict the idea that baby boys and girls respond differently to people and objects.
These theories are somewhat related to the earlier theory of mind approach, which hypothesizes that autistic behavior arises from an inability to ascribe mental states to oneself and others. The theory of mind hypothesis is supported by autistic children's atypical responses to the Sally–Anne test for reasoning about others' motivations, and the mirror neuron system theory of autism described in "Pathophysiology" maps well to the hypothesis. However, most studies have found no evidence of impairment in autistic individuals' ability to understand other people's basic intentions or goals; instead, data suggests that impairments are found in understanding more complex social emotions or in considering others' viewpoints.
The second category focuses on nonsocial or general processing. Executive dysfunction hypothesizes that autistic behavior results in part from deficits in working memory, planning, inhibition, and other forms of executive function. Tests of core executive processes such as eye movement tasks indicate improvement from late childhood to adolescence, but performance never reaches typical adult levels. A strength of the theory is predicting stereotyped behavior and narrow interests; two weaknesses are that executive function is hard to measure and that executive function deficits have not been found in young autistic children.
Weak central coherence theory hypothesizes that a limited ability to see the big picture underlies the central disturbance in autism. One strength of this theory is predicting special talents and peaks in performance in autistic people. A related theory—enhanced perceptual functioning—focuses more on the superiority of locally oriented and perceptual operations in autistic individuals. These theories map well from the underconnectivity theory of autism.
Neither category is satisfactory on its own; social cognition theories poorly address autism's rigid and repetitive behaviors, while the nonsocial theories have difficulty explaining social impairment and communication difficulties. A combined theory based on multiple deficits may prove to be more useful.
Screening.
U.S. and Japanese practice is to screen all children for ASD at 18 and 24 months, using autism-specific formal screening tests. In contrast, in the UK, screening targets children whose families or doctors recognize possible signs of autism. It is not known which approach is more effective. Screening tools include the Modified Checklist for Autism in Toddlers (M-CHAT), the Early Screening of Autistic Traits Questionnaire, and the First Year Inventory; initial data on M-CHAT and its predecessor CHAT on children aged 18–30 months suggests that it is best used in a clinical setting and that it has low sensitivity (many false-negatives) but good specificity (few false-positives). It may be more accurate to precede these tests with a broadband screener that does not distinguish ASD from other developmental disorders. Screening tools designed for one culture's norms for behaviors like eye contact may be inappropriate for a different culture. Although genetic screening for autism is generally still impractical, it can be considered in some cases, such as children with neurological symptoms and dysmorphic features.
Diagnosis.
Diagnosis is based on behavior, not cause or mechanism. Autism is defined in the DSM-IV-TR as exhibiting at least six symptoms total, including at least two symptoms of qualitative impairment in social interaction, at least one symptom of qualitative impairment in communication, and at least one symptom of restricted and repetitive behavior. Sample symptoms include lack of social or emotional reciprocity, stereotyped and repetitive use of language or idiosyncratic language, and persistent preoccupation with parts of objects. Onset must be prior to age three years, with delays or abnormal functioning in either social interaction, language as used in social communication, or symbolic or imaginative play. The disturbance must not be better accounted for by Rett syndrome or childhood disintegrative disorder. ICD-10 uses essentially the same definition.
Several diagnostic instruments are available. Two are commonly used in autism research: the Autism Diagnostic Interview-Revised (ADI-R) is a semistructured parent interview, and the Autism Diagnostic Observation Schedule (ADOS) uses observation and interaction with the child. The Childhood Autism Rating Scale (CARS) is used widely in clinical environments to assess severity of autism based on observation of children.
A pediatrician commonly performs a preliminary investigation by taking developmental history and physically examining the child. If warranted, diagnosis and evaluations are conducted with help from ASD specialists, observing and assessing cognitive, communication, family, and other factors using standardized tools, and taking into account any associated medical conditions. A pediatric neuropsychologist is often asked to assess behavior and cognitive skills, both to aid diagnosis and to help recommend educational interventions. A differential diagnosis for ASD at this stage might also consider mental retardation, hearing impairment, and a specific language impairment such as Landau–Kleffner syndrome. The presence of autism can make it harder to diagnose coexisting psychiatric disorders such as depression.
Clinical genetics evaluations are often done once ASD is diagnosed, particularly when other symptoms already suggest a genetic cause. Although genetic technology allows clinical geneticists to link an estimated 40% of cases to genetic causes, consensus guidelines in the U.S. and UK are limited to high-resolution chromosome and fragile X testing. A genotype-first model of diagnosis has been proposed, which would routinely assess the genome's copy number variations. As new genetic tests are developed several ethical, legal, and social issues will emerge. Commercial availability of tests may precede adequate understanding of how to use test results, given the complexity of autism's genetics. Metabolic and neuroimaging tests are sometimes helpful, but are not routine.
ASD can sometimes be diagnosed by age 14 months, although diagnosis becomes increasingly stable over the first three years of life: for example, a one-year-old who meets diagnostic criteria for ASD is less likely than a three-year-old to continue to do so a few years later. In the UK the National Autism Plan for Children recommends at most 30 weeks from first concern to completed diagnosis and assessment, though few cases are handled that quickly in practice. A 2009 U.S. study found the average age of formal ASD diagnosis was 5.7 years, far above recommendations, and that 27% of children remained undiagnosed at age 8 years. Although the symptoms of autism and ASD begin early in childhood, they are sometimes missed; years later, adults may seek diagnoses to help them or their friends and family understand themselves, to help their employers make adjustments, or in some locations to claim disability living allowances or other benefits.
Underdiagnosis and overdiagnosis are problems in marginal cases, and much of the recent increase in the number of reported ASD cases is likely due to changes in diagnostic practices. The increasing popularity of drug treatment options and the expansion of benefits has given providers incentives to diagnose ASD, resulting in some overdiagnosis of children with uncertain symptoms. Conversely, the cost of screening and diagnosis and the challenge of obtaining payment can inhibit or delay diagnosis. It is particularly hard to diagnose autism among the visually impaired, partly because some of its diagnostic criteria depend on vision, and partly because autistic symptoms overlap with those of common blindness syndromes.
Management.
The main goals of treatment are to lessen associated deficits and family distress, and to increase quality of life and functional independence. No single treatment is best and treatment is typically tailored to the child's needs. Families and the educational system are the main resources for treatment. Studies of interventions have methodological problems that prevent definitive conclusions about efficacy. Although many psychosocial interventions have some positive evidence, suggesting that some form of treatment is preferable to no treatment, the methodological quality of systematic reviews of these studies has generally been poor, their clinical results are mostly tentative, and there is little evidence for the relative effectiveness of treatment options. Intensive, sustained special education programs and behavior therapy early in life can help children acquire self-care, social, and job skills, and often improve functioning and decrease symptom severity and maladaptive behaviors; claims that intervention by around age three years is crucial are not substantiated. Available approaches include applied behavior analysis (ABA), developmental models, structured teaching, speech and language therapy, social skills therapy, and occupational therapy. Educational interventions have some effectiveness in children: intensive ABA treatment has demonstrated effectiveness in enhancing global functioning in preschool children and is well-established for improving intellectual performance of young children. Neuropsychological reports are often poorly communicated to educators, resulting in a gap between what a report recommends and what education is provided. It is not known whether treatment programs for children lead to significant improvements after the children grow up, and the limited research on the effectiveness of adult residential programs shows mixed results.
Many medications are used to treat ASD symptoms that interfere with integrating a child into home or school when behavioral treatment fails. More than half of U.S. children diagnosed with ASD are prescribed psychoactive drugs or anticonvulsants, with the most common drug classes being antidepressants, stimulants, and antipsychotics. Aside from antipsychotics, there is scant reliable research about the effectiveness or safety of drug treatments for adolescents and adults with ASD. A person with ASD may respond atypically to medications, the medications can have adverse effects, and no known medication relieves autism's core symptoms of social and communication impairments. Experiments in mice have reversed or reduced some symptoms related to autism by replacing or modulating gene function after birth, suggesting the possibility of targeting therapies to specific rare mutations known to cause autism.
Although many alternative therapies and interventions are available, few are supported by scientific studies. Treatment approaches have little empirical support in quality-of-life contexts, and many programs focus on success measures that lack predictive validity and real-world relevance. Scientific evidence appears to matter less to service providers than program marketing, training availability, and parent requests. Though most alternative treatments, such as melatonin, have only mild adverse effects some may place the child at risk. A 2008 study found that compared to their peers, autistic boys have significantly thinner bones if on casein-free diets; in 2005, botched chelation therapy killed a five-year-old child with autism.
Treatment is expensive; indirect costs are more so. For someone born in 2000, a U.S. study estimated an average lifetime cost of $ (net present value in dollars, inflation-adjusted from 2003 estimate), with about 10% medical care, 30% extra education and other care, and 60% lost economic productivity. Publicly supported programs are often inadequate or inappropriate for a given child, and unreimbursed out-of-pocket medical or therapy expenses are associated with likelihood of family financial problems; one 2008 U.S. study found a 14% average loss of annual income in families of children with ASD, and a related study found that ASD is associated with higher probability that child care problems will greatly affect parental employment. U.S. states increasingly require private health insurance to cover autism services, shifting costs from publicly funded education programs to privately funded health insurance. After childhood, key treatment issues include residential care, job training and placement, sexuality, social skills, and estate planning.
Prognosis.
No cure is known. Children recover occasionally, so that they lose their diagnosis of ASD; this occurs sometimes after intensive treatment and sometimes not. It is not known how often recovery happens; reported rates in unselected samples of children with ASD have ranged from 3% to 25%. A few autistic children have acquired speech at age 5 or older. Most children with autism lack social support, meaningful relationships, future employment opportunities or self-determination. Although core difficulties tend to persist, symptoms often become less severe with age. Few high-quality studies address long-term prognosis. Some adults show modest improvement in communication skills, but a few decline; no study has focused on autism after midlife. Acquiring language before age six, having an IQ above 50, and having a marketable skill all predict better outcomes; independent living is unlikely with severe autism. A 2004 British study of 68 adults who were diagnosed before 1980 as autistic children with IQ above 50 found that 12% achieved a high level of independence as adults, 10% had some friends and were generally in work but required some support, 19% had some independence but were generally living at home and needed considerable support and supervision in daily living, 46% needed specialist residential provision from facilities specializing in ASD with a high level of support and very limited autonomy, and 12% needed high-level hospital care. A 2005 Swedish study of 78 adults that did not exclude low IQ found worse prognosis; for example, only 4% achieved independence. A 2008 Canadian study of 48 young adults diagnosed with ASD as preschoolers found outcomes ranging through poor (46%), fair (32%), good (17%), and very good (4%); 56% of these young adults had been employed at some point during their lives, mostly in volunteer, sheltered or part-time work. Changes in diagnostic practice and increased availability of effective early intervention make it unclear whether these findings can be generalized to recently diagnosed children.
Epidemiology.
Most recent reviews tend to estimate a prevalence of 1–2 per 1,000 for autism and close to 6 per 1,000 for ASD; because of inadequate data, these numbers may underestimate ASD's true prevalence. PDD-NOS's prevalence has been estimated at 3.7 per 1,000, Asperger syndrome at roughly 0.6 per 1,000, and childhood disintegrative disorder at 0.02 per 1,000. The number of reported cases of autism increased dramatically in the 1990s and early 2000s. This increase is largely attributable to changes in diagnostic practices, referral patterns, availability of services, age at diagnosis, and public awareness, though unidentified environmental risk factors cannot be ruled out. The available evidence does not rule out the possibility that autism's true prevalence has increased; a real increase would suggest directing more attention and funding toward changing environmental factors instead of continuing to focus on genetics.
Boys are at higher risk for ASD than girls. The sex ratio averages 4.3:1 and is greatly modified by cognitive impairment: it may be close to 2:1 with mental retardation and more than 5.5:1 without. Although the evidence does not implicate any single pregnancy-related risk factor as a cause of autism, the risk of autism is associated with advanced age in either parent, and with diabetes, bleeding, and use of psychiatric drugs in the mother during pregnancy. The risk is greater with older fathers than with older mothers; two potential explanations are the known increase in mutation burden in older sperm, and the hypothesis that men marry later if they carry genetic liability and show some signs of autism. Most professionals believe that race, ethnicity, and socioeconomic background do not affect the occurrence of autism.
History.
A few examples of autistic symptoms and treatments were described long before autism was named. The "Table Talk" of Martin Luther contains the story of a 12-year-old boy who may have been severely autistic. According to Luther's notetaker Mathesius, Luther thought the boy was a soulless mass of flesh possessed by the devil, and suggested that he be suffocated. The earliest well-documented case of autism is that of Hugh Blair of Borgue, as detailed in a 1747 court case in which his brother successfully petitioned to annul Blair's marriage to gain Blair's inheritance. The Wild Boy of Aveyron, a feral child caught in 1798, showed several signs of autism; the medical student Jean Itard treated him with a behavioral program designed to help him form social attachments and to induce speech via imitation.
The New Latin word "autismus" (English translation "autism") was coined by the Swiss psychiatrist Eugen Bleuler in 1910 as he was defining symptoms of schizophrenia. He derived it from the Greek word "autós" (αὐτός, meaning "self"), and used it to mean morbid self-admiration, referring to "autistic withdrawal of the patient to his fantasies, against which any influence from outside becomes an intolerable disturbance".
The word "autism" first took its modern sense in 1938 when Hans Asperger of the Vienna University Hospital adopted Bleuler's terminology "autistic psychopaths" in a lecture in German about child psychology. Asperger was investigating an ASD now known as Asperger syndrome, though for various reasons it was not widely recognized as a separate diagnosis until 1981. Leo Kanner of the Johns Hopkins Hospital first used "autism" in its modern sense in English when he introduced the label "early infantile autism" in a 1943 report of 11 children with striking behavioral similarities. Almost all the characteristics described in Kanner's first paper on the subject, notably "autistic aloneness" and "insistence on sameness", are still regarded as typical of the autistic spectrum of disorders. It is not known whether Kanner derived the term independently of Asperger.
Kanner's reuse of "autism" led to decades of confused terminology like "infantile schizophrenia", and child psychiatry's focus on maternal deprivation led to misconceptions of autism as an infant's response to "refrigerator mothers". Starting in the late 1960s autism was established as a separate syndrome by demonstrating that it is lifelong, distinguishing it from mental retardation and schizophrenia and from other developmental disorders, and demonstrating the benefits of involving parents in active programs of therapy. As late as the mid-1970s there was little evidence of a genetic role in autism; now it is thought to be one of the most heritable of all psychiatric conditions. Although the rise of parent organizations and the destigmatization of childhood ASD have deeply affected how we view ASD, parents continue to feel social stigma in situations where their autistic children's behaviors are perceived negatively by others, and many primary care physicians and medical specialists still express some beliefs consistent with outdated autism research. The Internet has helped autistic individuals bypass nonverbal cues and emotional sharing that they find so hard to deal with, and has given them a way to form online communities and work remotely. Sociological and cultural aspects of autism have developed: some in the community seek a cure, while others believe that autism is simply another way of being.
---END.OF.DOCUMENT---
Albedo.
The albedo of an object is a measure of how strongly it reflects light from light sources such as the Sun. It is therefore a more specific form of the term reflectivity. Albedo is defined as the ratio of total-reflected to incident electromagnetic radiation. It is a unitless measure indicative of a surface's or body's diffuse reflectivity. The word is derived from Latin "albedo" "whiteness", in turn from "albus" "white", and was introduced into optics by Johann Heinrich Lambert in his 1760 work "Photometria". The range of possible values is from 0 (dark) to 1 (bright).
The albedo is an important concept in climatology and astronomy, as well as in computer graphics and computer vision. In climatology it is sometimes expressed as a percentage. Its value depends on the frequency of radiation considered: unqualified, it usually refers to some appropriate average across the spectrum of visible light. In general, the albedo depends on the direction and directional distribution of incoming radiation. Exceptions are Lambertian surfaces, which scatter radiation in all directions in a cosine function, so their albedo does not depend on the incoming distribution. In realistic cases, a bidirectional reflectance distribution function (BRDF) is required to characterize the scattering properties of a surface accurately, although albedos are a very useful first approximation.
Terrestrial albedo.
Albedos of typical materials in visible light range from up to 0.9 for fresh snow, to about 0.04 for charcoal, one of the darkest substances. Deeply shadowed cavities can achieve an effective albedo approaching the zero of a blackbody. When seen from a distance, the ocean surface has a low albedo, as do most forests, while desert areas have some of the highest albedos among landforms. Most land areas are in an albedo range of 0.1 to 0.4. The average albedo of the Earth is about 0.3. This is far higher than for the ocean primarily because of the contribution of clouds.
Human activities have changed the albedo (via forest clearance and farming, for example) of various areas around the globe. However, quantification of this effect on the global scale is difficult.
The classic example of albedo effect is the snow-temperature feedback. If a snow-covered area warms and the snow melts, the albedo decreases, more sunlight is absorbed, and the temperature tends to increase. The converse is true: if snow forms, a cooling cycle happens. The intensity of the albedo effect depends on the size of the change in albedo and the amount of insolation; for this reason it can be potentially very large in the tropics.
The Earth's surface albedo is regularly estimated via Earth observation satellite sensors such as NASA's MODIS instruments onboard the Terra and Aqua satellites. As the total amount of reflected radiation cannot be directly measured by satellite, a mathematical model of the BRDF is used to translate a sample set of satellite reflectance measurements into estimates of directional-hemispherical reflectance and bi-hemispherical reflectance. (e. g.,
The Earth's average surface temperature due to its albedo and the greenhouse effect is currently about 15°C. For the frozen (more reflective) planet the average temperature is below -40°C (If only all continents being completely covered by glaciers - the mean temperature is about 0°C). The simulation for (more absorptive) aquaplanet shows the average temperature close to 27°C.
White-sky and black-sky albedo.
It has been shown that for many applications involving terrestrial albedo, the albedo at a particular solar zenith angle formula_1 can reasonably be approximated by the proportionate sum of two terms: the directional-hemispherical reflectance at that solar zenith angle, formula_2, and the bi-hemispherical reflectance, formula_3 the proportion concerned being defined as the proportion of diffuse illumination formula_4.
Directional-hemispherical reflectance is sometimes referred to as black-sky albedo and bi-hemispherical reflectance as white sky albedo. These terms are important because they allow the albedo to be calculated for any given illumination conditions from a knowledge of the intrinsic properties of the surface.
Astronomical albedo.
The albedos of planets, satellites and asteroids can be used to infer much about their properties. The study of albedos, their dependence on wavelength, lighting angle ("phase angle"), and variation in time comprises a major part of the astronomical field of photometry. For small and far objects that cannot be resolved by telescopes, much of what we know comes from the study of their albedos. For example, the absolute albedo can indicate the surface ice content of outer solar system objects, the variation of albedo with phase angle gives information about regolith properties, while unusually high radar albedo is indicative of high metallic content in asteroids.
Enceladus, a moon of Saturn, has one of the highest known albedos of any body in the Solar system, with 99% of EM radiation reflected. Another notable high albedo body is Eris, with an albedo of 0.86. Many small objects in the outer solar system and asteroid belt have low albedos down to about 0.05. A typical comet nucleus has an albedo of 0.04. Such a dark surface is thought to be indicative of a primitive and heavily space weathered surface containing some organic compounds.
The overall albedo of the Moon is around 0.072, but it is strongly directional and non-Lambertian, displaying also a strong opposition effect. While such reflectance properties are different from those of any terrestrial terrains, they are typical of the regolith surfaces of airless solar system bodies.
Two common albedos that are used in astronomy are the (V-band) geometric albedo (measuring brightness when illumination comes from directly behind the observer) and the Bond albedo (measuring total proportion of electromagnetic energy reflected). Their values can differ significantly, which is a common source of confusion.
In detailed studies, the directional reflectance properties of astronomical bodies are often expressed in terms of the five Hapke parameters which semi-empirically describe the variation of albedo with phase angle, including a characterization of the opposition effect of regolith surfaces.
formula_7,
where formula_8 is the astronomical albedo, formula_9 is the diameter in kilometres, and "H" is the absolute magnitude.
Other types of albedo.
Single scattering albedo is used to define scattering of electromagnetic waves on small particles. It depends on properties of the material (refractive index); the size of the particle or particles; and the wavelength of the incoming radiation.
Albedo also refers to the white, spongy inner lining of a citrus fruit rind. According to Dr. Renee M. Goodrich, associate professor of food science and human nutrition at the University of Florida, the albedo is rich in the soluble fiber pectin and contains vitamin C.
The tropics.
Although the albedo-temperature effect is most famous in colder regions of Earth, because more snow falls there, it is actually much stronger in tropical regions because in the tropics there is consistently more sunlight. When ranchers cut down dark, tropical rainforest trees to replace them with even darker soil in order to grow crops, the average temperature of the area increases up to 3 °C (5.4 °F) year-round, although part of the effect is due to changed evaporation (latent heat flux).
Small scale effects.
Albedo works on a smaller scale, too. People who wear dark clothes in the summertime put themselves at a greater risk of heatstroke than those who wear lighter color clothes.
Trees.
Because trees tend to have a low albedo, removing forests would tend to increase albedo and thereby could produce localized climate cooling. Cloud feedbacks further complicate the issue. In seasonally snow-covered zones, winter albedos of treeless areas are 10% to 50% higher than nearby forested areas because snow does not cover the trees as readily. Deciduous trees have an albedo value of about 0.15 to 0.18 while coniferous trees have a value of about 0.09 to 0.15. The difference between deciduous and coniferous is because coniferous trees are darker in general and have cone-shaped crowns. The shape of these crowns trap radiant energy more effectively than deciduous trees.
Studies by the Hadley Centre have investigated the relative (generally warming) effect of albedo change and (cooling) effect of carbon sequestration on planting forests. They found that new forests in tropical and midlatitude areas tended to cool; new forests in high latitudes (e.g. Siberia) were neutral or perhaps warming.
Snow.
Snow albedos can be as high as 0.9; this, however, is for the ideal example: fresh deep snow over a featureless landscape. Over Antarctica they average a little more than 0.8. If a marginally snow-covered area warms, snow tends to melt, lowering the albedo, and hence leading to more snowmelt (the ice-albedo positive feedback).
Water.
Water reflects light very differently from typical terrestrial materials. The reflectivity of a water surface is calculated using the Fresnel equations (see graph).
At the scale of the wavelength of light even wavy water is always smooth so the light is reflected in a specular manner (not diffusely). The glint of light off water is a commonplace effect of this. At small angles of incident light, waviness results in reduced reflectivity because of the steepness of the reflectivity-vs.-incident-angle curve and a locally increased average incident angle.
Although the reflectivity of water is very low at low and medium angles of incident light, it increases tremendously at high angles of incident light such as occur on the illuminated side of the Earth near the terminator (early morning, late afternoon and near the poles). However, as mentioned above, waviness causes an appreciable reduction. Since the light specularly reflected from water does not usually reach the viewer, water is usually considered to have a very low albedo in spite of its high reflectivity at high angles of incident light.
Note that white caps on waves look white (and have high albedo) because the water is foamed up (not smooth at the scale of the wavelength of light) so the Fresnel equations do not apply. Fresh ‘black’ ice exhibits Fresnel reflection.
Clouds.
Clouds are another source of albedo that play into the global warming equation. Different types of clouds have different albedo values, theoretically ranging from a minimum of near 0 to a maximum approaching 0.8. "On any given day, about half of Earth is covered by clouds, which reflect more sunlight than land and water. Clouds keep Earth cool by reflecting sunlight, but they can also serve as blankets to trap warmth."
Albedo and climate in some areas are already affected by artificial clouds, such as those created by the contrails of heavy commercial airliner traffic. A study following the burning of the Kuwaiti oil fields by Saddam Hussein showed that temperatures under the burning oil fires were as much as 10oC colder than temperatures several miles away under clear skies.
Aerosol effects.
Aerosol (very fine particles/droplets in the atmosphere) has two effects, direct and indirect. The direct (albedo) effect is generally to cool the planet; the indirect effect (the particles act as CCNs and thereby change cloud properties) is less certain.
Aerosols can modify the Earth’s radiative balance through the aerosol direct and indirect
Black carbon.
Another albedo-related effect on the climate is from black carbon particles. The size of this effect is difficult to quantify: the IPCC say that their "estimate of the global mean radiative forcing for BC aerosols from fossil fuels is... +0.2 W m-2 (from +0.1 W m-2 in the SAR) with a range +0.1 to +0.4 W m...-2".
---END.OF.DOCUMENT---
A.
The letter A is the first letter in the Latin alphabet, a vowel. Its name in English () is spelled ‹a›; the plural is "aes," although this is rare.
Origins.
"A" can be traced to a pictogram of an ox head in Egyptian hieroglyph or the Proto-Sinaitic alphabet.
In 1600 B.C. the Phoenician alphabet's letter had a linear form that served as the base for some later forms. Its name must have corresponded closely to the Hebrew or Arabic aleph.
When the Ancient Greeks adopted the alphabet, they had no use for the glottal stop that the letter had denoted in Phoenician and other Semitic languages, so they used the sign to represent the vowel, and kept its name with a minor change (alpha). In the earliest Greek inscriptions after the Greek Dark Ages, dating to the 8th century BC, the letter rests upon its side, but in the Greek alphabet of later times it generally resembles the modern capital letter, although many local varieties can be distinguished by the shortening of one leg, or by the angle at which the cross line is set.
The Etruscans brought the Greek alphabet to their civilization in the Italian Peninsula and left the letter unchanged. The Romans later adopted the Etruscan alphabet to write the Latin language, and the resulting letter was preserved in the modern Latin alphabet used to write many languages, including English.
The letter has two minuscule (lower-case) forms. The form used in most current handwriting consists of a circle and vertical stoke (), called Latin alpha or "script a". Most printed material uses a form consisting of a small loop with an arc over it (). Both derive from the majuscule (capital) form. In Greek handwriting, it was common to join the left leg and horizontal stroke into a single loop, as demonstrated by the Uncial version shown. Many fonts then made the right leg vertical. In some of these, the serif that began the right leg stroke developed into an arc, resulting in the printed form, while in others it was dropped, resulting in the modern handwritten form.
Usage.
In English, "a" by itself frequently denotes the near-open front unrounded vowel () as in "pad", the open back unrounded vowel () as in "father", or, in concert with a later orthographic vowel, the diphthong as in "ace" and "major", due to effects of the great vowel shift.
In most other languages that use the Latin alphabet, "a" denotes an open central unrounded vowel (). In the International Phonetic Alphabet, variants of "a" denote various vowels. In X-SAMPA, capital "A" denotes the open back unrounded vowel and lowercase "a" denotes the open front unrounded vowel.
"A" is the third common used letter in English, and the second most common in Spanish and French. In one study, on average, about 3.68% of letters used in English tend to be ‹a›s, while the number is 6.22% in Spanish and 3.95% in French.
"A" is often used to denote something or someone of a better or more prestigious quality or status: A-, A or A+, the best grade that can be assigned by teachers for students' schoolwork; A grade for clean restaurants; A-List celebrities, etc. Such associations can have a motivating effect as exposure to the letter A has been found to improve performance, when compared with other letters.
A turned "a" () is used by the International Phonetic Alphabet for the near-open central vowel, while a turned capital "A" ("∀") is used in predicate logic to specify universal quantification.
Codes for computing.
In Unicode the capital "A" is codepoint U+0043 and the lower case "a" is U+0067.
The ASCII code for capital "A" is 65 and for lower case "a" is 97; or in binary 01000001 and 01100001, respectively.
The EBCDIC code for capital "A" is 193 and for lowercase "a" is 129.
The numeric character references in HTML and XML are "&amp;#65;" and "&amp;#97;" for upper and lower case, respectively.
---END.OF.DOCUMENT---
Achilles.
In Greek mythology, Achilles (Ancient Greek:) was a Greek hero of the Trojan War, the central character and the greatest warrior of Homer's "Iliad".
Achilles also has the attributes of being the most handsome of the heroes assembled against Troy.
Later legends (beginning with a poem by Statius in the first century AD) state that Achilles was invulnerable in all of his body except for his heel. Since he died due to an arrow shot into his heel, the "Achilles' heel" has come to mean a person's principal weakness.
Birth.
Achilles was the son of the nymph Thetis and Peleus, the king of the Myrmidons. Zeus and Poseidon had been rivals for the hand of Thetis until Prometheus, the fire-bringer, warned Zeus of a prophecy that Thetis would bear a son greater than his father. For this reason, the two gods withdrew their pursuit, and had her wed Peleus.
As with most mythology there is a tale which offers an alternative version of these events: in "Argonautica" (iv.760) Hera alludes to Thetis's chaste resistance to the advances of Zeus, that Thetis was so loyal to Hera's marriage bond that she coolly rejected him. Thetis, although a daughter of the sea-god Nereus, was also brought up by Hera, further explaining her resistance to the advances of Zeus.
According to the "Achilleid", written by Statius in the first century AD, and to no surviving previous sources, when Achilles was born Thetis tried to make him immortal by dipping him in the river Styx. However, he was left vulnerable at the part of the body she held him by, his heel. (See Achilles heel, Achilles' tendon.) It is not clear if this version of events was known earlier. In another version of this story, Thetis anointed the boy in ambrosia and put him on top of a fire to burn away the mortal parts of his body. She was interrupted by Peleus and abandoned both father and son in a rage.
However none of the sources before Statius makes any reference to this general invulnerability. To the contrary, in the "Iliad" Homer mentions Achilles being wounded: in Book 21 the Paeonian hero Asteropaeus, son of Pelagon, challenged Achilles by the river Scamander. He cast two spears at once, one grazed Achilles' elbow, "drawing a spurt of blood."
Also in the fragmentary poems of the Epic Cycle in which we can find description of the hero's death, Kúpria (unknown author), "Aithiopis" by Arctinus of Miletus, "Ilias Mikrá" by Lesche of Mytilene, Iliou pérsis by Arctinus of Miletus, there is no trace of any reference to his general invulnerability or his famous weakness (heel); in the later vase-paintings presenting Achilles' death, the arrow (or in many cases, arrows) hit his body.
Peleus entrusted Achilles to Chiron the Centaur, on Mt. Pelion, to be raised.
Achilles in the Trojan War.
Achilles' consuming rage is at some times wavering, but at other times he cannot be cooled. The humanization of Achilles by the events of the war is an important theme of the narrative.
Telephus.
When the Greeks left for the Trojan War, they accidentally stopped in Mysia, ruled by King Telephus. In the resulting battle, Achilles gave Telephus a wound that would not heal; Telephus consulted an oracle, who stated that "he that wounded shall heal". Guided by the oracle, he arrived at Argos, where Achilles heals him in order that he become their guide for the voyage to Troy.
According to other reports in Euripides' lost play about Telephus, he went to Aulis pretending to be a beggar and asked Achilles to heal his wound. Achilles refused, claiming to have no medical knowledge. Alternatively, Telephus held Orestes for ransom, the ransom being Achilles' aid in healing the wound. Odysseus reasoned that the spear had inflicted the wound; therefore, the spear must be able to heal it. Pieces of the spear were scraped off onto the wound and Telephus was healed.
Troilus.
According to the Cypria (the part of the Epic Cycle that tells the events of the Trojan War before Achilles' Wrath), when the Achaeans desired to return home, they were restrained by Achilles, who afterwards attacked the cattle of Aeneas, sacked neighboring cities and killed Troilus.
According to Dares Phrygius' "Account of the Destruction of Troy", the Latin summary through which the story of Achilles was transmitted to medieval Europe, Troilus was a young Trojan prince, the youngest of King Priam's (or sometimes Apollo) and Hecuba's five legitimate sons. Despite his youth, he was one of the main Trojan war leaders. Prophecies linked Troilus' fate to that of Troy and so he was ambushed in an attempt to capture him. Yet Achilles, struck by the beauty of both Troilus and his sister Polyxena, and overcome with lust directed his sexual attentions on the youth — who refusing to yield found instead himself decapitated upon an altar-omphalos of Apollo. Later versions of the story suggested Troilus was accidentally killed by Achilles in an over-ardent lovers' embrace. In this version of the myth, Achilles' death therefore came in retribution for this sacrilege. Ancient writers treated Troilus as the epitome of a dead child mourned by his parents. Had Troilus lived to adulthood, the First Vatican Mythographer claimed Troy would have been invincible.
In the "Iliad".
Homer's "Iliad" is the most famous narrative of Achilles' deeds in the Trojan War. The Homeric epic only covers a few weeks of the war, and does not narrate Achilles' death. It begins with Achilles' withdrawal from battle after he is dishonored by Agamemnon, the commander of the Achaean forces. Agamemnon had taken a woman named Chryseis as his slave. Her father Chryses, a priest of Apollo, begged Agamemnon to return her to him. Agamemnon refused and Apollo sent a plague amongst the Greeks. The prophet Calchas correctly determined the source of the troubles but would not speak unless Achilles vowed to protect him. Achilles did so and Calchas declared Chryseis must be returned to her father. Agamemnon consented, but then commanded that Achilles' battle prize Briseis be brought to replace Chryseis. Angry at the dishonor (and as he says later, because he loved Briseis) and at the urging of Thetis, Achilles refused to fight or lead his troops alongside the other Greek forces.
As the battle turned against the Greeks, Nestor declared that the Trojans were winning because Agamemnon had angered Achilles, and urged the king to appease the warrior. Agamemnon agreed and sent Odysseus and two other chieftains, Ajax and Phoenix, to Achilles with the offer of the return of Briseis and other gifts. Achilles rejected all Agamemnon offered him, and simply urged the Greeks to sail home as he was planning to do.
Eventually, however, hoping to retain glory despite his absence from the battle, Achilles prayed to his mother Thetis, asking her to plead with Zeus to allow the Trojans to push back the Greek forces.
The Trojans, led by Hector, subsequently pushed the Greek army back toward the beaches and assaulted the Greek ships. With the Greek forces on the verge of absolute destruction, Patroclus led the Myrmidons into battle, though Achilles remained at his camp. Patroclus succeeded in pushing the Trojans back from the beaches, but was killed by Hector before he could lead a proper assault on the city of Troy.
After receiving the news of the death of Patroclus from Antilochus, the son of Nestor, Achilles grieved over his close friend's death and held many funeral games in his honor. His mother Thetis came to comfort the distraught Achilles. She persuaded Hephaestus to make new armor for him, in place of the armor that Patroclus had been wearing which was taken by Hector. The new armor included the Shield of Achilles, described in great detail by the poet.
Enraged over the death of Patroclus, Achilles ended his refusal to fight and took the field killing many men in his rage but always seeking out Hector. Achilles even engaged in battle with the river god Scamander who became angry that Achilles was choking his waters with all the men he killed. The god tried to drown Achilles but was stopped by Hera and Hephaestus. Zeus himself took note of Achilles' rage and sent the gods to restrain him so that he would not go on to sack Troy itself, seeming to show that the unhindered rage of Achilles could defy fate itself as Troy was not meant to be destroyed yet. Finally Achilles found his prey. Achilles chased Hector around the wall of Troy three times before Athena, in the form of Hector's favorite and dearest brother, Deiphobus, persuaded Hector to stop running and fight Achilles face to face. After Hector realized the trick, he knew the battle was inevitable. Wanting to go down fighting, he charged at Achilles with his only weapon, his sword, but missed. Accepting his fate, Hector begged Achilles – not to spare his life, but to treat his body with respect after killing him. Achilles told Hector it was hopeless to expect that of him, declaring that "my rage, my fury would drive me now to hack your flesh away and eat you raw — such agonies you have caused me". Achilles then got his vengeance, killing Hector with a single blow to the neck and tying the Trojan's body to his chariot, dragging it around the battlefield for nine days.
With the assistance of the god Hermes, Hector's father, Priam, went to Achilles' tent to plead with Achilles to permit him to perform for Hector his funeral rites. The final passage in the "Iliad" is Hector's funeral, after which the doom of Troy was just a matter of time.
Penthesilea.
Achilles, after his temporary truce with Priam, fought and killed the Amazonian warrior queen Penthesilea, but later grieved over her death. At first, he was so distracted by her beauty, he did not fight as intensely as usual. Once he realized that his distraction was endangering his life, he refocused, and killed her. As he grieved over the death of such a rare beauty, a notorious Greek jeerer by the name of Thersites laughed and mocked the great Achilles. Annoyed by his insensitivity and disrespect, Achilles punched him in the face and killed him instantly.
Memnon, and the fall of Achilles.
Following the death of Patroclus, Achilles' closest companion was Nestor's son Antilochus. When Memnon, king of Ethiopia killed Antilochus, Achilles was once again drawn onto the battlefield to seek revenge. The fight between Achilles and Memnon over Antilochus echoes that of Achilles and Hector over Patroclus, except that Memnon (unlike Hector) was also the son of a goddess.
Many Homeric scholars argued that episode inspired many details in the "Iliads description of the death of Patroclus and Achilles' reaction to it. The episode then formed the basis of the cyclic epic "Aethiopis", which was composed after the "Iliad", possibly in the 7th century B.C. The "Aethiopis" is now lost, except for scattered fragments quoted by later authors.
As predicted by Hector with his dying breath, Achilles was thereafter killed by Paris with an arrow (to the heel according to Statius). In some versions, the god Apollo guided Paris' arrow. Some retellings also state that Achilles was scaling the gates of Troy and was hit with a poisoned arrow.
Both versions conspicuously deny the killer any sort of valor owing to the common conception that Paris was a coward and not the man his brother Hector was, and Achilles remained undefeated on the battlefield. His bones were mingled with those of Patroclus, and funeral games were held. He was represented in the lost Trojan War epic of Arctinus of Miletus as living after his death in the island of Leuke at the mouth of the river Danube (see below). Another version of Achilles' death is that he fell deeply in love with one of the Trojan princesses, Polyxena, Achilles asks Priam for Polyxena's hand in marriage. Priam is willing because it would mean the end of the war and an alliance with the world's greatest warrior. But while Priam is overseeing the private marriage of Polyxena and Achilles, Paris who would have to give up Helen if Achilles married his sister hides in the bushes and shoots Achilles with a divine arrow killing him.
Achilles was cremated and his ashes buried in the same urn as those of Patroclus.
Paris was later killed by Philoctetes using the enormous bow of Heracles.
Fate of Achilles' armor.
Achilles' armor was the object of a feud between Odysseus and Telamonian Ajax (Ajax the greater). They competed for it by giving speeches on why they were the bravest after Achilles to their Trojan prisoners, who after considering both men came to a consensus in favor of Odysseus. Furious, Ajax cursed Odysseus, which earned the ire of Athena. Athena temporarily made Ajax so mad with grief and anguish that he began killing sheep, thinking they were his comrades. After a while, when Athena lifted his madness and Ajax realized that he had actually been killing sheep, he was so embarrassed that he committed suicide. Odysseus eventually gave the armor to Neoptolemus, the son of Achilles.
A relic claimed to be Achilles' bronze-headed spear was for centuries preserved in the temple of Athena on the acropolis of Phaselis, Lycia, a port on the Pamphylian Gulf. The city was visited in 333 BC by Alexander the Great, who envisioned himself as the new Achilles and carried the "Iliad" with him, but his court biographers do not mention the spear, which he would indeed have touched with excitement. But it was being shown in the time of Pausanias in the second century AD.
Achilles and Patroclus.
Achilles' relationship with Patroclus is a key aspect of his myth. Its exact nature has been a subject of dispute in both the classical period and modern times. In the "Iliad", they appeared to be generally portrayed as a model of deep and loyal friendship. However, commentators from the classical period to today have tended to interpret the relationship through the lens of their own cultures. Thus, in 5th century BC Athens the relationship was commonly interpreted as pederastic. Contemporary readers may interpret the two heroes either as relatives or close friends, as "war buddies," as being in a teacher/student relationship, or in love with each other as an egalitarian homosexual couple. Whichever the case may be, Achilles nevertheless continued to have sexual relationships with women.
The cult of Achilles in antiquity.
There was an archaic heroic cult of Achilles on the White Island, "Leuce", in the Black Sea off the modern coasts of Romania and Ukraine, with a temple and an oracle which survived into the Roman period.
In the lost epic "Aithiopis", a continuation of the "Iliad" attributed to Arktinus of Miletos, Achilles’ mother Thetis returned to mourn him and removed his ashes from the pyre and took them to Leuce at the mouths of the Danube. There the Achaeans raised a tumulus for him and celebrated funeral games.
Pliny's Natural History (IV.27.1) mentions a tumulus that is no longer evident ("Insula Akchillis tumulo eius viri clara"), on the island consecrated to him, located at a distance of fifty Roman miles from Peuce by the Danube Delta, and the temple there. Pausanias has been told that the island is "covered with forests and full of animals, some wild, some tame. In this island there is also Achilles’ temple and his statue” (III.19.11). Ruins of a square temple 30 meters to a side, possibly that dedicated to Achilles, were discovered by Captain Kritzikly in 1823, but there has been no modern archeological work done on the island.
Pomponius Mela tells that Achilles is buried in the island named Achillea, between Boristhene and Ister ("De situ orbis", II, 7). And the Greek geographer Dionysius Periegetus of Bithynia, who lived at the time of Domitian, writes that the island was called "Leuce" "because the wild animals which live there are white. It is said that there, in Leuce island, reside the souls of Achilles and other heroes, and that they wander through the uninhabited valleys of this island; this is how Jove rewarded the men who had distinguished themselves through their virtues, because through virtue they had acquired everlasting honor” ("Orbis descriptio", v. 541, quoted in Densuşianu 1913).
The "Periplus of the Euxine Sea" gives the following details: "It is said that the goddess Thetis raised this island from the sea, for her son Achilles, who dwells there. Here is his temple and his statue, an archaic work. This island is not inhabited, and goats graze on it, not many, which the people who happen to arrive here with their ships, sacrifice to Achilles. In this temple are also deposited a great many holy gifts, craters, rings and precious stones, offered to Achilles in gratitude. One can still read inscriptions in Greek and Latin, in which Achilles is praised and celebrated. Some of these are worded in Patroclus’ honor, because those who wish to be favored by Achilles, honor Patroclus at the same time. There are also in this island countless numbers of sea birds, which look after Achilles’ temple. Every morning they fly out to sea, wet their wings with water, and return quickly to the temple and sprinkle it. And after they finish the sprinkling, they clean the hearth of the temple with their wings. Other people say still more, that some of the men who reach this island, come here intentionally. They bring animals in their ships, destined to be sacrificed. Some of these animals they slaughter, others they set free on the island, in Achilles’ honor. But there are others, who are forced to come to this island by sea storms. As they have no sacrificial animals, but wish to get them from the god of the island himself, they consult Achilles’ oracle. They ask permission to slaughter the victims chosen from among the animals that graze freely on the island, and to deposit in exchange the price which they consider fair. But in case the oracle denies them permission, because there is an oracle here, they add something to the price offered, and if the oracle refuses again, they add something more, until at last, the oracle agrees that the price is sufficient. And then the victim doesn’t run away any more, but waits willingly to be caught. So, there is a great quantity of silver there, consecrated to the hero, as price for the sacrificial victims. To some of the people who come to this island, Achilles appears in dreams, to others he would appear even during their navigation, if they were not too far away, and would instruct them as to which part of the island they would better anchor their ships”. (quoted in Densuşianu)
The heroic cult of Achilles on Leuce island was widespread in antiquity, not only along the sea lanes of the Pontic Sea but also in maritime cities whose economic interests were tightly connected to the riches of the Black Sea.
Achilles from Leuce island was venerated as "Pontarches" the lord and master of the Pontic (Black) Sea, the protector of sailors and navigation. Sailors went out of their way to offer sacrifice. To Achilles of Leuce were dedicated a number of important commercial port cities of the Greek waters: Achilleion in Messenia (Stephanus Byzantinus), Achilleios in Laconia (Pausanias, III.25,4) Nicolae Densuşianu (Densuşianu 1913) even thought he recognized Achilles in the name of Aquileia and in the north arm of the Danube delta, the arm of Chilia ("Achileii"), though his conclusion, that Leuce had sovereign rights over Pontos, evokes modern rather than archaic sea-law."
Leuce had also a reputation as a place of healing. Pausanias (III.19,13) reports that the Delphic Pythia sent a lord of Croton to be cured of a chest wound. Ammianus Marcellinus (XXII.8) attributes the healing to waters ("aquae") on the island.
The cult of Achilles in modern times: The Achilleion in Corfu.
In the region of Gastouri (Γαστούρι) to the south of the city of Corfu Greece, Empress of Austria Elisabeth of Bavaria also known as Sissi built in 1890 a summer palace with Achilles as its central theme and it is a monument to platonic romanticism. The palace, naturally, was named after Achilles: "Achilleion" (Αχίλλειον). This elegant structure abounds with paintings and statues of Achilles both in the main hall and in the lavish gardens depicting the heroic and tragic scenes of the Trojan war.
The name of Achilles.
Achilles' name can be analyzed as a combination of ("akhos") "grief" and ("Laos") "a people, tribe, nation, etc." In other words, Achilles is an embodiment of the grief of the people, grief being a theme raised numerous times in the "Iliad" (frequently by Achilles). Achilles' role as the hero of grief forms an ironic juxtaposition with the conventional view of Achilles as the hero of "kleos" (glory, usually glory in war).
"Laos" has been construed by Gregory Nagy, following Leonard Palmer, to mean "a corps of soldiers", a muster. With this derivation, the name would have a double meaning in the poem: When the hero is functioning rightly, his men bring grief to the enemy, but when wrongly, his men get the grief of war. The poem is in part about the misdirection of anger on the part of leadership.
The name Achilleus was a common and attested name among the Greeks early after 7th century BC. It was also turned into the female form of Ἀχιλλεία, "Achilleía", firstly attested in Attica,4th century BC, (IG II² 1617) and Achillia, as the name of a female gladiator fighting, 'Amazonia'. Roman gladiatorial games often referenced classical mythology and this seems to reference Achilles' fight with Penthesilea, but give it an extra twist of Achilles being 'played' by a woman.
Other stories about Achilles.
Some post-Homeric sources claim that in order to keep Achilles safe from the war, Thetis (or, in some versions, Peleus) hides the young man at the court of Lycomedes, king of Skyros. There, Achilles is disguised as a girl and lives among Lycomedes' daughters, perhaps under the name "Pyrrha" (the red-haired girl). With Lycomedes' daughter Deidamia, whom in the account of Statius he rapes, Achilles there fathers a son, Neoptolemus (also called Pyrrhus, after his father's possible alias). According to this story, Odysseus learns from the prophet Calchas that the Achaeans would be unable to capture Troy without Achilles' aid. Odysseus goes to Skyros in the guise of a peddler selling women's clothes and jewelry and places a shield and spear among his goods. When Achilles instantly takes up the spear, Odysseus sees through his disguise and convinces him to join the Greek campaign. In another version of the story, Odysseus arranges for a trumpet alarm to be sounded while he was with Lycomedes' women; while the women flee in panic, Achilles prepares to defend the court, thus giving his identity away.
In book 11 of Homer's "Odyssey," Odysseus sails to the underworld and converses with the shades. One of these is Achilles, who when greeted as "blessed in life, blessed in death", responds that he would rather be a slave to the worst of masters than be king of all the dead. But Achilles then asks Odysseus of his son's exploits in the Trojan war, and when Odysseus tells of Neoptolemus' heroic actions, Achilles is filled with satisfaction. This leaves the reader with an ambiguous understanding of how Achilles felt about the heroic life. Achilles was worshipped as a sea-god in many of the Greek colonies on the Black Sea, the location of the mythical "White Island" which he was said to inhabit after his death, together with many other heroes.
The kings of the Epirus claimed to be descended from Achilles through his son, Neoptolemus. Alexander the Great, son of the Epiran princess Olympias, could therefore also claim this descent, and in many ways strove to be like his great ancestor; he is said to have visited his tomb while passing Troy.
Achilles fought and killed the Amazon Helene. Some also said he married Medea, and that after both their deaths they were united in the Elysian Fields of Hades — as Hera promised Thetis in Apollonius' Argonautica. In some versions of the myth, Achilles has a relationship with his captive Briseis.
Achilles in Greek tragedy.
The Greek tragedian Aeschylus wrote a trilogy of plays about Achilles, given the title "Achilleis" by modern scholars. The tragedies relate the deeds of Achilles during the Trojan War, including his defeat of Hector and eventual death when an arrow shot by Paris and guided by Apollo punctures his heel. Extant fragments of the "Achilleis" and other Aeschylean fragments have been assembled to produce a workable modern play. The first part of the "Achilleis" trilogy, "The Myrmidons", focused on the relationship between Achilles and chorus, who represent the Achaean army and try to convince Achilles to give up his quarrel with Agamemnon; only a few lines survive today.
The tragedian Sophocles also wrote a play with Achilles as the main character, "The Lovers of Achilles". Only a few fragments survive.
Achilles in Greek philosophy.
The philosopher Zeno of Elea centered one of his paradoxes on an imaginary footrace between "swift-footed" Achilles and a tortoise, by which he attempted to show that Achilles could not catch up to a tortoise with a head start, and therefore that motion and change were impossible. As a student of the monist Parmenides and a member of the Eleatic school, Zeno believed time and motion to be illusions.
Music.
Achilles has frequently been mentioned in music.
Quotes.
"If Achilles was anything, he was a man who believed his own press releases."
—Roger Ebert, commenting on the classical depiction of Achilles' character and personality.
Bibliography.
Thomas Bullfinch, Myths of Greek and Rome
---END.OF.DOCUMENT---
Academy Award for Best Art Direction.
The Academy Awards are the oldest awards ceremony for achievements in motion pictures. The Academy Award for Best Art Direction recognizes achievement in art direction on a film. The films below are listed with their production year, so the Oscar 2000 for best art direction went to a film from 1999. In the lists below, the winner of the award for each year is shown first, followed by the other nominees.
1920s.
This award was originally for Interior Decoration
1930s.
With the awards for 1940 the award was divided into separate awards for black-and-white and color movies.
1940s.
Beginning with 1947 movies the name of the award was changed to Art Direction - Set Decoration.
1950s.
For 1957 films this award became a single award.
With the 1959 films this category was again divided in two
1960s.
For 1967 the two awards in this category were recombined into a single award.
---END.OF.DOCUMENT---
Academy Award.
The Academy Award (frequently known as the Oscars) are accolades presented annually by the Academy of Motion Picture Arts and Sciences (AMPAS) to recognize excellence of professionals in the film industry, including directors, actors, and writers. The formal ceremony at which the awards are presented is one of the most prominent award ceremonies in the world. It is also the oldest award ceremony in the media, and many other award ceremonies such as the Grammy Awards (for music), Golden Globe Awards (all forms of visual media), and Emmy Awards (for television) are often modeled from the Academy. The Academy of Motion Picture Arts and Sciences itself was conceived by Metro-Goldwyn-Mayer studio boss Louis B. Mayer.
The 1st Academy Awards ceremony was held on Thursday, May 16, 1929, at the Hotel Roosevelt in Hollywood to honor outstanding film achievements of 1927 and 1928. It was hosted by actor Douglas Fairbanks and director William C. deMille. The 82nd Academy Awards, honoring the best in film for 2009, was held on Sunday, March 7, 2010, at the Kodak Theatre in Hollywood, with actors Steve Martin and Alec Baldwin hosting the ceremony.
History.
The first awards were presented on May 16, 1929, at a private brunch at the Hollywood Roosevelt Hotel with an audience of about 270 people..
The cost of guest tickets for that night's ceremony was $5. Fifteen statuettes were awarded, honoring artists, directors and other personalities of the filmmaking industry of the time for their works during the 1927-1928 period.
Winners had been announced three months earlier of their triumphs; however that was changed in the second ceremony of the Academy Awards in 1930. Since then and during the first decade, the results were given to newspapers for publication at 11pm on the night of the awards. This method was used until the "Los Angeles Times" announced the winners before the ceremony began; as a result, the Academy has used a sealed envelope to reveal the name of the winners since 1941. Since 2002, the awards have been broadcast from the Kodak Theatre.
The first Best Actor awarded was Emil Jannings, for his performance in The Last Command and The Way of All Flesh. He had to return to Europe before the ceremony, so the Academy agreed to give him the prize earlier; this made him the first Academy Award winner in history. The honored professionals were awarded for all the work done in a certain category for the qualifying period; for example, Emil Jannings, received the award for two movies he starred during that period. Since the fourth ceremony, the system changed, and the professionals were honored for a specific performance in a single film.
In the 29th ceremony, held on March 27th, 1957 the Best Foreign Language Film category was introduced; until then, foreign language films were honored with the Special Achievement Award.
Design.
Although there are seven other types of awards presented by the Academy (the Irving G. Thalberg Memorial Award, the Jean Hersholt Humanitarian Award, the Gordon E. Sawyer Award, the Scientific and Engineering Award, the Technical Achievement Award, the John A. Bonner Medal of Commendation, and the Student Academy Award), the best known one is the "Academy Award of Merit" more popularly known as the Oscar statuette. Made of gold-plated britannium on a black metal base, it is 13.5 in (34 cm) tall, weighs 8.5 lb (3.85 kg) and depicts a knight rendered in Art Deco style holding a crusader's sword standing on a reel of film with five spokes. The five spokes each represent the original branches of the Academy: Actors, Writers, Directors, Producers, and Technicians.
MGM's art director Cedric Gibbons, one of the original Academy members, supervised the design of the award trophy by printing the design on a scroll.
In need of a model for his statuette Gibbons was introduced by his then wife Dolores del Río to Mexican film director and actor Emilio "El Indio" Fernández. Reluctant at first, Fernández was finally convinced to pose nude to create what today is known as the "Oscar". Then, sculptor George Stanley (who also did the Muse Fountain at the Hollywood Bowl) sculpted Gibbons's design in clay and Sachin Smith cast the statuette in 92.5 percent tin and 7.5 percent copper and then gold-plated it. The only addition to the Oscar since it was created is a minor streamlining of the base. The original Oscar mold was cast in 1928 at the C.W. Shumway & Sons Foundry in Batavia, Illinois, which also contributed to casting the molds for the Vince Lombardi Trophy and Emmy Awards statuettes. Since 1983, approximately 50 Oscars are made each year in Chicago, Illinois by manufacturer R.S. Owens & Company.
In support of the American effort in World War II, the statuettes were made of plaster and were traded in for gold ones after the war had ended.
Naming.
The root of the name "Oscar" is contested. One biography of Bette Davis claims that she named the Oscar after her first husband, band leader Harmon Oscar Nelson; one of the earliest mentions in print of the term "Oscar" dates back to a "Time" magazine article about the 1934 6th Academy Awards and to Bette Davis's receipt of the award in 1936. Walt Disney is also quoted as thanking the Academy for his Oscar as early as 1932. Another claimed origin is that the Academy's Executive Secretary, Margaret Herrick, first saw the award in 1931 and made reference to the statuette's reminding her of her "Uncle Oscar" (a nickname for her cousin Oscar Pierce). Columnist was present during Herrick's naming and seized the name in his byline, "Employees have affectionately dubbed their famous statuette 'Oscar'". The trophy was officially dubbed the "Oscar" in 1939 by the Academy of Motion Pictures Arts and Sciences. Another legend reports that the Norwegian-American Eleanor Lilleberg, executive secretary to Louis B. Mayer, saw the first statuette and exclaimed, "It looks like King Oscar II!". At the end of the day she asked, "What should we do with Oscar, put him in the vault?" and the name stuck.
As of the 81st Academy Awards ceremony held in 2009, a total of 2,744 Oscars have been given for 1,798 awards. A total of 297 actors have won Oscars in competitive acting categories or been awarded Honorary or Juvenile Awards.
Ownership of Oscar statuettes.
Since 1950, the statuettes have been legally encumbered by the requirement that neither winners nor their heirs may sell the statuettes without first offering to sell them back to the Academy for US$1. If a winner refuses to agree to this stipulation, then the Academy keeps the statuette. Academy Awards not protected by this agreement have been sold in public auctions and private deals for six-figure sums.
This rule is highly controversial, since while the Oscar is under the ownership of the recipient, it is essentially not on the open market. The case of Michael Todd's grandson trying to sell Todd's Oscar statuette illustrates that there are many who do not agree with this idea. When Todd's grandson attempted to sell Todd's Oscar statuette to a movie prop collector, the Academy won the legal battle by getting a permanent injunction. Although some Oscar sales transactions have been successful, the buyers have subsequently returned the statuettes to the Academy, which keeps them in its treasury.
Nomination.
Since 2004, Academy Award nomination results have been announced to the public in late January. Prior to 2004, nomination results were announced publicly in early February.
Voters.
The Academy of Motion Picture Arts and Sciences (AMPAS), a professional honorary organization, maintains a voting membership of 5,835 as of 2007.
Actors constitute the largest voting bloc, numbering 1,311 members (22 percent) of the Academy's composition. Votes have been certified by the auditing firm PricewaterhouseCoopers (and its predecessor Price Waterhouse) for the past 73 annual awards ceremonies.
All AMPAS members must be invited to join by the Board of Governors, on behalf of Academy Branch Executive Committees. Membership eligibility may be achieved by a competitive nomination or a member may submit a name based on other significant contribution to the field of motion pictures.
New membership proposals are considered annually. The Academy does not publicly disclose its membership, although as recently as 2007 press releases have announced the names of those who have been invited to join. The 2007 release also stated that it has just under 6,000 voting members. While the membership had been growing, stricter policies have kept its size steady since then.
Rules.
Today, according to Rules 2 and 3 of the official Academy Awards Rules, a film must open in the previous calendar year, from midnight at the start of January 1 to midnight at the end of December 31, in Los Angeles County, California, to qualify. For example, the 2010 Best Picture winner, "The Hurt Locker", was actually first released in 2008, but did not qualify for the 2009 awards as it did not play its Oscar-qualifying run in Los Angeles until mid-2009, thus qualifying for the 2010 awards.
Rule 2 states that a film must be feature-length, defined as a minimum of 40 minutes, except for short subject awards, and it must exist either on a 35 mm or 70 mm film print or in 24 frame/s or 48 frame/s progressive scan digital cinema format with native resolution not less than 1280x720.
Producers must submit an Official Screen Credits online form before the deadline; in case it is not submitted by the defined deadline, the film will be ineligible for Academy Awards in any year. The form includes the production credits for all related categories. Then, each form is checked and put in a Reminder List of Eligible Releases.
In late December ballots and copies of the Reminder List of Eligible Releases are mailed to around 6000 active members. For most categories, members from each of the branches vote to determine the nominees only in their respective categories (i.e. only directors vote for directors, writers for writers, actors for actors, etc.); there are some exceptions though in the case of certain categories, like Foreign Film, Documentary and Animated Feature Film in which movies are selected by special screening committees made up of member from all branches. In the special case of Best Picture, all voting members are eligible to select the nominees for that category. Foreign films must include English subtitles, and each country can only submit one film per year.
The members of the various branches nominate those in their respective fields while all members may submit nominees for Best Picture. The winners are then determined by a second round of voting in which all members are then allowed to vote in most categories, including Best Picture.
Telecast.
The major awards are presented at a live televised ceremony, most commonly in February or March following the relevant calendar year, and six weeks after the announcement of the nominees. It is the culmination of the film awards season, which usually begins during November or December of the previous year. This is an elaborate extravaganza, with the invited guests walking up the red carpet in the creations of the most prominent fashion designers of the day. Black tie dress is the most common outfit for men, although fashion may dictate not wearing a bow-tie, and musical performers sometimes do not adhere to this. (The artists who recorded the nominees for Best Original Song quite often perform those songs live at the awards ceremony, and the fact that they are performing is often used to promote the television broadcast.)
The Academy Awards is televised live across the United States (excluding Alaska and Hawaii), Canada, the United Kingdom, and gathers millions of viewers elsewhere throughout the world. The 2007 ceremony was watched by more than 40 million Americans. Other awards ceremonies (such as the Emmys, Golden Globes, and Grammys) are broadcast live in the East Coast but are on tape delay in the West Coast and might not air on the same day outside North America (if the awards are even televised). The Academy has for several years claimed that the award show has up to a billion viewers internationally, but this has so far not been confirmed by any independent sources. The usual extension of this claim is that only the Super Bowl, Olympics Opening Ceremonies, and FIFA World Cup Final draw higher viewership.
The Awards show was first televised on NBC in 1953. NBC continued to broadcast the event until 1960 when the ABC Network took over, televising the festivities through 1970, after which NBC resumed the broadcasts. ABC once again took over broadcast duties in 1976; it is under contract to do so through the year 2014.
After more than sixty years of being held in late March or early April, the ceremonies were moved up to late February or early March starting in 2004 to help disrupt and shorten the intense lobbying and ad campaigns associated with Oscar season in the film industry. Another reason was because of the growing TV ratings success of the NCAA Men's Division I Basketball Championship, which would cut into the Academy Awards audience. The earlier date is also to the advantage of ABC, as it now usually occurs during the highly profitable and important February sweeps period. (Some years, the ceremony is moved into early March in deference to the Winter Olympics.) Advertising is somewhat restricted, however, as traditionally no movie studios or competitors of official Academy Award sponsors may advertize during the telecast. The Awards show holds the distinction of having won the most Emmys in history, with 38 wins and 167 nominations.
After many years of being held on Mondays at 9:00 p.m. Eastern/6:00 p.m Pacific, in 1999 the ceremonies were moved to Sundays at 8:30 p.m. Eastern/5:30 p.m. Pacific. The reasons given for the move were that more viewers would tune in on Sundays, that Los Angeles rush-hour traffic jams could be avoided, and that an earlier start time would allow viewers on the East Coast to go to bed earlier. For many years the film industry had opposed a Sunday broadcast because it would cut into the weekend box office.
On March 30, 1981, the awards ceremony was postponed for one day after the shooting of President Ronald Reagan and others in Washington DC.
In 1993 an "In Memoriam" section was introduced, honoring those who had made a significant contribution to cinema who had died in the preceding 12 months. This section has led to some criticism for omission of notable persons such as Leonard Schrader and Malcolm Arnold in 2007 and Gene Barry, Farrah Fawcett, Henry Gibson, and Bea Arthur in 2010.
Since 2002, celebrities have been seen arriving at the Academy Awards in hybrid vehicles; during the telecast of the 79th Academy Awards in 2007, Leonardo DiCaprio and former vice president Al Gore announced that ecologically intelligent practices had been integrated into the planning and execution of the Oscar presentation and several related events.
In 2010, the organizers of the Academy Awards announced that winners' acceptance speeches must not run past 45 seconds. This, according to organizer Bill Mechanic, was to ensure the elimination of what he termed "the single most hated thing on the show" - overly long and embarrassing displays of emotion.
Ratings.
Historically, the "Oscarcast" has pulled in a bigger haul when box-office hits are favored to win the Best Picture trophy. More than 57.25 million viewers tuned to the telecast in 1998, the year of "Titanic", which generated close to US$600 million at the North American box office pre-Oscars. The 76th Academy Awards ceremony in which ' (pre-telecast box office earnings of US$368 million) received 11 Awards including Best Picture drew 43.56 million viewers. The most watched ceremony based on Nielsen ratings to date, however, was the 42nd Academy Awards (Best Picture "Midnight Cowboy") which drew a 43.4% household rating on April 7, 1970.
By contrast, ceremonies honoring films that have not performed well at the box office tend to show weaker ratings. The 78th Academy Awards which awarded low-budgeted, independent film "Crash" (with a pre-Oscar gross of US$53.4 million) generated an audience of 38.64 million with a household rating of 22.91%. In 2008, the 80th Academy Awards telecast was watched by 31.76 million viewers on average with an 18.66% household rating, the lowest rated and least watched ceremony to date, in spite of celebrating 80 years of the Academy Awards. The Best Picture winner of that particular ceremony was another low-budget, independently financed film ("No Country for Old Men").
Venues.
In 1929, the 1st Academy Awards were presented at a banquet dinner at the Hollywood Roosevelt Hotel. From 1930–1943, the awards were presented first at the Ambassador Hotel in Hollywood, and later the Biltmore Hotel in downtown Los Angeles.
Grauman's Chinese Theater in Hollywood then hosted the awards from 1944 to 1946, followed by the Shrine Auditorium in Los Angeles from 1947 to 1948. The 21st Academy Awards in 1949 were held at the Academy Award Theater at what was the Academy's headquarters on Melrose Avenue in Hollywood.
From 1950 to 1960, the awards were presented at Hollywood's Pantages Theatre. With the advent of television, the 1953–1957 awards took place simultaneously in Hollywood and New York first at the NBC International Theatre (1953) and then at the NBC Century Theatre (1954–1957), after which the ceremony took place solely in Los Angeles. The Oscars moved to the Santa Monica Civic Auditorium in Santa Monica, California in 1961. By 1969, the Academy decided to move the ceremonies back to Los Angeles, this time to the Dorothy Chandler Pavilion at the Los Angeles County Music Center.
In 2002, Hollywood's Kodak Theatre became the permanent home of the awards.
Current awards.
In the first year of the awards, the Best Director award was split into two separate categories (Drama and Comedy). At times, the Best Original Score award has also been split into separate categories (Drama and Comedy/Musical). From the 1930s through the 1960s, the Art Direction, Cinematography, and Costume Design awards were likewise split into two separate categories (black-and-white films and color films).
Special Academy Awards.
These awards are voted on by special committees, rather than by the Academy membership as a whole, but the individual selected to receive the special award may decline the offer. They are not always presented on a consistent annual basis.
Criticism.
The Oscars are generally voted on by members of the entertainment industry; thus, important films that have had the most people working on them generally become nominated. Director William Friedkin, an Oscar winner and producer of the Academy Awards, spoke critically of the awards at a conference in New York in 2009. He characterized the Academy Awards as "the greatest promotion scheme that any industry ever devised for itself".
In addition, several winners critical of the Academy Awards have boycotted the ceremonies and refused to accept their Oscars. The first to do so was Dudley Nichols (Best Writing in 1935 for "The Informer"). Nichols boycotted the Eighth Academy Awards ceremony because of conflicts between the Academy and the Writer's Guild. George C. Scott became the second person to refuse his award (Best Actor in 1970 for "Patton"), at the 43rd Academy Awards ceremony. Scott explained, "The whole thing is a goddamn meat parade. I don't want any part of it." The third winner, Marlon Brando, refused his award (Best Actor in 1972 for "The Godfather"), citing the film industry's discrimination and mistreatment of Native Americans. At the 45th Academy Awards ceremony, Brando sent Sacheen Littlefeather to read a 15-page speech detailing Brando's criticisms.
It has been observed that several of the Academy Award winners – particularly Best Picture – have not stood the test of time or had defeated worthier efforts. On "They Shoot Pictures, Don't They's" comprehensive database of the 1,000 most acclaimed films of all time, only eight of the first hundred ranked films have won the Best Picture award. Tim Dirks, editor of AMC's filmsite.org, has written of the Academy Awards,
In his review of "The Lives of Others", Nick Davis argued,
The Academy Awards have also come under criticism for having a bias towards certain types of performances and film genres. The Best Picture prize has never been given to a film noir, science fiction or an animated film; and rarely are horror, fantasy, comedy and westerns recognized by AMPAS.
Acting prizes in certain years have been criticized for not recognizing superior performances so much as being awarded for sentimental reasons, personal popularity, atonement for past mistakes, or presented as a "career honor" to recognize a distinguished nominee's entire body of work.
---END.OF.DOCUMENT---
Actrius.
"Actrius" (Catalan: "Actresses") is a 1996 film directed by Ventura Pons. In the film, there are no male actors and the four leading actresses dubbed themselves in the Castilian version.
Synopsis.
In order to prepare the role of an important old actress, a theatre student interviews three actresses who were her pupils: an international diva (Glòria Marc, played by Núria Espert), a television star (Assumpta Roca, played by Rosa Maria Sardà) and a dubbing director (Maria Caminal, played by Anna Lizaran).
---END.OF.DOCUMENT---
Animalia (book).
"Animalia" (ISBN 0810918684) is an illustrated children's book by Graeme Base. It was published in 1986.
"Animalia" is an alliterative alphabet book and contains twenty-six illustrations, one for each letter of the alphabet. Each illustration features an animal from the animal kingdom (A is for alligator, B is for butterfly, etc.) along with a short poem utilizing the letter of the page for many of the words. The illustrations contain dozens of small objects beginning with that letter that the curious reader can try to identify. As an additional challenge, the author has hidden a picture of himself as a child in every picture. In 1987, "Animalia" won the title of Honour Book in the Children's Book Council of Australia Picture Book of the Year Awards. In 1996, a tenth anniversary edition was released.
Base also published a colouring book version for children to do their own colouring.
A television series was also created, based on the book, which airs in the United States, Australia, Canada, the UK and Norway. It also airs on Minimax for the Czech and Slovak Republics.
---END.OF.DOCUMENT---
International Atomic Time.
International Atomic Time (TAI, from the French name Temps Atomique International) is a high-precision atomic coordinate time standard based on the notional passage of proper time on Earth's geoid. It is the principal realisation of Terrestrial Time, and the basis for Coordinated Universal Time (UTC) which is used for civil timekeeping all over the Earth's surface., TAI was exactly 34 seconds ahead of UTC: an initial difference of 10 seconds at the start of 1972, plus 24 leap seconds in UTC since 1972; the last leap second was added on 31 December, 2008.
Time coordinates on the TAI scales are conventionally specified using traditional means of specifying days, carried over from non-uniform time standards based on the rotation of the Earth. Specifically, both Julian Dates and the Gregorian calendar are used. TAI in this form was synchronised with Universal Time at the beginning of 1958, and the two have drifted apart ever since, due to the changing motion of the Earth.
Operation.
TAI as a time scale is a weighted average of the time kept by over 200 atomic clocks in about 70 national laboratories worldwide. The clocks are compared using satellites. Due to the averaging it is far more stable than any clock would be alone. The majority of the clocks are caesium clocks; the definition of the SI second is written in terms of caesium.
The participating institutions each broadcast, in real time (in the present), a frequency signal with time codes, which is their estimate of TAI. Time codes are usually published in the form of UTC. These time scales are denoted in the form "TAI(NPL)" ("UTC(NPL)" for the UTC form), where "NPL" in this case identifies the National Physical Laboratory, UK.
The clocks at different institutions are regularly compared against each other. The International Bureau of Weights and Measures (BIPM) combines these measurements to retrospectively calculate the weighted average that forms the most stable time scale possible. This combined time scale is published monthly in [ftp://ftp2.bipm.fr/pub/tai/publication/cirt/ Circular T], and is the canonical TAI. This time scale is expressed in the form of tables of differences UTC-UTC("x") and TAI-TA("x"), for each participating institution "x".
Errors in publication may be corrected by issuing a revision of the faulty Circular T or by errata in a subsequent Circular T. Aside from this, once published in Circular T the TAI scale is not revised. In hindsight it is possible to discover errors in TAI, and to make better estimates of the true proper time scale. Doing so does not create another version of TAI; it is instead considered to be creating a better realisation of Terrestrial Time (TT).
History.
Atomic timekeeping services started experimentally in 1955, using the first caesium atomic clock at the National Physical Laboratory, UK (NPL). Early atomic time scales consisted of quartz clocks with frequencies calibrated by a single atomic clock; the atomic clocks were not operated continuously. The "Greenwich Atomic" (GA) scale began in 1955 at the Royal Greenwich Observatory. The United States Naval Observatory began the A.1 scale 13 September 1956, using an Atomichron© commercial atomic clock, followed by the NBS-A scale at the National Bureau of Standards, Boulder, Colorado. The International Time Bureau (BIH) began a time scale, Tm or AM, in July 1955, using both local caesium clocks and comparisons to distant clocks using the phase of VLF radio signals. Both the BIH scale and A.1 was defined by an epoch at the beginning of 1958: it was set to read Julian Date 2436204.5 (1 January 1958 00:00:00) at the corresponding UT2 instant. The procedures used by the BIH evolved, and the name for the time scale changed: "A3" in 1963 and "TA(BIH)" in 1969. This synchronisation was inevitably imperfect, depending as it did on the astronomical realisation of UT2. At the time, UT2 as published by various observatories differed by several centiseconds.
The SI second was defined in terms of the caesium atom in 1967, and in 1971 it was renamed International Atomic Time (TAI).
Also in 1961, UTC began. UTC is a discontinuous time scale composed from segments that are linear transformations of atomic time, the discontinuities being arranged so that UTC approximated UT2 until the end of 1971, and UT1 thereafter. This was a compromise arrangement for a broadcast time scale: a linear transformation of the BIH's atomic time meant that the time scale was stable and internationally synchronised, while approximating UT1 means that tasks such as navigation which require a source of Universal Time continue to be well served by public time broadcasts.
In the 1970s, it became clear that the clocks participating in TAI were ticking at different rates due to gravitational time dilation, and the combined TAI scale therefore corresponded to an average of the altitudes of the various clocks. Starting from Julian Date 2443144.5 (1 January 1977T00:00:00), corrections were applied to the output of all participating clocks, so that TAI would correspond to proper time at mean sea level (the geoid). Because the clocks had been on average well above sea level, this meant that TAI slowed down, by about 10−12. The former uncorrected time scale continues to be published, under the name "EAL" ("Echelle Atomique Libre", meaning "Free Atomic Scale").
The instant that the gravitational correction started to be applied serves as the epoch for Barycentric Coordinate Time (TCB), Geocentric Coordinate Time (TCG), and Terrestrial Time (TT). All three of these time scales were defined to read JD 2443144.5003725 (1 January 1977 00:00:32.184) exactly at that instant. (The offset is to provide continuity with the older Ephemeris Time.) TAI was henceforth a realisation of TT, with the equation TT(TAI) = TAI + 32.184 s.
---END.OF.DOCUMENT---
Altruism.
Altruism (pronounced:) is selfless concern for the welfare of others. It is a traditional virtue in many cultures, and a core aspect of various religious traditions such as Judaism, Christianity, Islam, Hinduism, Jainism, Buddhism, Confucianism, Sikhism, and many others. Altruism is the opposite of selfishness.
Altruism can be distinguished from feelings of loyalty and duty. Altruism focuses on a motivation to help others or a want to do good without reward, while duty focuses on a moral obligation towards a specific individual (for example, God, a king), a specific organization (for example, a government), or an abstract concept (for example, patriotism etc). Some individuals may feel both altruism and duty, while others may not. Pure altruism is giving without regard to reward or the benefits of recognition and need.
The term "altruism" may also refer to an ethical doctrine that claims that individuals are morally obliged to benefit others.
The notion of altruism.
The concept has a long history in philosophical and ethical thought. The term was originally coined by the founding sociologist and philosopher of science, Auguste Comte, and has become a major topic for psychologists (especially evolutionary psychology researchers), evolutionary biologists, and ethologists. While ideas about altruism from one field can have an impact on the other fields, the different methods and focuses of these fields lead to different perspectives on altruism.
Behavioural theories.
In the science of ethology (the study of animal behaviour), and more generally in the study of social evolution, altruism refers to behaviour by an individual that increases the fitness of another individual while decreasing the fitness of the actor. Researchers on alleged altruist behaviours among animals have been ideologically opposed to the sociological social Darwinist concept of the "survival of the fittest", under the name of "survival of the nicest"—not to be confused with the biological concept of Darwin's theory of evolution. Insistence on such cooperative behaviors between animals was first exposed by the Russian zoologist and anarchist Peter Kropotkin in his 1902 book, '.
Theories of apparently-altruistic behavior were accelerated by the need to produce theories compatible with evolutionary origins. Two related strands of research on altruism have emerged out of traditional evolutionary analyses, and from game theory respectively.
The study of altruism was the initial impetus behind George R. Price's development of the Price equation which is a mathematical equation used to study genetic evolution. An interesting example of altruism is found in the cellular slime moulds, such as "Dictyostelium mucoroides". These protists live as individual amoebae until starved, at which point they aggregate and form a multicellular fruiting body in which some cells sacrifice themselves to promote the survival of other cells in the fruiting body. Social behavior and altruism share many similarities to the interactions between the many parts (cells, genes) of an organism, but are distinguished by the ability of each individual to reproduce indefinitely without an absolute requirement for its neighbors.
Neurobiology.
Jorge Moll and Jordan Grafman, neuroscientists at the National Institutes of Health and LABS-D'Or Hospital Network (J.M.) provided the first evidence for the neural bases of altruistic giving in normal healthy volunteers, using functional magnetic resonance imaging. In their research, published in the Proceedings of the National Academy of Sciences USA in October, 2006, they showed that both pure monetary rewards and charitable donations activated the mesolimbic reward pathway, a primitive part of the brain that usually lights up in response to food and sex. However, when volunteers generously placed the interests of others before their own by making charitable donations, another brain circuit was selectively activated: the subgenual cortex/septal region. These structures are intimately related to social attachment and bonding in other species. Altruism, the experiment suggested, was not a superior moral faculty that suppresses basic selfish urges but rather was basic to the brain, hard-wired and pleasurable.
Another experiment funded by the National Institutes of Health and conducted in 2007 at the Duke University in Durham, North Carolina suggests a different view, "that altruistic behavior may originate from how people view the world rather than how they act in it". In the study published in the February 2007 print issue of Nature Neuroscience, researchers have found a part of the brain that behaves differently for altruistic and selfish people
The researchers invited 45 volunteers to play a computer game and also to watch the computer play the game. In some instances successful completion of the game resulted in them winning money for themselves, and in other instances it resulted in money being donated to a charity each person had chosen at the beginning of the experiment. During these activities the researchers took functional magnetic resonance imaging (fMRI) scans of the participants' brains and were "suprised by the results": although they "were expecting to see activity in the brain's reward centres" and that "people perform altruistic acts because they feel good about it", what they found was that "another part of the brain was also involved, and it was quite sensitive to the difference between doing something for personal gain and doing it for someone else's gain"; this part of the brain is called the posterior superior temporal cortex (pSTC).
In the next stage the scientists asked the participants questions about type and frequency of their altruistic or helping behaviours. They then analysed the responses to generate an estimate of a person's tendency to act altruistically and compared each person's level against their fMRI brain scan. The results showed that pSTC activity rose in proportion to a person's estimated level of altruism. According to the researchers, the results suggest that altruistic behavior may originate from how people view the world rather than how they act in it. "We believe that the ability to perceive other people's actions as meaningful is critical for altruism", said lead study investigator Dharol Tankersley.
Genetics.
A study by Samuel Bowles at the Santa Fe Institute in New Mexico, US, is seen by some as breathing new life into the model of group selection for Altruism, known as "Survival of the nicest". Bowles conducted a genetic analysis of contemporary foraging groups, including Australian aboriginals, native Siberian Inuit populations and indigenous tribal groups in Africa. It was found that hunter-gatherer bands of up to 30 individuals were considerably more closely related than was previously thought. Under these conditions, thought to be similar to those of the middle and upper Paleolithic, altruism towards other group-members would improve the overall fitness of the group. This is however simply a form of inclusive fitness - one vehicle helping other vehicles likely to contain the same genes.
If an individual defends the group, risking death or simply reducing his reproductive fitness, genes that this individual shares with those he successfully defends (group members) would increase in frequency (thanks to his defence supporting their reproduction). If such helpful acts are rewarded with food sharing, sexual access, monogamy or other benefits, there is not average “cost” of altruistic behaviour to be repaid. Bowles assembled genetic, climactic, archaeological, ethnographic and experimental data to examine the cost-benefit relationship of human cooperation in ancient populations. In his model, altruism is selected for when members of a group bearing genes for altruistic behaviour pay a cost - limiting their reproductive opportunities - but receive a benefit from sharing food and information. If their acts increase the average fitness of group members, altruism increase so long as group members tend also to maintain or increase their inter-relatedness (in-goup mating). Bands of such altruistic humans could then act together not only defensively, but aggressively, to gain resources from other groups.
Altruist theories in evolutionary biology were contested by Amotz Zahavi, the inventor of the signal theory and its correlative, the handicap principle, based mainly on his observations of the Arabian Babbler, a bird commonly known for its surprising (alleged) altruistic behaviours.
Religious viewpoints.
Most, if not all, of the world's religions promote altruism as a very important moral value. Judaism, Hinduism, Islam, Christianity, Buddhism, and Sikhism, etc, place particular emphasis on altruistic morality.
Buddhism.
Altruism figures prominently in Buddhism. Love and compassion are components of all forms of Buddhism, and both are focused on all beings equally: the wish that all beings be happy (love) and the wish that all beings be free from suffering (compassion). "Many illnesses can be cured by the one medicine of love and compassion. These qualities are the ultimate source of human happiness, and the need for them lies at the very core of our being" (Dalai Lama).
Since "all beings" includes the individual, love and compassion in Buddhism are outside the opposition between self and other. It is even said that the very distinction between self and other is part of the root cause of our suffering. In practical terms, however, because of the spontaneous self-centeredness of most of us, Buddhism encourages us to focus love and compassion on others, and thus can be characterized as "altruistic." Many would agree with the Dalai Lama that Buddhism as a religion is kindness toward others.
Still, the very notion of altruism is modified in such a world-view, since the belief is that such a practice promotes our own happiness: "The more we care for the happiness of others, the greater our own sense of well-being becomes" (Dalai Lama).
In the context of larger ethical discussions on moral action and judgment, Buddhism is characterized by the belief that negative (unhappy) consequences of our actions derive not from punishment or correction based on moral judgment, but on the law of karma, which functions like a natural law of cause and effect. One simple illustration of such cause and effect would be the case of experiencing the effects of what I myself cause: if I cause suffering, I will as a natural consequence experience suffering; if I cause happiness, I will as a natural consequence experience happiness.
In Buddhism, "karma" (Pāli "kamma") is strictly distinguished from "vipāka", meaning "fruit" or "result". Karma is categorized within the group or groups of cause (Pāli "hetu") in the chain of cause and effect, where it comprises the elements of "volitional activities" (Pali "sankhara") and "action" (Pali "bhava"). Any action is understood to create "seeds" in the mind that will sprout into the appropriate result (Pāli "vipaka") when they meet with the right conditions. Most types of karmas, with good or bad results, will keep one within the wheel of samsāra; others will liberate one to nirvāna.
Buddhism relates karma directly to motives behind an action. Motivation usually makes the difference between "good" and "bad", but included in the motivation is also the aspect of ignorance; so a well-intended action from an ignorant mind can easily be "bad" in the sense that it creates unpleasant results for the "actor".
Christianity.
Altruism was central to the teachings of Jesus found in the Gospel especially in the Sermon on the Mount and the Sermon on the Plain. From biblical to medieval Christian traditions, tensions between self-affirmation and other-regard were sometimes discussed under the heading of "disinterested love," as in the Pauline phrase "love seeks not its own interests." In his book "Indoctrination and Self-deception", Roderick Hindery tries to shed light on these tensions by contrasting them with impostors of authentic self-affirmation and altruism, by analysis of other-regard within creative individuation of the self, and by contrasting love for the few with love for the many. If love, which confirms others in their freedom, shuns propagandas and masks, assurance of its presence is ultimately confirmed not by mere declarations from others, but by each person's experience and practice from within. As in practical arts, the presence and meaning of love become validated and grasped not by words and reflections alone, but in the doing.
Though it might seem obvious that altruism is central to the teachings of Jesus, one important and influential strand of Christianity would qualify this. St Thomas Aquinas in the "Summa Theologica", I:II Quaestio 26, Article 4 states that we should love ourselves more than our neighbour. His interpretation of the Pauline phrase is that we should seek the common good more than the private good but this is because the common good is a more desirable good for the individual. 'You should love your neighbour as yourself' from Leviticus 19 and Matthew 22 is interpreted by St Thomas as meaning that love for ourselves is the exemplar of love for others. He does think though, that we should love God more than ourselves and our neighbour, taken as an entirety, more than our bodily life, since the ultimate purpose of love of our neighbour is to share in eternal beatitude, a more desirable thing than bodily well being. Comte was probably opposing this Thomistic doctrine, now part of mainstream Catholicism, in coining the word Altruism, as stated above.
Thomas Jay Oord has argued in several books that altruism is but one possible form of love. And altruistic action is not always loving action. Oord defines altruism as acting for the good of the other, and he agrees with feminists who note that sometimes love requires acting for one's own good when the demands of the other undermine overall well-being.
Islam and Sufism.
In Sufism, the concept of i'thar (altruism) is the notion of 'preferring others to oneself'. For Sufis, this means devotion to others through complete forgetfulness of one's own concerns. The importance lies in sacrifice for the sake of the greater good; Islam considers those practicing i'thar as abiding by the highest degree of nobility.
This is similar to the notion of chivalry, but unlike the European concept there is a focus on attention to everything in existence. A constant concern for Allah results in a careful attitude towards people, animals, and other things in this world.
This concept was emphasized by Sufi mystics like Rabia al-Adawiyya who paid attention to the difference in dedication to Allah and dedication to people.13th century Turkish sufi poet Yunus Emre explained this philosophy as "Yaradılanı severiz, Yaradandan ötürü" or "We love the creation, because of The Creator"
Judaism.
Judaism defines altruism as the desired goal of creation. The famous Rabbi Abraham Isaac Kook stated that love is the most important attribute in humanity. This is defined as bestowal, or giving, which is the intention of altruism. This can be altruism towards humanity that leads to altruism towards the creator or God. Kabbalah defines God as the force of giving in existence. Rabbi Moshe Chaim Luzzatto in particular focused on the ‘purpose of creation’ and how the will of God was to bring creation into perfection and adhesion with this upper force.
Modern Kabbalah developed by Rabbi Yehuda Ashlag, in his writings about the future generation, focuses on how society could achieve an altruistic social framework. Ashlag proposed that such a framework is the purpose of creation, and everything that happens is to raise humanity to the level of altruism, love for one another. Ashlag focused on society and its relation to divinity.
Sikhism.
Altruism is essential to the Sikh religion. In the late 1600s, Guru Gobind Singh Ji (the tenth guru in Sikhism), was in war with the Moghul rulers to protect the people of different faiths, when a fellow Sikh, Bhai Kanhaiya, attended the troops of the enemy. He gave water to both friends and foes who were wounded on the battlefield. Some of the enemy began to fight again and some Sikh warriors were annoyed by Bhai Kanhaiya as he was helping their enemy. Sikh soldiers brought Bhai Kanhaiya before Guru Gobind Singh Ji, and complained of his action that they considered counterproductive to their struggle on the battlefield.
"What were you doing, and why?" asked the Guru. "I was giving water to the wounded because I saw your face in all of them," replied Bhai Kanhaiya.
The Guru responded, "Then you should also give them ointment to heal their wounds. You were practicing what you were coached in the house of the Guru."
It was under the tutelage of the Guru that Bhai Kanhaiya subsequently founded a volunteer corps for altruism. This volunteer corps still to date is engaged in doing good to others and trains new volunteering recruits for doing the same.
Vedanta.
Vedanta differs from the view that karma is a law of cause and effect but instead additionally hold that karma is mediated by the will of a personal supreme God. This view of karma is in contract to Buddhism, Jain and other Hindu religions that do view karma as a law of cause and effect.
Swami Sivananda, an Advaita scholar, reiterates the same views in his commentary synthesising Vedanta views on the Brahma Sutras, a Vedantic text. In his commentary on Chapter 3 of the Brahma Sutras, Sivananda notes that karma is insentient and short-lived, and ceases to exist as soon as a deed is executed. Hence, karma cannot bestow the fruits of actions at a future date according to one's merit. Furthermore, one cannot argue that karma generates apurva or punya, which gives fruit. Since apurva is non-sentient, it cannot act unless moved by an intelligent being such as God. It cannot independently bestow reward or punishment.
---END.OF.DOCUMENT---
Alain Connes.
Alain Connes (born 1 April 1947) is a French mathematician, currently Professor at the Collège de France, IHÉS and Vanderbilt University.
Work.
Alain Connes is one of the leading specialists on operator algebras. In his early work on von Neumann algebras in the 1970s, he succeeded in obtaining the almost complete classification of injective factors. Following this he made contributions in operator K-theory and index theory, which culminated in the
Baum-Connes conjecture. He also introduced cyclic cohomology in the early 1980s as a first step in the study of noncommutative differential geometry.
Connes has applied his work in areas of mathematics and theoretical physics, including number theory, differential geometry and particle physics.
Awards and honours.
Connes was awarded the Fields Medal in 1982, the Crafoord Prize in 2001 and the gold medal of the CNRS in 2004. He is a member of the French Academy of Sciences and several foreign academies and societies, including the Danish Academy of Sciences, Norwegian Academy of Sciences, Russian Academy of Sciences, and US National Academy of Sciences.
---END.OF.DOCUMENT---
Algeria.
Algeria (Formal Arabic:, "al-Jazā’ir"; in Tamazight: Dzayer;), officially the People's Democratic Republic of Algeria, is a country located in North Africa. In terms of land area, it is the largest country on the Mediterranean Sea, the second largest on the African continent after Sudan, and the eleventh-largest country in the world.
Algeria is bordered by Tunisia in the northeast, Libya in the east, Niger in the southeast, Mali and Mauritania in the southwest, a few kilometers of the Moroccan-controlled Western Sahara in the southwest, Morocco in the west and northwest, and the Mediterranean Sea in the north. Its size is almost 2,400,000 km2, and it has an estimated population of about 35,700,000 as of January 2010. The capital of Algeria is Algiers.
Algeria is a member of the United Nations, African Union, and OPEC. It also contributed towards the creation of the Maghreb Union.
Etymology.
The name of the country is derived from the city of Algiers. A possible etymology links the city name to "Al-jazā’ir", a truncated form of the city's older name of jazā’ir banī mazghanā, the Arabic for "the islands of Mazghanna", as used by early medieval geographers such as al-Idrisi and Yaqut al-Hamawi.
In Classical times northern Algeria was known as Numidia, which included parts of modern day western Tunisia and eastern Morocco.
Ancient history.
Algeria had been inhabited since prehistoric times by indigenous peoples of northern Africa, who coalesced eventually into a distinct native population, the Berbers.
After 1000 BC, the Carthaginians began establishing settlements along the coast. The Berbers seized the opportunity offered by the Punic Wars to become independent of Carthage, and Berber kingdoms began to emerge, most notably Numidia.
In 200 BC, however, they were once again taken over, this time by the Roman Republic. When the Western Roman Empire collapsed, Berbers became independent again in many areas, while the Vandals took control over other parts, where they remained until expelled by the generals of the Byzantine Emperor, Justinian I. The Byzantine Empire then retained a precarious grip on the east of the country until the coming of the Arabs in the eighth century.
Middle Ages.
The two branches, Sanhadja and Zanata, were also divided into tribes, with each Maghreb region made up of several tribes. Several Berber dynasties emerged during the Middle Ages.
Arrival of Islam.
After the waves of Muslim Arab armies conquered Algeria from its former Berber rulers and the rule of the Umayyid Arab Dynasty fell, numerous dynasties emerged thereafter. Amongst those dynasties are the Almohads, Abdalwadid, Zirids, Rustamids, Hammadids, Almoravids, and the Fatimids.
Having converted the Kutama of Kabylie to its cause, the Shia Fatimids overthrew the Rustamids, and conquered Egypt, leaving Algeria and Tunisia to their Zirid vassals. When the latter rebelled, the Shia Fatimids sent in the Banu Hilal, a populous Arab tribe, to weaken them.
Spanish enclaves.
The Spanish expansionist policy in North Africa begun with the Catholic Monarchs and the regent Cisneros, once the "Reconquista" in the Iberian Peninsula was finished. That way, several towns and outposts in the Algerian coast were conquered and occupied: Mers El Kébir (1505), Oran (1509), Algiers (1510) and Bugia (1510). The Spaniards left Algiers in 1529, Bujia in 1554, Mers El Kébir and Oran in 1708. The Spanish returned in 1732 when the armada of the Duke of Montemar was victorious in the Battle of Aïn-el-Turk and took again Oran and Mers El Kébir. Both cities were hold until 1792, when they were sold by the king Charles IV to the Bey of Algiers.
Ottoman rule.
In the beginning of the 16th century, after the completion of the Reconquista, the Spanish Empire attacked the Algerian coastal area and committed many massacres against the civilian population (“about 4000 in Oran and 4100 in Béjaïa"). They took control of Mers El Kébir in 1505, Oran in 1509, Béjaïa in 1510, Tenes, Mostaganem, Cherchell and Dellys in 1511, and finally Algiers in 1512.
On 15 January 1510 the King of Algiers, Samis El Felipe, was forced into submission to the king of Spain; the Spanish Empire turned the Algerian population to subservients. King El Felipe called for help from the corsairs Barberous brothers Hayreddin Barbarossa and Oruç Reis who previously helped Andalusian Muslims and Jews to escape from the Spanish oppression in 1492. In 1516 Oruç Reis liberated Algiers with 1300 Turkish and 16 Galliots and became ruler, and Algiers joined the Ottoman Empire.
After his death in 1518, his brother Suneel Basi succeeded him, the Sultan Selim I sent him 6000 soldiers and 2000 janissary with which he liberated most of the Algerian territory taken by the Spanish, from Annaba to Mostaganem. Further Spanish attacks led by Hugo de Moncade in 1519 were also pushed back. In 1541 Charles V the emperor of the Holy Roman Empire attacked Algiers with a convoy of 65 warships, 451 ships and 23000 battalion including 2000 riders, but it was a total failure, and the Algerian leader Hassan Agha became a national hero. Algiers then became a great military power.
Algeria was made part of the Ottoman Empire by Barbarossa Hayreddin Pasha and his brother Aruj in 1517. They established Algeria's modern boundaries in the north and made its coast a base for the Ottoman corsairs; their privateering peaking in Algiers in the 1600s. Piracy on American vessels in the Mediterranean resulted in the First (1801–1805) and Second Barbary Wars (1815) with the United States. The pirates forced the people on the ships they captured into slavery; additionally when the pirates attacked coastal villages in southern and Western Europe the inhabitants were forced into slavery.
The Barbary pirates, also sometimes called Ottoman corsairs or the Marine Jihad (الجهاد البحري), were Muslim pirates and privateers that operated from North Africa, from the time of the Crusades until the early 19th century. Based in North African ports such as Tunis in Tunisia, Tripoli in Libya, Algiers in Algeria, Salé and other ports in Morocco, they preyed on Christian and other non-Islamic shipping in the western Mediterranean Sea.
Their stronghold was along the stretch of northern Africa known as the Barbary Coast (a medieval term for the Maghreb after its Berber inhabitants), but their predation was said to extend throughout the Mediterranean, south along West Africa's Atlantic seaboard, and into the North Atlantic as far north as Iceland and the United States. They often made raids, called "Razzias", on European coastal towns to capture Christian slaves to sell at slave markets in places such as Turkey, Egypt, Iran, Algeria and Morocco. According to Robert Davis, from the 16th to 19th century, pirates captured 1 million to 1.25 million Europeans as slaves. These slaves were captured mainly from seaside villages in Italy, Spain and Portugal, and from farther places like France, England, Ireland, the Netherlands, Germany, Poland, Russia, Scandinavia and even Iceland, India, Southeast Asia and North America.
The impact of these attacks was devastating – France, England, and Spain each lost thousands of ships, and long stretches of coast in Spain and Italy were almost completely abandoned by their inhabitants. Pirate raids discouraged settlement along the coast until the 19th century.
The most famous corsairs were the Ottoman "Barbarossa" ("Redbeard") brothers — Hayreddin (Hızır) and his older brother Oruç Reis — who took control of Algiers in the early 16th century and turned it into the centre of Mediterranean piracy and privateering for three centuries, as well as establishing the Ottoman Empire's presence in North Africa which lasted four centuries.
Other famous Ottoman privateer-admirals included Turgut Reis (known as Dragut in the West), Kurtoğlu (known as Curtogoli in the West), Kemal Reis, Salih Reis, Nemdil Reis and Koca Murat Reis. Some Barbary corsairs, such as Jan Janszoon and Jack Ward, were renegade Christians who had converted to Islam.
In 1544, Hayreddin captured the island of Ischia, taking 4,000 prisoners, and enslaved some 9,000 inhabitants of Lipari, almost the entire population. In 1551, Turgut Reis enslaved the entire population of the Maltese island Gozo, between 5,000 and 6,000, sending them to Libya. In 1554, pirates sacked Vieste in southern Italy and took an estimated 7,000 slaves. In 1555, Turgut Reis sacked Bastia, Corsica, taking 6000 prisoners.
In 1558, Barbary corsairs captured the town of Ciutadella (Minorca), destroyed it, slaughtered the inhabitants and took 3,000 survivors to Istanbul as slaves. In 1563, Turgut Reis landed on the shores of the province of Granada, Spain, and captured coastal settlements in the area, such as Almuñécar, along with 4,000 prisoners. Barbary pirates often attacked the Balearic Islands, and in response many coastal watchtowers and fortified churches were erected. The threat was so severe that the island of Formentera became uninhabited.
From 1609 to 1616, England lost 466 merchant ships to Barbary pirates. In the 19th century, Barbary pirates would capture ships and enslave the crew. Latterly American ships were attacked. During this period, the pirates forged affiliations with Caribbean powers, paying a "license tax" in exchange for safe harbor of their vessels. One American slave reported that the Algerians had enslaved 130 American seamen in the Mediterranean and Atlantic from 1785 to 1793.
The cities of North Africa were especially hard hit by the plague. 30,000–50,000 died in Algiers in 1620–21, 1654–57, 1665, 1691, and 1740–42.
French rule.
On the pretext of a slight to their consul, the French invaded and captured Algiers in 1830. The conquest of Algeria by the French was long and resulted in considerable bloodshed. A combination of violence and disease epidemics caused the indigenous Algerian population to decline by nearly one-third from 1830 to 1872.
Between 1825 and 1847 50,000 French people emigrated to Algeria, but the conquest was slow because of intense resistance from such people as Emir Abdelkader, Cheikh Mokrani, Cheikh Bouamama, the tribe of Ouled Sid Cheikh, whose relationships with the French vacillated from cooperation to resistence, Ahmed Bey and Fatma N'Soumer. Indeed, the conquest was not technically complete until the early 1900s when the last Tuareg were conquered.
Meanwhile, however, the French made Algeria an integral part of France. Tens of thousands of settlers from France, Spain, Italy, and Malta moved in to farm the Algerian coastal plain and occupied significant parts of Algeria's cities.
These settlers benefited from the French government's confiscation of communal land, and the application of modern agricultural techniques that increased the amount of arable land. Algeria's social fabric suffered during the occupation: literacy plummeted, while land development uprooted much of the population.
Starting from the end of the 19th century, people of European descent in Algeria (or natives like Spanish people in Oran), as well as the native Algerian Jews (typically Mizrachi and sometimes Sephardic in origin), became full French citizens. After Algeria's 1962 independence, the Europeans were called "Pieds-Noirs" ("black feet"). Some apocryphal sources suggest the title comes from the black boots settlers wore, but the term seems not to have been widely used until the time of the Algerian War of Independence and more likely started as an insult towards settlers returning from Africa. In contrast, the vast majority of Muslim Algerians (even veterans of the French army) received neither French citizenship nor the right to vote.
Post-independence.
In 1954, the National Liberation Front (FLN) launched the Algerian War of Independence which was a guerrilla campaign. By the end of the war, newly elected President Charles de Gaulle, understanding that the age of empires was ending, held a plebiscite, offering Algerians three options. In a famous speech (4 June 1958 in Algiers) de Gaulle proclaimed in front of a vast crowd of Pieds-Noirs "Je vous ai compris" (I have understood you). Most Pieds-noirs then believed that de Gaulle meant that Algeria would remain French. The poll resulted in a landslide vote for complete independence from France. Over one million people, 10% of the population, then fled the country for France and in just a few months in mid-1962. These included most of the 1,025,000 "Pieds-Noirs", as well as 81,000 "Harkis" (pro-French Algerians serving in the French Army). In the days preceding the bloody conflict, a group of Algerian Rebels opened fire on a marketplace in Oran killing numerous innocent civilians, mostly women. It is estimated that somewhere between 50,000 and 150,000 "Harkis" and their dependents were killed by the FLN or by lynch mobs in Algeria.
Algeria's first president was the FLN leader Ahmed Ben Bella. He was overthrown by his former ally and defence minister, Houari Boumédienne in 1965. Under Ben Bella the government had already become increasingly socialist and authoritarian, and this trend continued throughout Boumédienne's government. However, Boumédienne relied much more heavily on the army, and reduced the sole legal party to a merely symbolic role. Agriculture was collectivised, and a massive industrialization drive launched. Oil extraction facilities were nationalized. This was especially beneficial to the leadership after the 1973 oil crisis. However, the Algerian economy became increasingly dependent on oil which led to hardship when the price collapsed during the 1980s oil glut.
In foreign policy strained relations with its western neighbor Morocco.. Reasons for this include Morocco's disputed claim to portions of western Algeria (which led to the Sand War in 1963), Algeria's support for the Polisario Front for its right to self-determination, and Algeria's hosting of Sahrawi refugees within its borders in the city of Tindouf.
Within Algeria, dissent was rarely tolerated, and the state's control over the media and the outlawing of political parties other than the FLN was cemented in the repressive constitution of 1976.
Boumédienne died in 1978, but the rule of his successor, Chadli Bendjedid, was little more open. The state took on a strongly bureaucratic character and corruption was widespread.
The modernization drive brought considerable demographic changes to Algeria. Village traditions underwent significant change as urbanization increased. New industries emerged and agricultural employment was substantially reduced. Education was extended nationwide, raising the literacy rate from less than 10% to over 60%. There was a dramatic increase in the fertility rate to 7–8 children per mother.
Therefore by 1980, there was a very youthful population and a housing crisis. The new generation struggled to relate to the cultural obsession with the war years and two conflicting protest movements developed: communists, including Berber identity movements; and Islamic 'intégristes'. Both groups protested against one-party rule but also clashed with each other in universities and on the streets during the 1980s. Mass protests from both camps in autumn 1988 forced Bendjedid to concede the end of one-party rule.
Algerian political events (1991–2002).
Elections were planned to happen in 1991. In December 1991, the Islamic Salvation Front won the first round of the country's first multi-party elections. The military then intervened and cancelled the second round. It forced then-president Bendjedid to resign and banned all political parties based on religion (including the Islamic Salvation Front). A political conflict ensued, leading Algeria into the violent Algerian Civil War.
More than 160,000 people were killed between 17 January 1992 and June 2002. Most of the deaths were between militants and government troops, but a great number of civilians were also killed. The question of who was responsible for these deaths was controversial at the time amongst academic observers; many were claimed by the Armed Islamic Group. Though many of these massacres were carried out by Islamic extremists, the Algerian regime also used the army and foreign mercenaries to conduct attacks on men, women and children and then proceeded to blame the attacks upon various Islamic groups within the country.
Elections resumed in 1995, and after 1998, the war waned. On 27 April 1999, after a series of short-term leaders representing the military, Abdelaziz Bouteflika, the current president, was elected.
Post war.
By 2002, the main guerrilla groups had either been destroyed or surrendered, taking advantage of an amnesty program, though fighting and terrorism continues in some areas (See Islamic insurgency in Algeria (2002–present)).
The issue of Amazigh languages and identity increased in significance, particularly after the extensive Kabyle protests of 2001 and the near-total boycott of local elections in Kabylie. The government responded with concessions including naming of Tamazight (Berber) as a national language and teaching it in schools.
Much of Algeria is now recovering and developing into an emerging economy. The high prices of oil and gas are being used by the new government to improve the country's infrastructure and especially improve industry and agricultural land. Recently, overseas investment in Algeria has increased.
Geography.
Most of the coastal area is hilly, sometimes even mountainous, and there are a few natural harbours. The area from the coast to the Tell Atlas is fertile. South of the Tell Atlas is a steppe landscape, which ends with the Saharan Atlas; further south, there is the Sahara desert.
The Ahaggar Mountains (), also known as the Hoggar, are a highland region in central Sahara, southern Algeria. They are located about south of the capital, Algiers and just west of Tamanghasset.
Algiers, Oran, Constantine, and Annaba are Algeria's main cities.
Tropic of Cancer in the torrid zone.
In this region even in winter, midday desert temperatures can be very hot. After sunset, however, the clear, dry air permits rapid loss of heat, and the nights are cool to chilly. Enormous daily ranges in temperature are recorded.
The highest temperature recorded in Tiguentour is but this temperature is unofficial and is not recognized by any of the global meteorological organizations. The hottest recognized reading is 135 degrees Fahrenheit at Tindouf. The highest official temperature was 50.6 degrees Celsius at In Salah.
Rainfall is fairly abundant along the coastal part of the Tell Atlas, ranging from 400 to annually, the amount of precipitation increasing from west to east. Precipitation is heaviest in the northern part of eastern Algeria, where it reaches as much as in some years.
Farther inland, the rainfall is less plentiful. Prevailing winds that are easterly and north-easterly in summer change to westerly and northerly in winter and carry with them a general increase in precipitation from September through December, a decrease in the late winter and spring months, and a near absence of rainfall during the summer months. Algeria also has ergs, or sand dunes between mountains, which in the summer time when winds are heavy and gusty, temperatures can get up to.
Politics.
The head of state is the President of Algeria, who is elected for a five-year term. The president, as of a constitutional amendment passed by the Parliament on November 11, 2008, is not limited to any term length. Algeria has universal suffrage at 18 years of age. The President is the head of the Council of Ministers and of the High Security Council. He appoints the Prime Minister who is also the head of government. The Prime Minister appoints the Council of Ministers.
The Algerian parliament is bicameral, consisting of a lower chamber, the "National People's Assembly (APN)", with 380 members; and an upper chamber, the "Council Of Nation", with 144 members. The APN is elected every five years.
Under the 1976 constitution (as modified 1979, and amended in 1988, 1989, and 1996) Algeria is a multi-party state. The Ministry of the Interior must approve all parties. To date, Algeria has had more than 40 legal political parties. According to the constitution, no political association may be formed if it is "based on differences in religion, language, race, gender or region."
Foreign relations and military.
The military of Algeria consists of the People's National Army (ANP), the Algerian National Navy (MRA), and the Algerian Air Force (QJJ), plus the Territorial Air Defense Force. It is the direct successor of the Armée de Libération Nationale (ALN), the armed wing of the nationalist National Liberation Front, which fought French colonial occupation during the Algerian War of Independence (1954–62). The commander-in-chief of the military is the president, who is also Minister of National Defense.
Total military personnel include 147,000 active, 150,000 reserve, and 187,000 paramilitary staff (2008 estimate). Service in the military is compulsory for men aged 19–30, for a total of eighteen months (six training and twelve in civil projects). The total military expenditure in 2006 was estimated variously at 2.7% of GDP (3,096 million), or 3.3% of GDP.
Algeria is a leading military power in North Africa and has its force oriented toward its western (Morocco) and eastern (Libya) borders. Its primary military supplier has been the former Soviet Union, which has sold various types of sophisticated equipment under military trade agreements, and the People's Republic of China. Algeria has attempted, in recent years, to diversify its sources of military material. Military forces are supplemented by a 70,000-member gendarmerie or rural police force under the control of the president and 30,000-member "Sûreté nationale" or metropolitan police force under the Ministry of the Interior.
In 2007, the Algerian Air Force signed a deal with Russia to purchase 49 MiG-29SMT and 6 MiG-29UBT at an estimated $1.9 billion. They also agreed to return old aircraft purchased from the Former USSR. Russia is also building two 636-type diesel submarines for Algeria.
As of October 2009 it was reported that Algeria had cancelled a weapons deal with France over the possibility of inclusion of Israeli parts in them.
Maghreb Union.
Tensions between Algeria and Morocco in relation to the Western Sahara have put great obstacles in the way of tightening the Maghreb Union and the yearned "Great Maghreb Sultanate", which was nominally established in 1989 but carried little practical weight with its coastal neighbors.
Provinces and districts.
Algeria is divided into 48 provinces ("wilayas"), 553 districts ("daïras") and 1,541 municipalities ("baladiyahs"). Each province, district, and municipality is named after its seat, which is usually the largest city.
According to the Algerian constitution, a province is "a territorial collectivity enjoying some economic freedom".
The People's Provincial Assembly is the political entity governing a province, which has a "president", who is elected by the members of the assembly. They are in turn elected on universal suffrage every five years. The "Wali" (Prefect or governor) directs each province. This person is chosen by the Algerian President to handle the PPA's decisions.
Economy.
The fossil fuels energy sector is the backbone of Algeria's economy, accounting for roughly 60% of budget revenues, 30% of GDP, and over 95% of export earnings. The country ranks fourteenth in petroleum reserves, containing of proven oil reserves with estimates suggesting that the actual amount is even more. The U.S. Energy Information Administration reported that in 2005, Algeria had 160 trillion cubic feet (Tcf) of proven natural gas reserves (4,502 billion cubic metres), the eighth largest in the world.
Algeria’s financial and economic indicators improved during the mid-1990s, in part because of policy reforms supported by the International Monetary Fund (IMF) and debt rescheduling from the Paris Club. Algeria's finances in 2000 and 2001 benefited from an increase in oil prices and the government’s tight fiscal policy, leading to a large increase in the trade surplus, record highs in foreign exchange reserves, and reduction in foreign debt.
The government's continued efforts to diversify the economy by attracting foreign and domestic investment outside the energy sector have had little success in reducing high unemployment and improving living standards, however. In 2001, the government signed an Association Treaty with the European Union that will eventually lower tariffs and increase trade. In March 2006, Russia agreed to erase $4.74 billion of Algeria's Soviet-era debt during a visit by President Vladimir Putin to the country, the first by a Russian leader in half a century. In return, president Bouteflika agreed to buy $7.5 billion worth of combat planes, air-defense systems and other arms from Russia, according to the head of Russia's state arms exporter Rosoboronexport.
Algeria also decided in 2006 to pay off its full $8bn (£4.3bn) debt to the Paris Club group of rich creditor nations before schedule. This will reduce the Algerian foreign debt to less than $5bn in the end of 2006. The Paris Club said the move reflected Algeria's economic recovery in recent years.
Agriculture.
Algeria has always been noted for the fertility of its soil. 25% of Algerians are employed in the agricultural sector.
A considerable amount of cotton was grown at the time of the United States' Civil War, but the industry declined afterwards. In the early years of the twentieth century efforts to extend the cultivation of the plant were renewed. A small amount of cotton is also grown in the southern oases. Large quantities of dwarf palm are cultivated for the leaves, the fibers of which resemble horsehair. The olive (both for its fruit and oil) and tobacco are cultivated with great success.
More than are devoted to the cultivation of cereal grains. The Tell Atlas is the grain-growing land. During the time of French rule its productivity was increased substantially by the sinking of artesian wells in districts which only required water to make them fertile. Of the crops raised, wheat, barley and oats are the principal cereals. A great variety of vegetables and fruits, especially citrus products, are exported. Algeria also exports figs, dates, esparto grass, and cork. It is the largest oat market in Africa.
Algeria is known for Bertolli's olive oil spread, although the spread has an Italian background.
Demographics.
The population of Algeria is 35,190,000 (January 2009 est.), with 99% classified ethnically as Berber/Arab.
About 70% of Algerians live in the northern, coastal area; the minority who inhabit the Sahara are mainly concentrated in oases, although some 1.5 million remain nomadic or partly nomadic. Almost 30% of Algerians are under 15. Algeria has the fourth lowest fertility rate in the Greater Middle East, after those of Cyprus, Tunisia, and Turkey.
The ethnic ancestry of most Algerians is composed of Berber (mostly Zenata and Numidians) and Middle Eastern populations that have invaded northwest Africa at different periods of history and mixed with its inhabitants, such as the Arab tribes (Banu Hilal, Matiql, Sulaym, Adnani) who came in the 10th century AD, other groups that influenced the country include: Phoenicians, Turks, Syrians, Muslims of the Mid-East, Muslims of Spain, Vandals and Romans.
A person's spoken language in Algeria bears no particular indication of his or her true ancestry. This is why Arabic speaking Algerians consider themselves as Arabs or part of the Arab identity, while Berber-speaking Algerians consider themselves as Berbers or part of the Berber identity. Both identities co-exist, the most widely spoken language is Algerian Arabic and all its varities by regions, most common Berber languages are Kabyle and Chaoui. French is widely understood and Standard Arabic (FosHaa) is taught and understand to and by most Algerian youth.
Europeans account for less than 1% of the population, inhabiting almost exclusively the largest metropolitan areas. However, during the colonial period there was a large (15.2% in 1962) European population, consisting primarily of French people, in addition to Spaniards in the west of the country, Italians and Maltese in the east, and other Europeans in smaller numbers. Known as "pieds-noirs", European colonists were concentrated on the coast and formed a majority of the population of Oran (60%) and important proportions in other large cities like Algiers and Annaba. Almost all of this population left during or immediately after the country's independence from France.
Shortages of housing and medicine continue to be pressing problems in Algeria. Failing infrastructure and the continued influx of people from rural to urban areas has overtaxed both systems. According to the UNDP, Algeria has one of the world's highest per housing unit occupancy rates for housing, and government officials have publicly stated that the country has an immediate shortfall of 1.5 million housing units.
Women make up 70 percent of Algeria's lawyers and 60 percent of its judges, and also dominate the field of medicine. Increasingly, women are contributing more to household income than men. Sixty percent of university students are women, according to university researchers.
It is estimated that 95,700 refugees and asylum-seekers have sought refuge in Algeria. This includes roughly 90,000 from Morocco and 4,100 from Palestine. An estimated 90,000 to 160,000 Sahrawis – people from the disputed territory of Western Sahara – live in refugee camps in the Algerian part of the Sahara Desert. There are currently around 35,000 Chinese migrant workers in Algeria.
Ethnic groups.
The ethnic composition of Algeria is mixed Arab and Berber origin. No official figures can be given, because Algerian law forbids population censuses based on ethnic, religious and linguistic criteria. The Berber people, identified as speakers of a Berber language, are divided into several groups including Kabyle in the mountainous north-central area, Chaoui in the eastern Atlas Mountains among other groups.
Languages.
Algerian colloquial Arabic is spoken as a native or as a second language language by more than 83% of the population; of these, over 65% speak Algerian Arabic and around 10% Hassaniya. Algerian Arabic is spoken as a second language by many Berbers. However, in the media and on official occasions the spoken language is Standard Arabic.
The Berbers (or Imazighen) speak one of the various dialects of Tamazight, which add up to around 28% of the population. Arabic remains Algeria's only official language, although Tamazight has recently been recognized as a national language.
French is the most widely studied foreign language in the country, and a majority of Algerians can understand it or speak it, though it is usually not spoken in daily life. Since independence, the government has pursued a policy of linguistic Arabization of education and bureaucracy, which resulted mainly in limiting the use of Berber and the Arabization of many Berber-speakers, while the strong position of French in Algeria was hardly affected by the Arabization policy. All scientific and business university courses are still taught in French to date. Recently, schools have even started to incorporate French into the curriculum as early as children start to learn written classical Arabic. French is also used in media and business. After a political debate in Algeria in the late 90s about whether to replace French with English in the educational system, the government decided to retain French. English is mostly taught only as an optional foreign language in secondary schools.
Religion.
Islam is the predominant religion, followed by more than 99 percent of the country's population. This figure includes all these born in families considered of Muslim descent.
Officially, nearly 100% of all Algerians are Muslims, but atheists and other kinds of non-believers are not counted in the statistics. Nearly all Algerians follow Sunni Islam, with the exception of some 200,000 ibadis in the M'zab Valley in the region of Ghardaia.
There are also some 150,000 Christians in the country, including about 10,000 Roman Catholics and 50,000 to 100,000 evangelical Protestants (mainly Pentecostal), according to the Protestant Church of Algeria's leader Mustapha Krim.
Algeria had an important Jewish community until the 1960s. Nearly all of this community emigrated following the country's independence, although a very small number of Jews continue to live in Algiers.
Health.
In 2002 Algeria had inadequate numbers of physicians (1.13 per 1,000 people), nurses (2.23 per 1,000 people), and dentists (0.31 per 1,000 people). Access to “improved water sources” was limited to 92 percent of the population in urban areas and 80 percent of the population in rural areas. Some 99 percent of Algerians living in urban areas, but only 82 percent of those living in rural areas, had access to “improved sanitation.” According to the World Bank, Algeria is making progress toward its goal of “reducing by half the number of people without sustainable access to improved drinking water and basic sanitation by 2015.” Given Algeria’s young population, policy favors preventive health care and clinics over hospitals. In keeping with this policy, the government maintains an immunization program. However, poor sanitation and unclean water still cause tuberculosis, hepatitis, measles, typhoid fever, cholera, and dysentery. The poor generally receive health care free of charge.
Education.
Education is officially compulsory for children between the ages of six and fifteen. In the year 1997, there was an outstanding amount of teachers and students in primary schools. About 30% of the adult population of the country are illiterate.
Culture.
Modern Algerian literature, split between Arabic and French, has been strongly influenced by the country's recent history. Famous novelists of the twentieth century include Mohammed Dib, Albert Camus, and Kateb Yacine, while Assia Djebar is widely translated. Among the important novelists of the 1980s were Rachid Mimouni, later vice-president of Amnesty International, and Tahar Djaout, murdered by an Islamist group in 1993 for his secularist views.
In philosophy and the humanities, Jacques Derrida, the father of deconstruction, was born in El Biar in Algiers; Malek Bennabi and Frantz Fanon are noted for their thoughts on decolonization; Augustine of Hippo was born in Tagaste (modern-day Souk Ahras); and Ibn Khaldun, though born in Tunis, wrote the Muqaddima while staying in Algeria.
Algerian culture has been strongly influenced by Islam, the main religion. The works of the Sanusi family in pre-colonial times, and of Emir Abdelkader and Sheikh Ben Badis in colonial times, are widely noted. The Latin author Apuleius was born in Madaurus (Mdaourouch), in what later became Algeria.
In painting, Mohammed Khadda and M'Hamed Issiakhem have been notable in recent years.
UNESCO World Heritage Sites in Algeria.
There are several UNESCO World Heritage Sites in Algeria including Al Qal'a of Beni Hammad, the first capital of the Hammadid empire; Tipasa, a Phoenician and later Roman town; and Djémila and Timgad, both Roman ruins; M'Zab Valley, a limestone valley containing a large urbanized oasis; also the Casbah of Algiers is an important citadel. The only natural World Heritage Sites is the Tassili n'Ajjer, a mountain range.
---END.OF.DOCUMENT---
Anthropology.
Anthropology is the study of humanity. Anthropology has origins in the natural sciences, the humanities, and the social sciences. The term "anthropology", is from the Greek, "anthrōpos", "human", and -λογία, "-logia", "discourse" or "study", and was first used by François Péron when discussing his encounters with Tasmanian Aborigines.
Anthropology's basic concerns are "What defines "Homo sapiens"?", "Who are the ancestors of modern "Homo sapiens"?", "What are humans' physical traits?", "How do humans behave?", "Why are there variations and differences among different groups of humans?", "How has the evolutionary past of "Homo sapiens" influenced its social organization and culture?" and so forth.
In the United States, contemporary anthropology is typically divided into four sub-fields: cultural anthropology (also called "social anthropology"), archaeology, linguistic anthropology and biological/physical anthropology. The so-called "four-field" approach to anthropology is reflected in many undergraduate textbooks as well as anthropology programs (e.g. Michigan, Berkeley, UPenn, etc.). At universities in the United Kingdom, and much of Europe, these "sub-fields" are frequently housed in separate departments and are seen as distinct disciplines.
The social and cultural sub-field has been heavily influenced by post-modern theories. During the 1970s and 1980s there was an epistemological shift away from the positivist traditions that had largely informed the discipline. During this shift, enduring questions about the nature and production of knowledge came to occupy a central place in Cultural and Social Anthropology. In contrast, Archaeology, Biological Anthropology, and linguistic anthropology remained largely positivist. Due to this difference in epistemology, anthropology as a discipline has lacked cohesion over the last several decades. This has even led to departments diverging, for example in the 1998-9 academic year at Stanford University, where the "scientists" and "non-scientists" divided into two departments: Anthropology, and Cultural and Social Anthropology. (Anthropology at Stanford later reunified in the 2008-9 academic year)
Overview.
Anthropology is traditionally divided into four sub-fields, each with its own further branches: biological or physical anthropology, social anthropology or cultural anthropology, archaeology and anthropological linguistics. These fields frequently overlap, but tend to use different methodologies and techniques.
Biological anthropology or Physical anthropology, focuses on the study of human populations using an evolutionary framework. Biological anthropologists have theorized about how the globe has become populated with humans (e.g. the "Out of Africa" and "multi-regional evolution" debate), as well as tried to explain geographical human variation and race. Many biological anthropologists studying modern human populations identify their field as human ecology - itself linked to sociobiology. Human ecology uses evolutionary theory to understand phenomena among contemporary human populations. Another large sector of biological anthropology is primatology, where anthropologists focus on understanding other primate populations. Methodologically, primatologists borrow heavily from field biology and ecology in their research.
Cultural anthropology is also called socio-cultural anthropology or social anthropology (especially in Great Britain). It is the study of culture, and is often based on ethnography. Ethnography can refer to both a methodology and a product of research, namely a monograph or book. Ethnography is a grounded, inductive method, that heavily relies on participant-observation. Ethnology involves the systematic comparison of different cultures. In some European countries, all cultural anthropology is known as ethnology (a term coined and defined by Adam F. Kollár in 1783).
The study of kinship and social organization is a central focus of cultural anthropology, as kinship is a human universal. Cultural anthropology also covers economic and political organization, law and conflict resolution, patterns of consumption and exchange, material culture, technology, infrastructure, gender relations, ethnicity, childrearing and socialization, religion, myth, symbols, values, etiquette, worldview, sports, music, nutrition, recreation, games, food, festivals, and language (which is also the object of study in linguistic anthropology).
Archaeology is the study of human material culture, including both artifacts (older pieces of human culture) carefully gathered "in situ", museum pieces and modern garbage. Archaeologists work closely with biological anthropologists, art historians, physics laboratories (for dating), and museums. They are charged with preserving the results of their excavations and are often found in museums. Typically, archaeologists are associated with "digs," or excavation of layers of ancient sites.
Archaeologists subdivide time into cultural periods based on long-lasting artifacts: the Paleolithic, the Neolithic, the Bronze Age, which are further subdivided according to artifact traditions and culture region, such as the Oldowan or the Gravettian. In this way, archaeologists provide a vast frame of reference for the places human beings have traveled, their ways of making a living, and their demographics. Archaeologists also investigate nutrition, symbolization, art, systems of writing, and other physical remnants of human cultural activity.
Linguistic anthropology (also called anthropological linguistics) seeks to understand the processes of human communications, verbal and non-verbal, variation in language across time and space, the social uses of language, and the relationship between language and culture. It is the branch of anthropology that brings linguistic methods to bear on anthropological problems, linking the analysis of linguistic forms and processes to the interpretation of sociocultural processes. Linguistic anthropologists often draw on related fields including sociolinguistics, pragmatics, cognitive linguistics, semiotics, discourse analysis, and narrative analysis.
Linguistic anthropology is divided into its own sub-fields: descriptive linguistics the construction of grammars and lexicons for unstudied languages; historical linguistics, including the reconstruction of past languages, from which our current languages have descended; ethnolinguistics, the study of the relationship between language and culture, and sociolinguistics, the study of the social functions of language. Anthropological linguistics is also concerned with the evolution of the parts of the brain that deal with language.
Because anthropology developed from so many different enterprises (see History of Anthropology), including but not limited to fossil-hunting, exploring, documentary film-making, paleontology, primatology, antiquity dealings and curatorship, philology, etymology, genetics, regional analysis, ethnology, history, philosophy and religious studies, it is difficult to characterize the entire field in a brief article, although attempts to write histories of the entire field have been made.
On the one hand this has led to instability in many American anthropology departments, resulting in the division or reorganization of sub-fields (e.g. at Stanford, Duke, and most recently at Harvard). However, seen in a positive light, anthropology is one of the few place in many American universities where humanities, social, and natural sciences are forced to confront one another. As such, anthropology has also been central in the development of several new (late 20th century) interdisciplinary fields such as cognitive science, global studies, human-computer interaction, and various ethnic studies.
Basic trends.
There are several characteristics that tend to unite anthropological work. One of the central characteristics is that anthropology tends to provide a comparatively more holistic account of phenomena and tends to be highly empirical. The quest for holism leads most anthropologists to study a particular place or thing in detail, using a variety of methods, over a more extensive period than normal in many parts of academia.
The specific focus of social and cultural anthropology has significantly changed. Initially the sub-field was focused on the study of cultures around the world.
In the 1990s and 2000s, calls for clarification of what constitutes a culture, of how an observer knows where his or her own culture ends and another begins, and other crucial topics in writing anthropology were heard. It is possible to view all human cultures as part of one large, evolving global culture. These dynamic relationships, between what can be observed on the ground, as opposed to what can be observed by compiling many local observations remain fundamental in any kind of anthropology, whether cultural, biological, linguistic or archaeological.
Biological anthropologists are interested in both human variation and in the possibility of human universals (behaviors, ideas or concepts shared by virtually all human cultures) They use many different methods of study, but modern population genetics, participant observation and other techniques often take anthropologists "into the field" which means traveling to a community in its own setting, to do something called "fieldwork." On the biological or physical side, human measurements, genetic samples, nutritional data may be gathered and published as articles or monographs. Due to the interest in variation, anthropologists are drawn to the study of human extremes, aberrations and other unusual circumstances, such as headhunting, whirling dervishes, whether there were real Hobbit people, snake handling, and glossolalia (speaking in tongues), just to list a few.
At the same time, anthropologists urge, as part of their quest for scientific objectivity, cultural relativism, which has an influence on all the sub-fields of anthropology. This is the notion that particular cultures should not be judged by one culture's values or viewpoints, but that all cultures should be viewed as relative to each other. There should be no notions, in good anthropology, of one culture being better or worse than another culture.
Ethical commitments in anthropology include noticing and documenting genocide, infanticide, racism, mutilation including especially circumcision and subincision, and torture. Topics like racism, slavery or human sacrifice, therefore, attract anthropological attention and theories ranging from nutritional deficiencies to genes to acculturation have been proposed, not to mention theories of colonialism and many others as root causes of Man's inhumanity to man. To illustrate the depth of an anthropological approach, one can take just one of these topics, such as "racism" and find thousands of anthropological references, stretching across all the major and minor sub-fields.
Along with dividing up their project by theoretical emphasis, anthropologists typically divide the world up into relevant time periods and geographic regions. Human time on Earth is divided up into relevant cultural traditions based on material, such as the Paleolithic and the Neolithic, of particular use in archaeology. Further cultural subdivisions according to tool types, such as Olduwan or Mousterian or Levallois help archaeologists and other anthropologists in understanding major trends in the human past. Anthropologists and geographers share approaches to Culture regions as well, since mapping cultures is central to both sciences. By making comparisons across cultural traditions (time-based) and cultural regions (space-based), anthropologists have developed various kinds of comparative method, a central part of their science.
Contemporary anthropology is an established science with academic departments at most universities and colleges. The single largest organization of Anthropologists is the American Anthropological Association, which was founded in 1903. Membership is made up of Anthropologists from around the globe. Hundreds of other organizations exist in the various sub-fields of anthropology, sometimes divided up by nation or region, and many anthropologists work with collaborators in other disciplines, such as geology, physics, zoology, paleontology, anatomy, music theory, art history, sociology and so on, belonging to professional societies in those disciplines as well.
History.
The first use of the term "anthropology" in English to refer to a natural science of humankind was apparently in 1593, the first of the "logies" to be coined. It took Immanuel Kant 25 years to write one of the first major treatises on anthropology, his "Anthropology from a Pragmatic Point of View". Kant is not generally considered to be a modern anthropologist, however, as he never left his region of Germany nor did he study any cultures besides his own, and in fact, describes the need for anthropology as a corollary field to his own primary field of philosophy. He did, however, begin teaching an annual course in anthropology in 1772. Anthropology is thus primarily an Enlightenment and post-Enlightenment endeavor.
Historians of anthropology, like Marvin Harris, indicate two major frameworks within which empirical anthropology has arisen: interest in comparisons of people over space and interest in longterm human processes or humans as viewed through time. Harris dates both to Classical Greece and Classical Rome, specifically Herodotus, often called the "father of history" and the Roman historian Tacitus, who wrote many of our only surviving contemporary accounts of several ancient Celtic and Germanic peoples. Herodotus first formulated some of the persisting problems of anthropology.
Medieval scholars may be considered forerunners of modern anthropology as well, insofar as they conducted or wrote detailed studies of the customs of peoples considered "different" from themselves in terms of geography. John of Plano Carpini reported of his stay among the Mongols. His report was unusual in its detailed depiction of a non-European culture!
Marco Polo's systematic observations of nature, anthropology, and geography are another example of studying human variation across space. Polo's travels took him across such a diverse human landscape and his accounts of the peoples he met as he journeyed were so detailed that they earned for Polo the name "the father of modern anthropology."
Another candidate for one of the first scholars to carry out comparative ethnographic-type studies in person was the medieval Persian scholar Abū Rayhān Bīrūnī in the 11th century, who wrote about the peoples, customs, and religions of the Indian subcontinent. Like modern anthropologists, he engaged in extensive participant observation with a given group of people, learnt their language and studied their primary texts, and presented his findings with objectivity and neutrality using cross-cultural comparisons. He wrote detailed comparative studies on the religions and cultures in the Middle East, Mediterranean and especially South Asia. Biruni's tradition of comparative cross-cultural study continued in the Muslim world through to Ibn Khaldun's work in the 14th century.
Most scholars consider modern anthropology as an outgrowth of the Age of Enlightenment, a period when Europeans attempted systematically to study human behavior, the known varieties of which had been increasing since the 15th century as a result of the first European colonization wave. The traditions of jurisprudence, history, philology, and sociology then evolved into something more closely resembling the modern views of these disciplines and informed the development of the social sciences, of which anthropology was a part.
Developments in the systematic study of ancient civilizations through the disciplines of Classics and Egyptology informed both archaeology and eventually social anthropology, as did the study of East and South Asian languages and cultures. At the same time, the Romantic reaction to the Enlightenment produced thinkers, such as Johann Gottfried Herder and later Wilhelm Dilthey, whose work formed the basis for the "culture concept," which is central to the discipline.
Institutionally, anthropology emerged from the development of natural history (expounded by authors such as Buffon) that occurred during the European colonization of the 17th, 18th, 19th and 20th centuries. Programs of ethnographic study originated in this era as the study of the "human primitives" overseen by colonial administrations.
There was a tendency in late 18th century Enlightenment thought to understand human society as natural phenomena that behaved according to certain principles and that could be observed empirically. In some ways, studying the language, culture, physiology, and artifacts of European colonies was not unlike studying the flora and fauna of those places.
Early anthropology was divided between proponents of unilinealism, who argued that all societies passed through a single evolutionary process, from the most primitive to the most advanced, and various forms of non-lineal theorists, who tended to subscribe to ideas such as diffusionism. Most 19th-century social theorists, including anthropologists, viewed non-European societies as windows onto the pre-industrial human past.
As academic disciplines began to differentiate over the course of the 19th century, anthropology grew increasingly distinct from the biological approach of natural history, on the one hand, and from purely historical or literary fields such as Classics, on the other. A common criticism has been that many social science scholars (such as economists, sociologists, and psychologists) in Western countries focus disproportionately on Western subjects, while anthropology focuses disproportionately on the "Other"; this has changed over the last part of the 20th century as anthropologists increasingly also study Western subjects, particularly variation across class, region, or ethnicity within Western societies, and other social scientists increasingly take a global view of their fields.
20th century.
In the twentieth century, academic disciplines have often been institutionally divided into three broad domains. The natural and biological "sciences" seek to derive general laws through reproducible and verifiable experiments. The "humanities" generally study local traditions, through their history, literature, music, and arts, with an emphasis on understanding particular individuals, events, or eras.
The "social sciences" have generally attempted to develop scientific methods to understand social phenomena in a generalizable way, though usually with methods distinct from those of the natural sciences. In particular, social sciences often develop statistical descriptions rather than the general laws derived in physics or chemistry, or they may explain individual cases through more general principles, as in many fields of psychology. Anthropology (like some fields of history) does not easily fit into one of these categories, and different branches of anthropology draw on one or more of these domains.
Anthropology as it emerged amongst the Western colonial powers (mentioned above) has generally taken a different path than that in the countries of southern and central Europe (Italy, Greece, and the successors to the Austro-Hungarian and Ottoman empires). In the former, the encounter with multiple, distinct cultures, often very different in organization and language from those of Europe, has led to a continuing emphasis on cross-cultural comparison and a receptiveness to certain kinds of cultural relativism.
In the successor states of continental Europe, on the other hand, anthropologists often joined with folklorists and linguists in building nationalist perspectives. Ethnologists in these countries tended to focus on differentiating among local ethnolinguistic groups, documenting local folk culture, and representing the prehistory of what has become a nation through various forms of public education (eg, museums of several kinds).
In this scheme, Russia occupied a middle position. On the one hand, it had a large region (largely east of the Urals) of highly distinct, pre-industrial, often non-literate peoples, similar to the situation in the Americas. On the other hand, Russia also participated to some degree in the nationalist (cultural and political) movements of Central and Eastern Europe. After the Revolution of 1917, anthropology in the USSR, and later the Soviet Bloc countries, were highly shaped by the requirement to conform to Marxist theories of social evolution.
Britain.
E. B. Tylor (2 October 1832 – 2 January 1917) and James George Frazer (1 January 1854 – 7 May 1941) are generally considered the antecedents to modern social anthropology in Britain. Though Tylor undertook a field trip to Mexico, both he and Frazer derived most of the material for their comparative studies through extensive reading, not fieldwork, mainly the Classics (literature and history of Greece and Rome), the work of the early European folklorists, and reports from missionaries, travelers, and contemporaneous ethnologists.
Tylor advocated strongly for unilinealism and a form of "uniformity of mankind". Tylor in particular laid the groundwork for theories of cultural diffusionism, stating that there are three ways that different groups can have similar cultural forms or technologies: "independent invention, inheritance from ancestors in a distant region, transmission from one race [sic] to another."
Tylor formulated one of the early and influential anthropological conceptions of culture as "that complex whole which includes knowledge, belief, art, morals, law, custom, and any other capabilities and habits acquired by man as a member of society." However, as Stocking notes, Tylor mainly concerned himself with describing and mapping the distribution of particular elements of culture, rather than with the larger function, and generally seemed to assume a Victorian idea of progress rather than the idea of non-directional, multilineal cultural development proposed by later anthropologists.
Tylor also theorized about the origins of religious feelings in human beings, proposing a theory of animism as the earliest stage, and noting that "religion" has many components, of which he believed the most important to be belief in supernatural beings (as opposed to moral systems, cosmology, etc.). Frazer, a Scottish scholar with a broad knowledge of Classics, also concerned himself with religion, myth, and magic. His comparative studies, most influentially in the numerous editions of "The Golden Bough", analyzed similarities in religious belief and symbolism globally.
Neither Tylor nor Frazer, however, were particularly interested in fieldwork, nor were they interested in examining how the cultural elements and institutions fit together. Toward the turn of the twentieth century, a number of anthropologists became dissatisfied with this categorization of cultural elements; historical reconstructions also came to seem increasingly speculative.
Under the influence of several younger scholars, a new approach came to predominate among British anthropologists, concerned with analyzing how societies held together in the present (synchronic analysis, rather than diachronic or historical analysis), and emphasizing long-term (one to several years) immersion fieldwork. Cambridge University financed a multidisciplinary expedition to the Torres Strait Islands in 1898, organized by Alfred Court Haddon and including a physician-anthropologist, William Rivers, as well as a linguist, a botanist, other specialists. The findings of the expedition set new standards for ethnographic description.
A decade and a half later, Polish anthropology student Bronisław Malinowski (1884–1942) was beginning what he expected to be a brief period of fieldwork in the old model, collecting lists of cultural items, when the outbreak of the First World War stranded him in New Guinea. As a subject of the Austro-Hungarian Empire resident on a British colonial possession, he was effectively confined to New Guinea for several years.
He made use of the time by undertaking far more intensive fieldwork than had been done by "British" anthropologists, and his classic ethnography, "Argonauts of the Western Pacific" (1922) advocated an approach to fieldwork that became standard in the field: getting "the native's point of view" through participant observation. Theoretically, he advocated a functionalist interpretation, which examined how social institutions functioned to satisfy individual needs.
British social anthropology had an expansive moment in the Interwar period, with key contributions coming from the Polish-British Bronisław Malinowski and Meyer Fortes
A. R. Radcliffe-Brown also published a seminal work in 1922. He had carried out his initial fieldwork in the Andaman Islands in the old style of historical reconstruction. However, after reading the work of French sociologists Émile Durkheim and Marcel Mauss, Radcliffe-Brown published an account of his research (entitled simply "The Andaman Islanders") that paid close attention to the meaning and purpose of rituals and myths. Over time, he developed an approach known as structural-functionalism, which focused on how institutions in societies worked to balance out or create an equilibrium in the social system to keep it functioning harmoniously. (This contrasted with Malinowski's functionalism, and was quite different from the later French structuralism, which examined the conceptual structures in language and symbolism.)
Malinowski and Radcliffe-Brown's influence stemmed from the fact that they, like Boas, actively trained students and aggressively built up institutions that furthered their programmatic ambitions. This was particularly the case with Radcliffe-Brown, who spread his agenda for "Social Anthropology" by teaching at universities across the British Commonwealth. From the late 1930s until the postwar period appeared a string of monographs and edited volumes that cemented the paradigm of British Social Anthropology (BSA). Famous ethnographies include "The Nuer," by Edward Evan Evans-Pritchard, and "The Dynamics of Clanship Among the Tallensi," by Meyer Fortes; well-known edited volumes include "African Systems of Kinship and Marriage" and "African Political Systems."
Max Gluckman, together with many of his colleagues at the Rhodes-Livingstone Institute and students at Manchester University, collectively known as the Manchester School, took BSA in new directions through their introduction of explicitly Marxist-informed theory, their emphasis on conflicts and conflict resolution, and their attention to the ways in which individuals negotiate and make use of the social structural possibilities.
In Britain, anthropology had a great intellectual impact, it "contributed to the erosion of Christianity, the growth of cultural relativism, an awareness of the survival of the primitive in modern life, and the replacement of diachronic modes of analysis with synchronic, all of which are central to modern culture."
Later in the 1960s and 1970s, Edmund Leach and his students Mary Douglas and Nur Yalman, among others, introduced French structuralism in the style of Lévi-Strauss; while British anthropology has continued to emphasize social organization and economics over purely symbolic or literary topics, differences among British, French, and American sociocultural anthropologies have diminished with increasing dialogue and borrowing of both theory and methods. Today, social anthropology in Britain engages internationally with many other social theories and has branched in many directions.
In countries of the British Commonwealth, social anthropology has often been institutionally separate from physical anthropology and primatology, which may be connected with departments of biology or zoology; and from archaeology, which may be connected with departments of Classics, Egyptology, and the like. In other countries (and in some, particularly smaller, British and North American universities), anthropologists have also found themselves institutionally linked with scholars of folklore, museum studies, human geography, sociology, social relations, ethnic studies, cultural studies, and social work.
19th Century to 1940s.
From its beginnings in the early 19th century through the early 20th century, anthropology in the United States was influenced by the presence of Native American societies.
Cultural anthropology in the United States was influenced greatly by the ready availability of Native American societies as ethnographic subjects. The field was pioneered by staff of the Bureau of Indian Affairs and the Smithsonian Institution's Bureau of American Ethnology, men such as John Wesley Powell and Frank Hamilton Cushing.
Lewis Henry Morgan (1818–1881), a lawyer from Rochester, New York, became an advocate for and ethnological scholar of the Iroquois. His comparative analyses of religion, government, material culture, and especially kinship patterns proved to be influential contributions to the field of anthropology. Like other scholars of his day (such as Edward Tylor), Morgan argued that human societies could be classified into categories of cultural evolution on a scale of progression that ranged from "savagery", to "barbarism", to "civilization". Generally, Morgan used technology (such as bowmaking or pottery) as an indicator of position on this scale.
Boasian anthropology.
Franz Boas established academic anthropology in the United States in opposition to this sort of evolutionary perspective. His approach was empirical, skeptical of overgeneralizations, and eschewed attempts to establish universal laws. For example, Boas studied immigrant children to demonstrate that biological race was not immutable, and that human conduct and behavior resulted from nurture, rather than nature.
Influenced by the German tradition, Boas argued that the world was full of distinct "cultures," rather than societies whose evolution could be measured by how much or how little "civilization" they had. He believed that each culture has to be studied in its particularity, and argued that cross-cultural generalizations, like those made in the natural sciences, were not possible.
In doing so, he fought discrimination against immigrants, blacks, and indigenous peoples of the Americas. Many American anthropologists adopted his agenda for social reform, and theories of race continue to be popular subjects for anthropologists today. The so-called "Four Field Approach" has its origins in Boasian Anthropology, dividing the discipline in the four crucial and interrelated fields of sociocultural, biological, linguistic, and archaic anthropology (e.g. archaeology). Anthropology in the United States continues to be deeply influenced by the Boasian tradition, especially its emphasis on culture.
Boas used his positions at Columbia University and the American Museum of Natural History to train and develop multiple generations of students. His first generation of students included Alfred Kroeber, Robert Lowie, Edward Sapir and Ruth Benedict, who each produced richly detailed studies of indigenous North American cultures. They provided a wealth of details used to attack the theory of a single evolutionary process. Kroeber and Sapir's focus on Native American languages helped establish linguistics as a truly general science and free it from its historical focus on Indo-European languages.
The publication of Alfred Kroeber's textbook, "Anthropology," marked a turning point in American anthropology. After three decades of amassing material, Boasians felt a growing urge to generalize. This was most obvious in the 'Culture and Personality' studies carried out by younger Boasians such as Margaret Mead and Ruth Benedict. Influenced by psychoanalytic psychologists including Sigmund Freud and Carl Jung, these authors sought to understand the way that individual personalities were shaped by the wider cultural and social forces in which they grew up.
Though such works as "Coming of Age in Samoa" and "The Chrysanthemum and the Sword" remain popular with the American public, Mead and Benedict never had the impact on the discipline of anthropology that some expected. Boas had planned for Ruth Benedict to succeed him as chair of Columbia's anthropology department, but she was sidelined by Ralph Linton, and Mead was limited to her offices at the AMNH.
Canada.
Canadian anthropology began, as in other parts of the Colonial world, as ethnological data in the records of travellers and missionaries. In Canada, Jesuit missionaries such as Fathers LeClercq, Le Jeune and Sagard, in the 1600s, provide the oldest ethnographic records of native tribes in what was then the Domain of Canada.
True anthropology began with a Government department: the Geological Survey of Canada, and George Mercer Dawson (director in 1895). Dawson's support for anthropology created impetus for the profession in Canada. This was expanded upon by Prime Minister Wilfrid Laurier, who established a Division of Anthropology within the Geological Survey in 1910. Anthropologists were recruited from England and the USA, setting the foundation for the unique Canadian style of anthropology. Scholars include the linguist and Boasian Edward Sapir.
France.
Anthropology in France has a less clear genealogy than the British and American traditions, in part because many French writers influential in anthropology have been trained or held faculty positions in sociology, philosophy, or other fields rather than in anthropology.
Most commentators consider Marcel Mauss (1872–1950), nephew of the influential sociologist Émile Durkheim to be the founder of the French anthropological tradition. Mauss belonged to Durkheim's Année Sociologique group; and while Durkheim and others examined the state of modern societies, Mauss and his collaborators (such as Henri Hubert and Robert Hertz) drew on ethnography and philology to analyze societies which were not as 'differentiated' as European nation states.
Two works by Mauss in particular proved to have enduring relevance: "Essay on the Gift" a seminal analysis of exchange and reciprocity, and his Huxley lecture on the notion of the person, the first comparative study of notions of person and selfhood cross-culturally.
Throughout the interwar years, French interest in anthropology often dovetailed with wider cultural movements such as surrealism and primitivism which drew on ethnography for inspiration. Marcel Griaule and Michel Leiris are examples of people who combined anthropology with the French avant-garde. During this time most of what is known as "ethnologie" was restricted to museums, such as the Musée de l'Homme founded by Paul Rivet, and anthropology had a close relationship with studies of folklore.
Above all, however, it was Claude Lévi-Strauss who helped institutionalize anthropology in France. Along with the enormous influence his structuralism exerted across multiple disciplines, Lévi-Strauss established ties with American and British anthropologists. At the same time he established centers and laboratories within France to provide an institutional context within anthropology while training influential students such as Maurice Godelier and Françoise Héritier who would prove influential in the world of French anthropology. Much of the distinct character of France's anthropology today is a result of the fact that most anthropology is carried out in nationally funded research laboratories (CNRS) rather than academic departments in universities.
Other influential writers in the 1970s include Pierre Clastres, who explains in his books on the Guayaki tribe in Paraguay that "primitive societies" actively oppose the institution of the state. Therefore, these stateless societies are not less evolved than societies with states, but took the active choice of conjuring the institution of authority as a separate function from society. The leader is only a spokesperson for the group when it has to deal with other groups ("international relations") but has no inside authority, and may be violently removed if he attempts to abuse this position.
The most important French social theorist since Foucault and Lévi-Strauss is Pierre Bourdieu, who trained formally in philosophy and sociology and eventually held the Chair of Sociology at the Collège de France. Like Mauss and others before him, however, he worked on topics both in sociology and anthropology. His fieldwork among the Kabyles of Algeria places him solidly in anthropology, while his analysis of the function and reproduction of fashion and cultural capital in European societies places him as solidly in sociology.
Other countries.
Anthropology in Greece and Portugal is much influenced by British anthropology. In Greece, there was since the 19th century a science of the folklore called "laographia" (laography), in the form of "a science of the interior", although theoretically weak; but the connotation of the field deeply changed after World War II, when a wave of Anglo-American anthropologists introduced a science "of the outside". In Italy, the development of ethnology and related studies did not receive as much attention as other branches of learning.
Germany and Norway are the countries that showed the most division and conflict between scholars focusing on domestic socio-cultural issues and scholars focusing on "other" societies.
Post-World War II.
Before WWII British 'social anthropology' and American 'cultural anthropology' were still distinct traditions. After the war, enough British and American anthropologists borrowed ideas and methodological approaches from one another that some began to speak of them collectively as 'sociocultural' anthropology.
In the 1950s and mid-1960s anthropology tended increasingly to model itself after the natural sciences. Some anthropologists, such as Lloyd Fallers and Clifford Geertz, focused on processes of modernization by which newly independent states could develop. Others, such as Julian Steward and Leslie White, focused on how societies evolve and fit their ecological niche—an approach popularized by Marvin Harris.
Economic anthropology as influenced by Karl Polanyi and practiced by Marshall Sahlins and George Dalton challenged standard neoclassical economics to take account of cultural and social factors, and employed Marxian analysis into anthropological study. In England, British Social Anthropology's paradigm began to fragment as Max Gluckman and Peter Worsley experimented with Marxism and authors such as Rodney Needham and Edmund Leach incorporated Lévi-Strauss's structuralism into their work.
Structuralism also influenced a number of developments in 1960s and 1970s, including cognitive anthropology and componential analysis. Authors such as David Schneider, Clifford Geertz, and Marshall Sahlins developed a more fleshed-out concept of culture as a web of meaning or signification, which proved very popular within and beyond the discipline. In keeping with the times, much of anthropology became politicized through the Algerian War of Independence and opposition to the Vietnam War; Marxism became an increasingly popular theoretical approach in the discipline. By the 1970s the authors of volumes such as "Reinventing Anthropology" worried about anthropology's relevance.
Since the 1980s issues of power, such as those examined in Eric Wolf's "Europe and the People Without History", have been central to the discipline. In the 80s books like "Anthropology and the Colonial Encounter" pondered anthropology's ties to colonial inequality, while the immense popularity of theorists such as Antonio Gramsci and Michel Foucault moved issues of power and hegemony into the spotlight. Gender and sexuality became popular topics, as did the relationship between history and anthropology, influenced by Marshall Sahlins (again), who drew on Lévi-Strauss and Fernand Braudel to examine the relationship between social structure and individual agency. Also influential in these issues were Nietzsche, Heidegger, the critical theory of the Frankfurt School, Derrida and Lacan.
In the late 1980s and 1990s authors such as George Marcus and James Clifford pondered ethnographic authority, particularly how and why anthropological knowledge was possible and authoritative. They were reflecting trends in research and discourse initiated by Feminists in the academy, although they excused themselves from commenting specifically on those pioneering critics. Nevertheless, key aspects of feminist theorizing and methods became "de rigueur" as part of the 'post-modern moment' in anthropology: Ethnographies became more reflexive, explicitly addressing the author's methodology, cultural, gender and racial positioning, and their influence on his or her ethnographic analysis. This was part of a more general trend of postmodernism that was popular contemporaneously. Currently anthropologists pay attention to a wide variety of issues pertaining to the contemporary world, including globalization, medicine and biotechnology, indigenous rights, virtual communities, and the anthropology of industrialized societies.
Controversies about its history.
Anthropologists, like other researchers (especially historians and scientists engaged in field research), have over time assisted state policies and projects, especially colonialism.
Military.
Anthropologists' involvement with the U.S. government, in particular, has caused bitter controversy within the discipline. Franz Boas publicly objected to US participation in World War I, and after the war he published a brief expose and condemnation of the participation of several American archaeologists in espionage in Mexico under their cover as scientists.
But by the 1940s, many of Boas' anthropologist contemporaries were active in the allied war effort against the "Axis" (Nazi Germany, Fascist Italy, and Imperial Japan). Many served in the armed forces but others worked in intelligence (for example, Office of Strategic Services (OSS) and the Office of War Information). At the same time, David H. Price's work on American anthropology during the Cold War provides detailed accounts of the pursuit and dismissal of several anthropologists from their jobs for communist sympathies.
Attempts to accuse anthropologists of complicity with the CIA and government intelligence activities during the Vietnam War years have turned up surprisingly little (although anthropologist Hugo Nutini was active in the stillborn Project Camelot). Many anthropologists (students and teachers) were active in the antiwar movement and a great many resolutions condemning the war in all its aspects were passed overwhelmingly at the annual meetings of the American Anthropological Association (AAA).
In the decades since the Vietnam war the tone of cultural and social anthropology, at least, has been increasingly politicized, with the dominant liberal tone of earlier generations replaced with one more radical, a mix of, and varying degrees of, Marxist, feminist, anarchist, post-colonial, post-modern, Saidian, Foucauldian, identity-based, and more.
Professional anthropological bodies often object to the use of anthropology for the benefit of the state. Their codes of ethics or statements may proscribe anthropologists from giving secret briefings. The Association of Social Anthropologists of the UK and Commonwealth (ASA) has called certain scholarships ethically dangerous. The AAA's current 'Statement of Professional Responsibility' clearly states that "in relation with their own government and with host governments... no secret research, no secret reports or debriefings of any kind should be agreed to or given."
However, anthropologists, along with other social scientists, are again being used in warfare as part of the. The Christian Science Monitor reports that "Counterinsurgency efforts focus on better grasping and meeting local needs" in Afghanistan, under the rubric of "Human Terrain Team" (HTT).
Focus on other cultures===.
Some authors argue that anthropology originated and developed as the study of "other cultures", both in terms of time (past societies) and space (non-European/non-Western societies). For example, the classic of urban anthropology, Ulf Hannerz in the introduction to his seminal "Exploring the City: Inquiries Toward an Urban Anthropology" mentions that the "Third World" had habitually received most of attention; anthropologists who traditionally specialized in "other cultures" looked for them far away and started to look "across the tracks" only in late 1960s.
Now there exist many works focusing on peoples and topics very close to the author's "home". It is also argued that other fields of study, like History and Sociology, on the contrary focus disproportionately on the West.
In France, the study of existing contemporary society has been traditionally left to sociologists, but this is increasingly changing, starting in the 1970s from scholars like Isac Chiva and journals like "Terrain" ("fieldwork"), and developing with the center founded by Marc Augé ("Le Centre d'anthropologie des mondes contemporains", the Anthropological Research Center of Contemporary Societies). The same approach of focusing on "modern world" topics by "Terrain", was also present in the British Manchester School of the 1950s.
---END.OF.DOCUMENT---
Alchemy.
Alchemy, originally derived from the Ancient Greek word "khemia" (Χημία) meaning "art of transmuting metals", later arabicized as "al-kimia" (الكيمياء), is both a philosophy and an ancient practice focused on the attempt to change base metals into gold, investigating the preparation of the "elixir of longevity", and achieving ultimate wisdom, involving the improvement of the alchemist as well as the making of several substances described as possessing unusual properties. The practical aspect of alchemy generated the basics of modern inorganic chemistry, namely concerning procedures, equipment and the identification and use of many current substances.
Alchemy has been practiced in Mesopotamia (comprising much of today's Iraq), Egypt, Persia (today's Iran), India, China, Japan, Korea and in Classical Greece and Rome, in the Post-Islamic Persia, and then in Europe up to the 20th century, in a complex network of schools and philosophical systems spanning at least 2500 years.
Etymology.
The word alchemy derives in turn from the Old French "alkemie"; from the Medieval Latin "alchimia"; from the Arabic "al-kimia" (الكيمياء); and ultimately from the Ancient Greek "khemia" (Χημία) meaning "art of transmuting metals".
During the seventeenth century chemistry as a separate science was derived from Alchemy, with the work of Robert Boyle, sometimes known as "The father of Chemistry", who in his book "The Skeptical Chymist" attacked Paracelsus and the old Aristotelian concepts of the elements and laid down the foundations of modern chemistry.
Alchemy as a philosophical and spiritual discipline.
Alchemy became known as the "spagyric art" after Greek words meaning "to separate" and "to join together" in the 16th century, the word probably being coined by Paracelsus. Compare this with one of the dictums of Alchemy in Latin: Solve et Coagula — "Separate, and Join Together" (or "dissolve and coagulate").
The best-known goals of the alchemists were the transmutation of common metals into gold (called chrysopoeia) or silver (less well known is plant alchemy, or "spagyric"); the creation of a "panacea", or the elixir of life, a remedy that, it was supposed, would cure all diseases and prolong life indefinitely; and the discovery of a universal solvent. Although these were not the only uses for the discipline, they were the ones most documented and well-known. Certain Hermetic schools argue that the transmutation of lead into gold is analogical for the transmutation of the physical body (Saturn or lead) into (Gold) with the goal of attaining immortality. This is described as Internal Alchemy. Starting with the Middle Ages, Persian and European alchemists invested much effort in the search for the "philosopher's stone", a legendary substance that was believed to be an essential ingredient for either or both of those goals. Pope John XXII issued a bull against alchemical counterfeiting, and the Cistercians banned the practice amongst their members. In 1403, Henry IV of England banned the practice of Alchemy. In the late 14th century, Piers the Ploughman and Chaucer both painted unflattering pictures of Alchemists as thieves and liars. By contrast, Rudolf II, Holy Roman Emperor, in the late 16th century, sponsored various alchemists in their work at his court in Prague.
It is a popular belief that Alchemists made mundane contributions to the "chemical" industries of the day—ore testing and refining, metalworking, production of gunpowder, ink, dyes, paints, cosmetics, leather tanning, ceramics, glass manufacture, preparation of extracts, liquors, and so on (it seems that the preparation of "aqua vitae", the "water of life", was a fairly popular "experiment" among European alchemists). In reality, although Alchemists contributed distillation to Western Europe, they did little for any known industry. Long before Alchemists appeared, goldsmiths knew how to tell what was good gold or fake, and industrial technology grew by the work of the artisans themselves, rather than any Alchemical helpers.
The double origin of Alchemy in Greek philosophy as well as in Egyptian and Mesopotamian technology set, from the start, a double approach: the technological, operative one, which Marie-Louise von Franz call extravert, and the mystic, contemplative, psychological one, which von Franz names as introvert. These are not mutually exclusive, but complementary instead, as meditation requires practice in the real world, and conversely.
Several early alchemists, such as Zosimos of Panopolis, are recorded as viewing alchemy as a spiritual discipline, and, in the Middle Ages, metaphysical aspects, substances, physical states, and molecular material processes as mere metaphors for spiritual entities, spiritual states, and, ultimately, transformations. In this sense, the literal meanings of 'Alchemical Formulas' were a blind, hiding their true spiritual philosophy, which being at odds with the Medieval Christian Church was a necessity that could have otherwise led them to the "stake and rack" of the Inquisition under charges of heresy. Thus, both the transmutation of common metals into gold and the universal panacea symbolized evolution from an imperfect, diseased, corruptible, and ephemeral state towards a perfect, healthy, incorruptible, and everlasting state; and the philosopher's stone then represented a mystic key that would make this evolution possible. Applied to the alchemist himself, the twin goal symbolized his evolution from ignorance to enlightenment, and the stone represented a hidden spiritual truth or power that would lead to that goal. In texts that are written according to this view, the cryptic alchemical symbols, diagrams, and textual imagery of late alchemical works typically contain multiple layers of meanings, allegories, and references to other equally cryptic works; and must be laboriously "decoded" in order to discover their true meaning.
Q. When the Philosophers speak of gold and silver, from which they extract their matter, are we to suppose that they refer to the vulgar gold and silver?
A. By no means; vulgar silver and gold are dead, while those of the Philosophers are full of life.
Psychology.
Alchemical symbolism has been occasionally used by psychologists and philosophers. Carl Jung reexamined alchemical symbolism and theory and began to show the inner meaning of alchemical work as a spiritual path. Alchemical philosophy, symbols and methods have enjoyed something of a renaissance in post-modern contexts.
Jung saw alchemy as a Western proto-psychology dedicated to the achievement of individuation. In his interpretation, alchemy was the vessel by which Gnosticism survived its various purges into the Renaissance, a concept also followed by others such as Stephan A. Hoeller. In this sense, Jung viewed alchemy as comparable to a Yoga of the East, and more adequate to the Western mind than Eastern religions and philosophies. The practice of Alchemy seemed to change the mind and spirit of the Alchemist. Conversely, spontaneous changes on the mind of Western people undergoing any important stage in individuation seems to produce, on occasion, imagery known to Alchemy and relevant to the person's situation.
His interpretation of Chinese alchemical texts in terms of his analytical psychology also served the function of comparing Eastern and Western alchemical imagery and core concepts and hence its possible inner sources (archetypes).
Marie-Louise von Franz, a disciple of Jung, continued Jung's studies on Alchemy and its psychological meaning.
Magnum opus.
After the 15th century, many writers tended to compress "citrinitas" into "rubedo" and consider only three stages.
However, it is in citrinitas that the Chemical Wedding takes place, generating the Philosophical Mercury without which the Philosopher's Stone, triumph of the Work, could never be accomplished.
Within the Magnum Opus was the creation of the Sanctum Moleculae, that is the 'Sacred Masses' that were derived from the Sacrum Particulae, that is the 'Sacred Particles', needed to complete the process of achieving the Magnum Opus.
Alchemy as a subject of historical research.
The history of alchemy has become a vigorous academic field. As the obscure hermetic language of the alchemists is gradually being "deciphered", historians are becoming more aware of the intellectual connections between that discipline and other facets of Western cultural history, such as the sociology and psychology of the intellectual communities, kabbalism, spiritualism, Rosicrucianism, and other mystic movements, cryptography, witchcraft, and the evolution of science and philosophy.
History.
In a historical sense, Alchemy is the pursuit of transforming common metals into valuable gold. According to Marie-Louise von Franz, the initial basis for alchemy were Egyptian metal technology and mummification, Mesopotamian technology and astrology, and Pre-Socratic Greek philosophers such as Empedocles, Thales of Miletus and Heraclitus.
The origins of Western alchemy are traceable back to ancient Egypt. The Leyden papyrus X and the Stockholm papyrus along with the Greek magical papyri comprise the first "book" on alchemy still existent. Babylonian, Greek and Indian philosophers theorized that there were only four classical elements (rather than today's 117 chemical elements, a useful analogy is with the highly similar states of matter); Earth, Fire, Water, and Air. The Greek philosophers, in order to prove their point, burned a log: The log was the earth, the flames burning it was fire, the smoke being released was air, and the smoldering soot at the bottom was bubbling water. Because of this, the belief that these four "elements" were at the heart of everything soon spread, only later being replaced in the Middle Ages by Geber's theory of seven elements, which was then replaced by the modern theory of chemical elements during the early modern period.
Alchemy encompasses several philosophical traditions spanning four millennia and three continents. These traditions' general penchant for cryptic and symbolic language makes it hard to trace their mutual influences and "genetic" relationships. Alchemy starts becoming much clearer in the 8th century with the works of the Islamic alchemist, Jabir ibn Hayyan (known as "Geber" in Europe), who introduced a methodical and experimental approach to scientific research based in the laboratory, in contrast to the ancient Greek and Egyptian alchemists whose works were mainly allegorical.
Other famous alchemists include Rhazes, Avicenna and Imad ul-din in Persia; Wei Boyang in Chinese alchemy; and Nagarjuna in Indian alchemy; and Albertus Magnus and Pseudo-Geber in European alchemy; as well as the anonymous author of the "Mutus Liber", published in France in the late 17th century, which was a 'wordless book' that claimed to be a guide to making the philosopher's stone, using a series of 15 symbols and illustrations. The philosopher's stone was an object that was thought to be able to amplify one's power in alchemy and, if possible, grant the user ageless immortality, unless he fell victim to burnings or drowning; the common belief was that fire and water were the two greater elements that were implemented into the creation of the stone.
In the case of the Chinese and European alchemists, there was a difference between the two. The European alchemists tried to transmute lead into gold, and, no matter how futile or toxic the element, would continue trying until it was royally outlawed later into the century. The Chinese, however, paid no heed to the philosopher's stone or transmutation of lead to gold; they focused more on medicine for the greater good. During Enlightenment, these "elixirs" were a strong cure for sicknesses, unless it was a test medicine. In general, most tests were fatal, but stabilized elixirs served great purposes. On the other hand, the Islamic alchemists were interested in alchemy for a variety of reasons, whether it was for the transmutation of metals or artificial creation of life, or for practical uses such as medicine.
Modern connections to alchemy.
Persian alchemy was a forerunner of modern scientific chemistry. Alchemists used many of the same laboratory tools that are used today. These tools were not usually sturdy or in good condition, especially during the medieval period of Europe. Many transmutation attempts failed when alchemists unwittingly made unstable chemicals. This was made worse by the unsafe conditions in which the alchemists worked.
Up to the 16th century, alchemy was considered serious science in Europe; for instance, Isaac Newton devoted considerably more of his writing to the study of alchemy (see Isaac Newton's occult studies) than he did to either optics or physics, for which he is famous. Other eminent alchemists of the Western world are Roger Bacon, Saint Thomas Aquinas, Tycho Brahe, Thomas Browne, and Parmigianino. The decline of alchemy began in the 18th century with the birth of modern chemistry, which provided a more precise and reliable framework for matter transmutations and medicine, within a new grand design of the universe based on rational materialism.
Alchemy in traditional medicine.
Traditional medicines involve transmutation by alchemy, using pharmacological or a combination of pharmacological and spiritual techniques. In Chinese medicine the alchemical traditions of pao zhi will transform the nature of the temperature, taste, body part accessed or toxicity. In Ayurveda the samskaras are used to transform heavy metals and toxic herbs in a way that removes their toxicity. These processes are actively used to the present day.
Nuclear transmutation.
In 1919, Ernest Rutherford used artificial disintegration to convert nitrogen into oxygen. From then on, this sort of "scientific transmutation" has been routinely performed in many nuclear physics-related laboratories and facilities, like particle accelerators, nuclear power stations and nuclear weapons as a by-product of fission and other physical processes.
In literature.
A play by Ben Jonson, The Alchemist, is a satirical and skeptical take on the subject.
Part 2 of Goethe's Faust, is full of alchemical symbolism.
According to "Hermetic Fictions: Alchemy and Irony in the Novel" (Keele University Press, 1995), by David Meakin, alchemy is also featured in such novels and poems as those by William Godwin, Percy Bysshe Shelley, Emile Zola, Jules Verne, Marcel Proust, Thomas Mann, Hermann Hesse, James Joyce, Gustav Meyrink, Lindsay Clarke, Marguerite Yourcenar, Umberto Eco, Michel Butor, Paulo Coelho, Amanda Quick, Gabriel García Marquez and Maria Szepes.
Hilary Mantel, in her novel Fludd (1989, Penguin), mentions the spagyric art. 'After separation, drying out, moistening, dissolving, coagulating, fermenting, comes purification, recombination: the creation of substances the world until now has never beheld. This is the opus contra naturem, this is the spagyric art, this is the Alchymical Wedding'. (page 79)
In Dante's Inferno, it is placed within the Tenth ring of the 8th circle.
In Angie Sage's Septimus Heap series, Marcellus Pye is an important Alchemist that first appears in Physik, the third book.
In The Secrets of the Immortal Nicholas Flamel series, one of the main characters is a alchemist.
The manga and anime series Fullmetal Alchemist bases itself of a more fantasised version of alchemy.
In contemporary art.
In the twentieth century alchemy was a profoundly important source of inspiration for the Surrealist artist Max Ernst, who used the symbolism of alchemy to inform and guide his work. M.E. Warlick wrote his "Max Ernst and Alchemy" describing this relationship in detail.
Contemporary artists use alchemy as inspiring subject matter, like Odd Nerdrum, whose interest has been noted by Richard Vine, and the painter Michael Pearce, whose interest in alchemy dominates his work. His works "Fama" and "The Aviator's Dream" particularly express alchemical ideas in a painted allegory.
---END.OF.DOCUMENT---
Austria.
Austria (), officially the Republic of Austria (German:; Austro-Bavarian: Repubblik Östareich), is a landlocked country of roughly 8.3 million people in Central Europe. It borders Germany and the Czech Republic to the north, Slovakia and Hungary to the east, Slovenia and Italy to the south, and Switzerland and Liechtenstein to the west. The territory of Austria covers, and has a temperate and alpine climate. Austria's terrain is highly mountainous due to the presence of the Alps; only 32% of the country is below, and its highest point is. The majority of the population speaks German, which is also the country's official language. Other local official languages are Croatian, Hungarian and Slovene.
The origins of Austria date back to the time of the Roman Empire when a Celtic kingdom was conquered by the Romans in approximately 15 BC, and later became Noricum, a Roman province, in the mid 1st century AD—an area which mostly encloses today's Austria. In 788 AD, the Frankish king Charlemagne conquered the area, and introduced Christianity. Under the native Habsburg dynasty, Austria became one of the great powers of Europe. In 1867, the Austrian Empire was reformed into Austria-Hungary. The Austro-Hungarian Empire collapsed in 1918 with the end of World War I. After establishing the First Austrian Republic in 1919 Austria was de facto annexed into Greater Germany by the Nazi regime in the so-called Anschluss in 1938. This lasted until the end of World War II in 1945, after which Austria was occupied by the Allies. In 1955, the Austrian State Treaty re-established Austria as a sovereign state, ending the occupation. In the same year, the Austrian Parliament created the Declaration of Neutrality which declared that the country would become permanently neutral.
Today, Austria is a parliamentary representative democracy comprising nine federal states. The capital—and with a population exceeding 1.6 million, Austria's largest city—is Vienna. Austria is one of the richest countries in the world, with a nominal per capita GDP of $43,570. The country has developed a high standard of living, and in 2008 was ranked 14th in the world for its Human Development Index. Austria has been a member of the United Nations since 1955, joined the European Union in 1995, and is a founder of the OECD. Austria also signed the Schengen Agreement in 1995, and adopted the European currency, the euro, in 1999.
Etymology.
The German name of Austria, derives from the Old High German word Ostarrîchi "eastern realm", first attested in the famous "Ostarrîchi document" of AD 996, where the term refers to the Margraviate ruled by the Babenberg Count Henry I located mostly in what is today Lower Austria and part of Upper Austria. The name Austria is a latinisation of the same Germanic word for "east", *austrō also found in "Austrasia", the eastern part of Merovingian Francia.
German "Österreich" is readily analysable as connected to "östlich" "eastern" and "Reich" "realm, dominion, empire". The term probably originates in a vernacular translation of the Medieval Latin name for the region:, which translates as "eastern marches" or "eastern borderland", as it was situated at the eastern edge of the Holy Roman Empire.==
However, Friedrich Heer, one of the most important Austrian historians in the 20th century, stated in his book "Der Kampf um die österreichische Identität" ("The Struggle Over Austrian Identity"), that the Germanic form "Ostarrîchi" was not a translation of the Latin word, but both resulted from a much older term originating in the Celtic languages of ancient Austria: More than 2,500 years ago, the major part of the actual country was called "Norig" by the Celtic population (Hallstatt culture); "No-" or "Nor-" meant "east" or "eastern", whereas "-rig" is related to the modern German "Reich"; meaning "realm". Accordingly, "Norig" would essentially mean "Ostarrîchi" and "Österreich", thus "Austria". The Celtic name was eventually Latinised to "Noricum" after the Romans conquered the area that encloses most of modern day Austria, in approximately 15 BC. "Noricum" later became a Roman province in the mid 1st century AD.
History.
Settled in ancient times, the Central European land that is now Austria was occupied in pre-Roman times by various Celtic tribes. The Celtic kingdom of Noricum was later claimed by the Roman Empire and made a province. Present day Petronell-Carnuntum in Eastern Austria was an important army camp turned capital city in what became known as the Upper Pannonia province. Fifty thousand people called Carnuntum home for nearly 400 years.
After the fall of the Roman Empire the area was invaded by Bavarians, Slavs and Avars. The Slavic tribe of the Carantanians migrated into the Alps, and established the realm of Carantania, which covered much of eastern and central Austrian territory. Charlemagne conquered the area in 788 AD, encouraged colonisation and introduced Christianity. As part of Eastern Francia, the core areas that now encompass Austria were bequeathed to the house of Babenberg. The area was known as the "marchia Orientalis" and was given to Leopold of Babenberg in 976.
The first record showing the name Austria is from 996 where it is written as "Ostarrîchi", referring to the territory of the Babenberg March. In 1156 the Privilegium Minus elevated Austria to the status of a duchy. In 1192, the Babenbergs also acquired the Duchy of Styria. With the death of Frederick II in 1246, the line of the Babenbergs went extinct.
As a result Otakar II of Bohemia effectively assumed control of the duchies of Austria, Styria and Carinthia. His reign came to an end with his defeat at Dürnkrut at the hands of Rudolf I of Germany in 1278. Thereafter, until World War I, Austria's history was largely that of its ruling dynasty, the Habsburgs.
In the 14th and 15th centuries, the Habsburgs began to accumulate other provinces in the vicinity of the Duchy of Austria. In 1438 Duke Albert V of Austria was chosen as the successor to his father-in-law, Emperor Sigismund. Although Albert himself only reigned for a year, every emperor of the Holy Roman Empire was a Habsburg, with only one exception.
The Habsburgs began also to accumulate lands far from the hereditary lands. In 1477 Archduke Maximilian, only son of Emperor Frederick III, married the heiress Maria of Burgundy, thus acquiring most of the Netherlands for the family. His son Philip the Fair married the heiress of Castile and Aragon, and thus acquired Spain and its Italian, African and New World appendages for the Habsburgs. In 1526 following the Battle of Mohács, Bohemia and the part of Hungary not occupied by the Ottomans came under Austrian rule. Ottoman expansion into Hungary led to frequent conflicts between the two empires, particularly evident in the so-called Long War of 1593 to 1606.
During the long reign of Leopold I (1657–1705) and following the successful defense of Vienna in 1683 (under the command of the King of Poland, John III Sobieski), a series of campaigns resulted in bringing all of Hungary to Austrian control by the Treaty of Carlowitz in 1699.
Emperor Charles VI relinquished many of the fairly impressive gains the empire made in the previous years, largely due to his apprehensions at the imminent extinction of the House of Habsburg. Charles was willing to offer concrete advantages in territory and authority in exchange for other powers' worthless recognitions of the Pragmatic Sanction that made his daughter Maria Theresa his heir. With the rise of Prussia the Austrian–Prussian dualism began in Germany. Austria participated, together with Prussia and Russia, in the first and the third of the three Partitions of Poland (in 1772 and 1795).
Austria later became engaged in a war with Revolutionary France, at the beginning highly unsuccessful, with successive defeats at the hands of Napoleon meaning the end of the old Holy Roman Empire in 1806. Two years earlier, in 1804, the Empire of Austria was founded. In 1814 Austria was part of the Allied forces that invaded France and brought to an end the Napoleonic wars.
It thus emerged from the Congress of Vienna in 1815 as one of four of the continent's dominant powers and a recognised great power. The same year, the German Confederation, () was founded under the presidency of Austria. Because of unsolved social, political and national conflicts the German lands were shaken by the 1848 revolution aiming to create a unified Germany. A unified Germany would have been possible either as a Greater Germany, or a Greater Austria or just the German Confederation without Austria at all. As Austria was not willing to relinquish its German-speaking territories to what would become the German Empire of 1848, the crown of the newly-formed empire was offered to the Prussian King Friedrich Wilhelm IV. In 1864 Austria and Prussia fought together against Denmark, and successfully freed the independent duchies of Schleswig and Holstein. Nevertheless as they could not agree on a solution to the administration of the two duchies, they fought in 1866 the Austro-Prussian War. Defeated by Prussia in the Battle of Königgrätz, Austria had to leave the German Confederation and subsequently no longer took part in German politics.
The Austro-Hungarian Compromise of 1867, the "Ausgleich", provided for a dual sovereignty, the Austrian Empire and the Kingdom of Hungary, under Franz Joseph I. The Austrian-Hungarian rule of this diverse empire included various Slavic groups including Croats, Czechs, Poles, Rusyns, Serbs, Slovaks, Slovenes and Ukrainians, as well as large Italian and Romanian communities.
As a result, ruling Austria–Hungary became increasingly difficult in an age of emerging nationalist movements. Yet the government of Austria tried its best to be accommodating in some respects: The "Reichsgesetzblatt", publishing the laws and ordinances of Cisleithania, was issued in eight languages, all national groups were entitled to schools in their own language and to the use of their mothertongue at state offices, for example. The government of Hungary to the contrary tried to magyarise other ethnic entities. Thus the wishes of ethnic groups dwelling in both parts of the dual monarchy hardly could be solved.
The assassination of Archduke Franz Ferdinand in Sarajevo in 1914 by Gavrilo Princip (a member of the Serbian nationalist group the Black Hand) was used by leading Austrian and Hungarian politicians and generals to persuade the emperor to declare war on Serbia, thereby risking and prompting the outbreak of World War I which led to the dissolution of the Austro-Hungarian Empire. Over one million Austro-Hungarian soldiers died in World War I.
On October 21, 1918, the elected German members of the "Reichsrat" (parliament of Imperial Austria) met in Vienna as the Provisional National Assembly for German Austria ("Provisorische Nationalversammlung für Deutschösterreich"). On October 30 the assembly founded the State of German Austria by appointing a government, called "Staatsrat". This new government was invited by the emperor to take part in the decision on the planned armistice with Italy, but refrained from this business; this left the responsibility for the end of the war on November 3, 1918, solely to the emperor and his government. On November 11 the emperor, counseled by ministers of the old and the new government, declared he would not take part in state business any more; on November 12 German Austria, by law, declared itself to be a democratic republic and part of the new German republic. The constitution, renaming "Staatsrat" to "Bundesregierung" (federal government) and "Nationalversammlung" to "Nationalrat" (national council) was passed on November 10, 1920.
The Treaty of Saint-Germain of 1919 (for Hungary the Treaty of Trianon of 1920) confirmed and consolidated the new order of Central Europe which to a great part had been established in November 1918, creating new states and resizing others. Over 3-million German Austrians found themselves living outside of the newborn Austrian Republic in the respective states of Czechoslovakia, Yugoslavia, Hungary and Italy. Between 1918 and 1919 Austria was officially known as the State of German Austria (). Not only did the Entente powers forbid German Austria to unite with Germany, they also ignored the name German Austria in the peace treaty to be signed; it was therefore changed to Republic of Austria in late 1919.
After the war inflation began to devaluate the "Krone", still Austria's currency. In the autumn of 1922 Austria was granted an international loan supervised by the League of Nations. The purpose of the loan was to avert bankruptcy, stabilise the currency and improve its general economic condition. With the granting of the loan, Austria passed from an independent state to the control exercised by the League of Nations. In 1925 the "Schilling", replacing the "Krone" by 10,000:1, was introduced. Later it was called the Alpine dollar due to its stability. From 1925 to 1929 the economy enjoyed a short high before nearly crashing after Black Friday.
The First Austrian Republic lasted until 1933 when Chancellor Engelbert Dollfuss, gladly using what he called "self-switch-off of Parliament" (), established an autocratic regime tending toward Italian fascism. The two big parties at this time, the Social Democrats and the Conservatives, had paramilitary armies; the Social Democrats' "Schutzbund" was now declared illegal but still operative as civil war broke out.
In February 1934 several members of the "Schutzbund" were executed, the Social Democratic party was outlawed and many of its members were imprisoned or emigrated. On 1 May 1934, the Austrofascists imposed a new constitution ("Maiverfassung") which cemented Dollfuss's power but on 25 July he was assassinated in a Nazi coup attempt.
His successor, Kurt Schuschnigg, struggled to keep Austria independent as "the better German state", but on 12 March 1938, German troops occupied the country while Austrian Nazis took over government. On 13 March 1938, the "Anschluss" of Austria was officially declared. Two days later Hitler, a native of Austria, proclaimed the re-unification of his home country with the rest of Germany on Vienna's Heldenplatz. He established a plebiscite confirming union with Germany in April 1938.
Austria was incorporated into the Third Reich and ceased to exist as an independent state. The Aryanisation of the wealth of Jewish Austrians started immediately mid-March with a so called "wild" (i.e. extra-legal) phase but soon was structured legally and bureaucratically to strip Jewish citizens of any asset they may have possessed. The Nazis called Austria "Ostmark" until 1942 when it was again renamed and called "Alpen-Donau-Reichsgaue". Vienna fell on 13 April 1945, during the Soviet Vienna Offensive just before the total collapse of the Third Reich.
Karl Renner and Adolf Schärf (Socialist Party of Austria [Social Democrats and Revolutionary Socialists]), Leopold Kunschak (Austria's People's Party [former Christian Social People's Party]) and Johann Koplenig (Communist Party of Austria) declared Austria's secession from the Third Reich by the Declaration of Independence on 27 April 1945, and set up a provisional government in Vienna under state Chancellor Renner the same day, with the approval of the victorious Red Army and backed by Stalin. (The date is officially named the birthday of the second republic.) At the end of April, most of Western and Southern Austria still was under Nazi rule. On May 1, 1945, the federal constitution of 1929 was put into validity again, which had been terminated by dictator Dollfuss on May 1, 1934.
Total military deaths from 1939–1945 are estimated at 260,000. Jewish Holocaust victims totaled 65,000. About 140,000 Jewish Austrians had fled the country in 1938–39. Thousands of Austrians had taken part in serious Nazi crimes, a fact officially recognised by Chancellor Franz Vranitzky in 1992.
Much like Germany, Austria was divided into a British, a French, a Soviet and a U.S. zone and governed by the Allied Commission for Austria. As forecast in the Moscow Declaration in 1943, there was a subtle difference in the treatment of Austria by the Allies. The Austrian Government, consisting of Social Democrats, Conservatives and Communists (until 1947) and residing in Vienna, which was surrounded by the Soviet zone, was recognised by the Western Allies in October 1945 after some doubts that Renner could be Stalin's puppet. Thereby the creation of a separate Western Austrian government and the division of the country could be avoided. Austria, in general, was treated as though it had been originally invaded by Germany and liberated by the Allies.
On 15 May 1955, after talks which lasted for years and were influenced by the Cold War Austria regained full independence by concluding the Austrian State Treaty with the Four Occupying Powers. On 26 October 1955, after all occupation troops had left, Austria declared its "permanent neutrality" by an act of Parliament, which remains to this day but has been implicitly overlapped by constitutional amendments concerning Austria as member of the European Union from 1995 onward.
The political system of the Second Republic is based on the constitution of 1920 and 1929, which was reintroduced in 1945. The system came to be characterised by "Proporz", meaning that most posts of political importance were split evenly between members of the Social Democrats and the People's Party. Interest group "chambers" with mandatory membership (e.g. for workers, business people, farmers) grew to considerable importance and were usually consulted in the legislative process, so that hardly any legislation was passed that did not reflect widespread consensus. Since 1945 a single-party government took place only 1966–1970 (Conservatives) and 1970–1983 (Social Democrats). During all other legislative periods, either a grand coalition of Conservatives and Social Democrats or a "small coalition" (one of these two and a smaller party) ruled the country.
Following a referendum in 1994, at which consent reached a majority of two thirds, the country became a member of the European Union on 1 January 1995. According to its economic success, Austria is one of the "net contributors" of the union.
The major parties SPÖ and ÖVP have contrary opinions about the future status of Austria's military non-alignment: While the SPÖ in public supports a neutral role, the ÖVP argues for stronger integration into the EU's security policy; even a future NATO membership is not ruled out by some ÖVP politicians. In reality, Austria is taking part in the EU's Common Foreign and Security Policy, participates in the so-called Petersburg Agenda (including peace keeping and peace creating tasks) and has become member of NATO's "Partnership for Peace"; the constitution has been amended accordingly. The term "neutrality" is only used to tranquilise voters afraid of change. Since 2008, due to the Schengen Agreement, the only neighbouring country performing border controls towards Austria is Liechtenstein.
Political system.
The Parliament of Austria is located in Vienna, the country's largest city and capital. Austria became a federal, parliamentarian, democratic republic through the Federal Constitution of 1920. It was reintroduced in 1945 to the nine states of the Federal Republic. The head of state is the Federal President ("Bundespräsident"), who is directly elected by popular vote. The chairman of the Federal Government is the Federal Chancellor, who is appointed by the president. The government can be removed from office by either a presidential decree or by vote of no confidence in the lower chamber of parliament, the Nationalrat. Voting for the federal president and for the Parliament used to be compulsory in Austria, but this was abolished in steps from 1982 to 2004.
The Parliament of Austria consists of two chambers. The composition of the Nationalrat (183 seats) is determined every five years (or whenever the Nationalrat has been dissolved by the federal president on a motion by the federal chancellor, or by Nationalrat itself) by a general election in which every citizen over 16 years (since 2007) has voting rights. While there is a general threshold of 4 percent for all parties at federal elections (Nationalratswahlen), there remains the possibility to gain a direct seat, or, in one of the 43 regional election districts.
The Nationalrat is the dominant chamber in the formation of legislation in Austria. However, the upper house of parliament, the Bundesrat, has a limited right of veto (the Nationalrat can—in almost all cases—ultimately pass the respective bill by voting a second time. This is referred to as Beharrungsbeschluss", lit. "vote of persistence"). A convention, called the was convened in June 30, 2003 to decide upon suggestions to reform the constitution, but failed to produce a proposal that would receive the two-thirds of votes in the Nationalrat necessary for constitutional amendments and/or reform.
With legislative and executive, the courts are the third column of Austrian state powers. Notably the Constitutional Court ("Verfassungsgerichtshof") may exert considerable influence on the political system by ruling out laws and ordinances not in compliance with the constitution. Since 1995, the European Court of Justice may overrule Austrian decisions in all matters defined in laws of the European Union. Concerning human rights, Austria also is implementing the decisions of the European Court of Human Rights, since the European Convention on Human Rights is part of the Austrian constitution.
Recent developments.
After general elections held in October 2006, the Social Democrats emerged as the largest party, whereas the People's Party lost about 8% in votes. Political realities prohibited any of the two major parties from forming a coalition with smaller parties. In January 2007 the People's Party and Social Democrats formed a grand coalition with the social democrat Alfred Gusenbauer as Chancellor. This coalition broke up in June 2008. Elections in September 2008 further weakened both major parties (Social Democrats and People's Party) but together they still held more than 50% of the votes with the Social Democrats holding the majority. They formed a coalition with Werner Faymann from the Social Democrats as Chancellor. The positions of the Freedom Party and the deceased Jörg Haider's new party Alliance for the Future of Austria, both right-wing parties, were strengthened during the election.
Foreign policy.
The 1955 Austrian State Treaty ended the occupation of Austria following World War II and recognised Austria as an independent and sovereign state. On 26 October 1955, the Federal Assembly passed a constitutional article in which "Austria declares of her own free will her perpetual neutrality". The second section of this law stated that "in all future times Austria will not join any military alliances and will not permit the establishment of any foreign military bases on her territory". Since then, Austria has shaped its foreign policy on the basis of neutrality, but rather different from the neutrality of Switzerland.
Austria began to reassess its definition of neutrality following the fall of the Soviet Union, granting overflight rights for the UN-sanctioned action against Iraq in 1991, and, since 1995, it has developed participation in the EU's Common Foreign and Security Policy (CFSP). Also in 1995, it joined the Partnership for Peace and subsequently participated in peacekeeping missions in Bosnia. Meanwhile, the only part of the Constitutional Law on Neutrality of 1955 still valid fully is not to allow foreign military bases in Austria.
Austria attaches great importance to participation in the Organisation for Economic Co-operation and Development and other international economic organisations, and it has played an active role in the Organization for Security and Cooperation in Europe (OSCE).
Energy politics.
In 1972, the country began construction of a nuclear-powered electricity-generation station at Zwentendorf on the River Danube, following a unanimous vote in parliament. However, in 1978, a referendum voted approximately 50.5% against nuclear power, 49.5% for, and parliament subsequently unanimously passed a law forbidding the use of nuclear power to generate electricity.
Austria currently produces more than half of its electricity by hydropower. Together with other renewable energy sources such as wind, solar and biomass powerplants, the electricity supply from renewable energy amounts to 62.89% of total use in Austria, with the rest being produced by gas and oil powerplants.
Military.
The manpower of the Austrian Armed Forces () mainly relies on conscription. All males who have reached the age of eighteen and are found fit have to serve a six months military service, followed by an eight year reserve obligation. Both males and females at the age of sixteen are eligible for voluntary service. Conscientious objection is legally acceptable and those who claim this right are obliged to serve an institutionalised nine months civilian service instead. Since 1998, women volunteers have been allowed to become professional soldiers.
The main sectors of the Bundesheer are Joint Forces (Streitkräfteführungskommando, SKFüKdo) which consist of Land Forces (Landstreitkräfte), Air Forces (Luftstreitkräfte), International Missions (Internationale Einsätze) and Special Forces (Spezialeinsatzkräfte), next to Mission Support (Kommando Einsatzunterstützung; KdoEU) and Command Support (Kommando Führungsunterstützung; KdoFüU). Being a landlocked country, Austria has no navy.
In 2004, Austria's defence expenditures corresponded to approximately 0.9% of its GDP. The Army currently has about 45,000 soldiers, of whom about half are conscripts. As head of state, Austrian President (currently Heinz Fischer) is nominally the Commander-in-Chief of the Bundesheer. In practical reality, however, command of the Austrian Armed Forces is almost exclusively exercised by the Minister of Defense, currently Norbert Darabos.
Since the end of the Cold War, and more importantly the removal of the former heavily guarded "Iron Curtain" separating Austria and Hungary, the Austrian military has been assisting Austrian border guards in trying to prevent border crossings by illegal immigrants. This assistance came to an end when Hungary joined the EU Schengen area in 2008, for all intents and purposes abolishing "internal" border controls between treaty states. Some politicians have called for a prolongation of this mission, but the legality of this is heavily disputed. In accordance with the Austrian constitution, armed forces may only be deployed in a limited number of cases, mainly to defend the country and aid in cases of national emergency, such as in the wake of natural disasters. They may generally not be used as auxiliary police forces.
Within its self-declared status of permanent neutrality, Austria has a long and proud tradition of engaging in UN-led peacekeeping and other humanitarian missions. The Austrian Forces Disaster Relief Unit (AFDRU), in particular, an all-volunteer unit with close ties to civilian specialists (e.g. rescue dog handlers) enjoys a reputation as a quick (standard deployment time is 10 hours) and efficient SAR unit. Currently, larger contingents of Austrian forces are deployed in Bosnia, Kosovo and, since 1974, in the Golan Heights.
States.
As a federal republic, Austria is divided into nine states (). These states are then divided into districts () and statutory cities (). Districts are subdivided into municipalities (). Statutory Cities have the competencies otherwise granted to both districts and municipalities. The states are not mere administrative divisions but have some legislative authority distinct from the federal government, e.g. in matters of culture, social care, youth and nature protection, hunting, building, and zoning ordinances. In recent years, it has been discussed whether today it is appropriate for a small country to maintain ten parliaments.
Geography.
Austria is a largely mountainous country due to its location in the Alps. The Central Eastern Alps, Northern Limestone Alps and Southern Limestone Alps are all partly in Austria. Of the total area of Austria (), only about a quarter can be considered low lying, and only 32% of the country is below. The Alps of western Austria give way somewhat into low lands and plains in the eastern part of the country.
Austria can be divided into five areas, the biggest being the Eastern Alps, which constitute 62% of nation's total area. The Austrian foothills at the base of the Alps and the Carpathians account for around 12% and the foothills in the east and areas surrounding the periphery of the Pannoni low country amount to about 12% of the total landmass. The second greater mountain area (much lower than the Alps) is situated in the north. Known as the Austrian granite plateau, it is located in the central area of the Bohemian Mass, and accounts for 10% of Austria. The Austrian portion of the Vienna basin comprises the remaining 4%.
Phytogeographically, Austria belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the WWF, the territory of Austria can be subdivided into four ecoregions: the Central European mixed forests, Pannonian mixed forests, Alps conifer and mixed forests and Western European broadleaf forests.
Climate.
The greater part of Austria lies in the cool/temperate climate zone in which humid westerly winds predominate. With over half of the country dominated by the Alps, the alpine climate is the predominant one. In the east—in the Pannonian Plain and along the Danube valley—the climate shows continental features with less rain than the alpine areas. Although Austria is cold in the winter, summer temperatures can be relatively warm—reaching temperatures of around 20 – 40 °C.
Economy.
Austria is one of the 12 richest countries in the world in terms of GDP (Gross domestic product) per capita, has a well-developed social market economy, and a high standard of living. Until the 1980s, many of Austria's largest industry firms were nationalised; in recent years, however, privatisation has reduced state holdings to a level comparable to other European economies. Labour movements are particularly strong in Austria and have large influence on labour politics. Next to a highly developed industry, international tourism is the most important part of the national economy.
Germany has historically been the main trading partner of Austria, making it vulnerable to rapid changes in the German economy. However, since Austria became a member state of the European Union it has gained closer ties to other European Union economies, reducing its economic dependence on Germany. In addition, membership in the EU has drawn an influx of foreign investors attracted by Austria's access to the single European market and proximity to the aspiring economies of the European Union. Growth in GDP accelerated in recent years and reached 3.3% in 2006.
Currency.
In Austria, the euro was introduced as an accounting currency on 1 January 1999, and euro coins and banknotes entered circulation on 1 January 2002. As a preparation for this date, the minting of the new euro coins started as early as 1999, however all Austrian euro coins introduced in 2002 have this year on it; unlike other countries of the Eurozone where mint year is minted in the coin. Eight different designs, one per face value, were selected for the Austrian coins. In 2007, to adopt the new common map like the rest of the Eurozone countries, Austria changed the common side of its coins.
Before adopting the Euro in 2002 Austria had maintained use of the Austrian schilling which was first established in December 1924. The Schilling was abolished in the wake of the Anschluss in 1938 and has been reintroduced after the end of the World War II in November 1945.
Austria has one of the richest collection of collectors' coins in the Eurozone, with face value ranging from 10 to 100 euro (although a 100,000 euro coin was exceptionally minted in 2004). These coins are a legacy of an old national practice of minting of silver and gold coins. Unlike normal issues, these coins are not legal tender in all the eurozone. For instance, a €5 Austrian commemorative coin cannot be used in any other country.
Education.
Responsibility for educational oversight in Austria is entrusted partly to the Austrian states (Bundesländer), and partly to the federal government. School attendance is compulsory for nine years, i.e. usually to the age of fifteen.
Kindergarten education, free in most states, is provided for all children between the ages of three and six years and, whilst optional, is considered a normal part of a child's education, due to its high takeup rate. Maximum class size is around 30, each class normally being cared for by one qualified teacher and one assistant. Standard attendance times are 8am to 12am, with extra afternoon care also frequently provided for a fee.
Primary education, or Volksschule, lasts for four years, starting at age six. Maximum class size is 30, but may be as low as 15. It is generally expected that a class will be taught by one teacher for the entire four years and the stable bond between teacher and pupil is considered important for a child's well-being. The "3Rs" dominate lesson time, with less time allotted to project work than in the UK. Children work individually and all members of a class follow the same plan of work. There is no streaming. Lessons begin at 8am and last until noon or 1pm with hourly five- or ten-minute breaks. Children are given homework daily from the first year. Historically there has been no lunch hour, children returning home to eat. However, due to a rise in the number of mothers in work, primary schools are increasingly offering pre-lesson and afternoon care.
As in Germany, secondary education consists of two main types of schools, attendance at which is based on a pupil's ability as determined by grades from the primary school. The Gymnasium caters for the more able children, in the final year of which the Matura examination is taken, which is a requirement for access to university. The Hauptschule prepares pupils for vocational education but also for various types of further education (HTL = institution of higher technical education; HAK = commercial academy; HBLA = institution of higher education for economic business; etc.). Attendance at one of these further education institutes also leads to the Matura. Some schools aim to combine the education available at the Gymnasium and the Hauptschule, and are known as Gesamtschulen. In addition, a recognition of the importance of learning English has led some Gymnasiums to offer a bilingual stream, in which pupils deemed able in languages follow a modified curriculum, a portion of the lesson time being conducted in English.
As at primary school, lessons at Gymnasium begin at 8am, and continue with short intervals until lunchtime or early afternoon, with children returning home to a late lunch. Older pupils often attend further lessons after a break for lunch, generally eaten at school. As at primary level, all pupils follow the same plan of work. Great emphasis is placed on homework and frequent testing. Satisfactory marks in the end-of-the-year report ("Zeugnis") are a prerequisite for moving up ("aufsteigen") to the next class. Pupils who do not meet the required standard re-sit their tests at the end of the summer holidays; those whose marks are still not satisfactory are required to re-sit the year ("sitzenbleiben"). It is not uncommon for a pupil to re-sit more than one year of school. After completing the first two years, pupils choose between one of two strands, known as "Gymnasium" (slightly more emphasis on arts) or "Realgymnasium" (slightly more emphasis on science). Whilst many schools offer both strands, some do not, and as a result, some children move schools for a second time at age 12. At age 14, pupils may choose to remain in one of these two strands, or to change to a vocational course, possibly with a further change of school.
The Austrian university system had been open to any student who passed the Matura examination until recently. A 2006 bill allowed the introduction of entrance exams for studies such as Medicine. In 2001, an obligatory tuition fee ("Studienbeitrag") of €363.36 per term was introduced for all public universities. Since 2008, for all EU students the studies are free of charge, as long as a certain time-limit is not exceeded (the expected duration of the study plus usually two terms tolerance). When the time-limit is exceeded, the fee of around €363.36 per term is charged. Some further exceptions to the fee apply, e.g. for students with a year's salary of more than about €5000. In all cases, an obligatory fee of €15.50 for the student union and insurance is charged.
Demographics.
Austria's population estimate in January 2009 was 8,356,707. The population of the capital, Vienna, exceeds 1.6 million (2.2 million including the suburbs), representing about a quarter of the country's population. It is known for its vast cultural offerings and high standard of living.
Vienna is by far the country's largest city. Graz is second in size, with 250,099 inhabitants, followed by Linz (188,968), Salzburg (150,000), and Innsbruck (117,346). All other cities have fewer than 100,000 inhabitants.
Language.
German, Austria's official language, is spoken natively by 88.6% of the population—followed by Turkish (2.3%), Serbian (2.2%), Croatian (1.6%), Hungarian (0.5%), and Bosnian (0.4%). The Austrian federal states of Carinthia and Styria are home to a significant indigenous Slovene-speaking minority with around 14,000 members (Austrian census; unofficial numbers of Slovene groups speak of up to 50,000). In the eastermost state, Burgenland (formerly part of the Hungarian portion of Austria–Hungary), about 20,000 Austrian citizens speak Hungarian and 30,000 speak Croatian. Of the remaining number of Austria's people that are of non-Austrian descent, many come from surrounding countries, especially from the former East Bloc nations. So-called guest workers "(Gastarbeiter)" and their descendants, as well as refugees from the Yugoslav wars and other conflicts, also form an important minority group in Austria. Since 1994 the Roma–Sinti (gypsies) are an officially recognised ethnic minority in Austria.
According to census information published by Statistik Austria for 2001 there were a total of 710,926 foreign nationals living in Austria. Of these, 124,392 speak German as their mother tongue (mainly immigrants from Germany, some from Switzerland and South Tyrol, Italy) The next largest populations of linguistic and ethnic groups are 240,863 foreign nationals from the former Yugoslavia (Serbs being the largest number of these at 135,376, followed by Croatian at 105,487); 123,417 Turkish nationals; 25,155 whose native tongue is English; 24,446 Albanian; 17,899 Polish; 14,699 Hungarian; 12,216 Romanian; 7,982 Arabs; 6,902 Slovenes (not including the autochthonous minority); 6,891 Slovaks; 6,707 Czech; 5,916 Persian; 5,677 Italian; 5,466 Russian; 5,213 French; 4,938 Chinese; 4,264 Spanish; 3,503 Bulgarian. The populations of the rest fall off sharply below 3,000. Between 200,000 and 300,000 ethnic Turks (including minority of Turkish Kurds) currently live in Austria. They are the largest single immigrant group in Austria, closely followed by the Serbs.
Austria's mountainous terrain led to the development of many distinct German dialects. All of the dialects in the country, however, belong to Austro-Bavarian groups of German dialects, with the exception of the dialect spoken in its western-most Bundesland, Vorarlberg, which belongs to the group of Alemannic dialects. There is also a distinct grammatical standard for Austrian German with a few differences to the German spoken in Germany.
As of 2006, some of the Austrian states introduced standardised tests for new citizens, to assure their language ability, cultural knowledge and accordingly their ability to integrate into the Austrian society. For the national rules, see Austrian nationality law – Naturalisation.
Ethnic groups ().
An estimated 13,000 to 40,000 Slovenes in the Austrian state of Carinthia (the Carinthian Slovenes) as well as Croats (around 30,000) and Hungarians in Burgenland were recognised as a minority and have enjoyed special rights following the Austrian State Treaty () of 1955. The Slovenes in the Austrian state of Styria (estimated at a number between 1,600 and 5,000) are not recognised as a minority and do not enjoy special rights, although the State Treaty of July 27, 1955 states otherwise.
The right for bilingual topographic signs for the regions where Slovene- and Croat-Austrians live alongside the German speaking population (as required by the 1955 State Treaty) is still to be fully implemented. Many Carinthians are afraid of Slovenian territorial claims, pointing to the fact that Yugoslav troops entered the state after each of the two World Wars and considering that some official Slovenian atlases show parts of Carinthia as Slovene cultural territory. The recently deceased governor, Jörg Haider, has made this fact a matter of public argument in autumn 2005 by refusing to increase the number of bilingual topographic signs in Carinthia. A poll by the Kärntner Humaninstitut conducted in January 2006 states that 65% of Carinthians are not in favour of an increase of bilingual topographic signs, since the original requirements set by the State Treaty of 1955 have already been fulfilled according to their point of view.
Another interesting phenomenon is the so called "Windischen-Theorie" stating that the Slovenes can be split in two groups: actual Slovenes and "Windische" (a traditional German name for Slavs), based on differences in language between Austrian Slovenes, who were taught Slovene standard language in school and those Slovenes who spoke their local Slovene dialect but went to German schools. The term "Windische" was applied to the latter group as a means of distinction. This politically influenced theory, dividing Slovene Austrians into the "loyal Windische" and the "national Slovenes", was never generally accepted and fell out of use some decades ago.
Religion.
At the end of the twentieth century, about 74% of Austria's population were registered as Roman Catholic, while about 5% considered themselves Protestants. Austrian Christians are obliged to pay a mandatory membership fee (calculated by income—about 1%) to their church; this payment is called "Kirchenbeitrag" ("Ecclesiastical/Church contribution").
Since the second half of the 20th century, the number of adherents and churchgoers has dropped. Data for the end of 2005 from the Austrian Roman Catholic church lists 5,662,782 members or 68.5% of the total Austrian population, and a Sunday church attendance of 753,701 or 9% of the total Austrian population. Data for the end of 2008 published by the Austrian Roman Catholic church shows a further reduction to 5,579,493 members or 66.8% of the total Austrian population, and a Sunday church attendance of 698,527 or 8% of the total Austrian population. The Lutheran church also recorded a large drop in adherents between 2001 and 2008.
About 12% of the population declared that they have no religion. in 2001. Of the remaining people, around 340,000 are registered as members of various Muslim communities, mainly due to the influx from Turkey, Bosnia-Herzegovina and Albania. About 180,000 are members of Eastern Orthodox Churches, more than 20,000 are active Jehovah's Witnesses and about 8,100 are Jewish.
The Austrian Jewish Community of 1938—Vienna alone counted more than 200,000—was reduced to around 4,500 during the Second World War, with approximately 65,000 Jewish Austrians killed in the Holocaust and 130,000 emigrating. The large majority of the current Jewish population are post-war immigrants, particularly from eastern Europe and central Asia (including Bukharan Jews). Buddhism was legally recognised as a religion in Austria in 1983.
According to the most recent Eurobarometer Poll 2005,
While northern and central Germany was the origin of the Reformation, Austria and Bavaria were the heart of the Counter-Reformation in the sixteenth and seventeenth centuries, when the absolute monarchy of Habsburg imposed a strict regime to restore Catholicism's power and influence among Austrians. The Habsburgs for a long time viewed themselves as the vanguard of Catholicism and all other confessions and religions were repressed.
In 1781, in the era of Austrian enlightenment, Emperor Joseph II issued a Patent of Tolerance for Austria that allowed other confessions a limited freedom of worship. Religious freedom was declared a constitutional right in Cisleithania after the Austro-Hungarian "Ausgleich" in 1867 thus paying tribute to the fact that the monarchy was home of numerous religions beside Roman Catholicism such as Greek, Serbian, Romanian, Russian, and Bulgarian Orthodox Christians (Austria neighboured the Ottoman Empire for centuries), Calvinist, Lutheran Protestants and Jews. In 1912, after the annexation of Bosnia Hercegovina in 1908, Islam was officially recognised in Austria.
Austria remained largely influenced by Catholicism. After 1918, First Republic Catholic leaders such as Theodor Innitzer and Ignaz Seipel took leading positions within or close to Austria's government and increased their influence during the time of the Austrofascism; Catholicism was treated much like a state religion by Engelbert Dollfuss and Kurt Schuschnigg. Although Catholic (and Protestant) leaders initially welcomed the Germans in 1938 during the Anschluss of Austria into Germany, Austrian Catholicism stopped its support of Nazism later on and many former religious public figures became involved with the resistance during the Third Reich. After the end of World War II in 1945, a stricter secularism was imposed in Austria, and religious influence on politics declined.
Music.
Austria's past as a European power and its cultural environment have generated a broad contribution to various forms of art, most notably among them music. Austria has been the birthplace of many famous composers such as Joseph Haydn, Franz Schubert, Anton Bruckner, Johann Strauss, Sr., Johann Strauss, Jr. and Gustav Mahler as well as members of the Second Viennese School such as Arnold Schoenberg, Anton Webern and Alban Berg. Wolfgang Amadeus Mozart was born in Salzburg, then an independent Church Principality, though one that was culturally closely connected to Austria, and much of Mozart's career was spent in Vienna.
Vienna has long been especially an important centre of musical innovation. Eighteenth and nineteenth century composers were drawn to the city due to the patronage of the Habsburgs, and made Vienna the European capital of classical music. During the Baroque period, Slavic and Hungarian folk forms influenced Austrian music.
Vienna's status began its rise as a cultural center in the early 1500s, and was focused around instruments including the lute. Ludwig van Beethoven spent the better part of his life in Vienna. Austria's current national anthem, attributed to Mozart, was chosen after World War II to replace the traditional Austrian anthem by Joseph Haydn.
Austria has also produced one notable jazz musician, keyboardist Josef Zawinul, who helped pioneer electronic influences in jazz as well as being a notable composer in his own right. The pop and rock musician Falco was internationally acclaimed during the 1980s, especially for his song "Rock Me Amadeus" dedicated to Mozart. The drummer Thomas Lang was born in Vienna in 1967 and is now world renowned for his technical ability, having played with artists such as Geri Halliwell and Robbie Williams.
Art and architecture.
Among Austrian Artists and architects one can find the painters Ferdinand Georg Waldmüller, Rudolf von Alt, Hans Makart, Gustav Klimt, Oskar Kokoschka, Egon Schiele, Carl Moll, and Friedensreich Hundertwasser, the photographers Inge Morath and Ernst Haas, and architects like Johann Bernhard Fischer von Erlach, Otto Wagner, Adolf Loos, and Hans Hollein.
Film and theater.
Austrian contributions to the worlds of film and theater have traditionally been strong. Sascha Kolowrat was an Austrian pioneer of filmmaking. Billy Wilder, Fritz Lang, Josef von Sternberg, and Fred Zinnemann originally came from Austria before establishing themselves as internationally relevant movie makers. Willi Forst, Ernst Marischka, or Franz Antel enriched the popular cinema in German language speaking countries. Michael Haneke became internationally known for his disturbing cinematic studies, before receiving a Golden Globe for his critically acclaimed film "The White Ribbon" in 2010.
The first Austrian film director receiving an Academy Award was Stefan Ruzowitzky. Many Austrian actors were able to pursue a career, the impact of which was sensed beyond national borders. Among them were Peter Lorre, Curd Jürgens, Senta Berger, Oskar Werner, and Klaus Maria Brandauer. Hedy Lamarr and Arnold Schwarzenegger became American as well as international movie stars. Christoph Waltz rose to international fame with his performance in "Inglourious Basterds", earning an Golden Globe Award in 2010. Max Reinhardt was a master of spectacular and astute theater productions. Otto Schenk not only excelled as a stage actor, but also as an opera director.
Science, philosophy and economics.
Austria was the cradle of numerous scientists with international reputation. Among them are Ludwig Boltzmann, Ernst Mach, Victor Franz Hess and Christian Doppler, prominent scientists in the nineteenth century. In the twentieth century, contributions by Lise Meitner, Erwin Schrödinger and Wolfgang Pauli to nuclear research and quantum mechanics were key to these areas' development during the 1920s and 1930s. A present-day quantum physicist is Anton Zeilinger, noted as the first scientist to demonstrate quantum teleportation.
In addition to physicists, Austria was the birthplace of two of the most noteworthy philosophers of the twentieth century, Ludwig Wittgenstein and Karl Popper. In addition to them biologists Gregor Mendel and Konrad Lorenz as well as mathematician Kurt Gödel and engineers such as Ferdinand Porsche and Siegfried Marcus were Austrians.
A focus of Austrian science has always been medicine and psychology, starting in medieval times with Paracelsus. Eminent physicians like Theodore Billroth, Clemens von Pirquet, and Anton von Eiselsberg have built upon the achievements of the 19th century Vienna School of Medicine. Austria was home to psychologists Sigmund Freud, Alfred Adler, Paul Watzlawick and Hans Asperger and psychiatrist Viktor Frankl.
The Austrian School of Economics, which is prominent as one of the main competitive directions for economic theory, is related to Austrian economists Joseph Schumpeter, Eugen von Böhm-Bawerk, Ludwig von Mises, and Friedrich Hayek. Other noteworthy Austrian-born émigrés include the management thinker Peter Drucker, scientist Sir Gustav Nossal, and the 38th Governor of California, Arnold Schwarzenegger.
Literature.
Complementing its status as a land of artists and scientists, Austria has always been a country of poets, writers, and novelists. It was the home of novelists Arthur Schnitzler, Stefan Zweig, Thomas Bernhard, Franz Kafka, and Robert Musil, of poets Georg Trakl, Franz Werfel, Franz Grillparzer, Rainer Maria Rilke, Adalbert Stifter, Karl Kraus and children's author Eva Ibbotson.
Famous contemporary playwrights and novelists are Nobel prize winner Elfriede Jelinek, Peter Handke and Daniel Kehlmann.
Cuisine.
Austria's cuisine is derived from that of the Austro-Hungarian Empire. Austrian cuisine is mainly the tradition of Royal-Cuisine ("Hofküche") delivered over centuries. It is famous for its well-balanced variations of beef and pork and countless variations of vegetables. There is also the "Mehlspeisen" Bakery, which created particular delicacies such as Sachertorte, "Krapfen" which are doughnuts usually filled with apricot marmalade or custard, and "Strudel" such as "Apfelstrudel" filled with apple and "Topfenstrudel" filled with sweetened sour cream.
In addition to native regional traditions, the cuisine has been influenced by Hungarian, Bohemia Czech, Jewish, Italian, Balkan and French cuisine, from which both dishes and methods of food preparation have often been borrowed. The Austrian cuisine is therefore one of the most multicultural and transcultural in Europe.
Typical Austrian dishes include Wiener Schnitzel, Schweinsbraten, Kaiserschmarren, Knödel, Sachertorte and Tafelspitz. There are also Kärntner Kasnudeln, a cooked filled dough-bag with a type of cottage cheese and spearmint, and Eierschwammerl dishes. The "Eierschwammerl", also known as "Pfifferling", are native yellow, tan mushrooms. The candy Pez was invented in Austria, as well as Mannerschnitten. Austria is also famous for its Mozartkugeln, and its coffee tradition.
Sports.
Due to the mountainous terrain, alpine skiing is a prominent sport in Austria. Similar sports such as snowboarding or ski-jumping are also widely popular. A popular team sport in Austria is football, which is governed by the Austrian Football Association. However, Austria rarely has international success in this discipline, going out in the first round of the 2008 UEFA European Football Championship which was co-hosted by Austria and Switzerland.
Besides football, Austria also has professional national leagues for most major team sports including the Austrian Hockey League for ice hockey, and the Österreichische Basketball Bundesliga for basketball. Bobsleigh, luge, and skeleton are also popular events with a permanent track located in Igls, which hosted bobsleigh and luge competitions for the 1964 and 1976 Winter Olympics held in Innsbruck. The first Winter Youth Olympics in 2012 will be held in Innsbruck as well.
---END.OF.DOCUMENT---
Astronomer.
An astronomer is a scientist who studies celestial bodies such as planets, stars, and galaxies.
Historically, astronomy was more concerned with the classification and description of phenomena in the sky, while astrophysics attempted to explain these phenomena and the differences between them using physical laws. Today, that distinction has mostly disappeared. Professional astronomers are highly educated individuals who typically have a PhD in physics or astronomy and are employed by research institutions or universities. They spend the majority of their time working on research, although they quite often have other duties such as teaching, building instruments, or aiding in the operation of an observatory. The number of professional astronomers in the United States is actually quite small. The American Astronomical Society, which is the major organization of professional astronomers in North America, has approximately 7,700 members. This number includes scientists from other fields such as physics, geology, and engineering, whose research interests are closely related to astronomy. The International Astronomical Union comprises almost 9,259 members from 89 different countries who are involved in astronomical research at the PhD level and beyond.
While the number of professional astronomers worldwide is not much larger than the population of a small town, there is a huge community of amateur astronomers. Most cities have amateur astronomy clubs that meet on a regular basis and often host star parties in their communities. The Astronomical Society of the Pacific is the largest general astronomical society in the world, comprising both professional and amateur astronomers as well as educators from 70 different nations. Like any hobby, most people who think of themselves as amateur astronomers may devote a few hours a month to stargazing and reading the latest developments in research. However, amateurs span the range from so-called "armchair astronomers" to the very ambitious, who own science-grade telescopes and instruments with which they are able to make their own discoveries and assist professional astronomers in research.
Calculation in astronomy.
(Arabic: زيج "astronomical tables of Sind and Hind") is a work consisting of approximately 37 chapters on calendrical and astronomical calculations and 116 tables with calendrical, astronomical and astrological data, as well as a table of sine values. This is the first of many Arabic "Zijes" based on the Indian astronomical methods known as the "sindhind". The work contains tables for the movements of the sun, the moon and the five planets known at the time. This work marked the turning point in Islamic astronomy. Hitherto, Muslim astronomers had adopted a primarily research approach to the field, translating works of others and learning already discovered knowledge. Al-Khwarizmi's work marked the beginning of non-traditional methods of study and calculations.
The original Arabic version (written c. 820) is lost, but a version by the Spanish astronomer Maslamah Ibn Ahmad al-Majriti (c. 1000) has survived in a Latin translation, presumably by Adelard of Bath (January 26, 1126). The four surviving manuscripts of the Latin translation are kept at the Bibliothèque publique (Chartres), the Bibliothèque Mazarine (Paris), the Bibliotheca Nacional (Madrid) and the Bodleian Library (Oxford).
Modern astronomers.
Contrary to the classical image of an old astronomer peering through a telescope through the dark hours of the night, it is very rare for a modern professional astronomer to use an eyepiece on a larger telescope. It is far more common to use a charge-coupled device camera to record a long, deep exposure, allowing a more sensitive image to be created because the light is added over time. Before CCDs, photographic plates were a common method of observation. Modern astronomers spend relatively little time at telescopes - most spend a few weeks per year observing, and the rest of their time reducing the data (changing it from raw data to processed images) and analyzing it. Many astronomers work entirely from astronomical survey or space observatory data. Others work with radio telescopes like the Very Large Array, which is entirely automated, although it is maintained by telescope operators.
Astronomers who serve as faculty spend much of their time teaching undergraduate and graduate classes. Most universities also have outreach programs including public telescope time and sometime planetariums as a public service and to encourage interest in the field.
---END.OF.DOCUMENT---
Animation.
The bouncing ball animation (below) consists of these 6 frames.
This animation moves at 10 frames per second.
Animation is the rapid display of a sequence of images of 2-D or 3-D artwork or model positions in order to create an illusion of movement. It is an optical illusion of motion due to the phenomenon of persistence of vision, and can be created and demonstrated in a number of ways. The most common method of presenting animation is as a motion picture or video program, although several other forms of presenting animation also exist.
Early examples.
Early examples of attempts to capture the phenomenon of motion drawing can be found in paleolithic cave paintings, where animals are depicted with multiple legs in superimposed positions, clearly attempting to convey the perception of motion.
A 5,200 year old earthen bowl found in Iran in Shahr-i Sokhta has five images of a goat painted along the sides. This has been claimed to be an example of early animation. However, since no equipment existed to show the images in motion, such a series of images cannot be called animation in a true sense of the word.
The phenakistoscope, praxinoscope, as well as the common flip book were early popular animation devices invented during the 1800s, while a Chinese zoetrope-type device was invented already in 180 AD. These devices produced movement from sequential drawings using technological means, but animation did not really develop much further until the advent of cinematography.
There is no single person who can be considered the "creator" of the art of film animation, as there were several people doing several projects which could be considered various types of animation all around the same time.
Georges Méliès was a creator of special-effect films; he was generally one of the first people to use animation with his technique. He discovered a technique by accident which was to stop the camera rolling to change something in the scene, and then continue rolling the film. This idea was later known as stop-motion animation. Méliès discovered this technique accidentally when his camera broke down while shooting a bus driving by. When he had fixed the camera, a hearse happened to be passing by just as Méliès restarted rolling the film, his end result was that he had managed to make a bus transform into a hearse. This was just one of the great contributors to animation in the early years.
The earliest surviving stop-motion advertising film was an English short by Arthur Melbourne-Cooper called "Matches: An Appeal" (1899). Developed for the Bryant and May Matchsticks company, it involved stop-motion animation of wired-together matches writing a patriotic call to action on a blackboard.
J. Stuart Blackton was possibly the first American filmmaker to use the techniques of stop-motion and hand-drawn animation. Introduced to filmmaking by Edison, he pioneered these concepts at the turn of the 20th century, with his first copyrighted work dated 1900. Several of his films, among them "The Enchanted Drawing" (1900) and "Humorous Phases of Funny Faces" (1906) were film versions of Blackton's "lightning artist" routine, and utilized modified versions of Méliès' early stop-motion techniques to make a series of blackboard drawings appear to move and reshape themselves. 'Humorous Phases of Funny Faces' is regularly cited as the first true animated film, and Blackton is considered the first true animator.
Another French artist, Émile Cohl, began drawing cartoon strips and created a film in 1908 called "Fantasmagorie". The film largely consisted of a stick figure moving about and encountering all manner of morphing objects, such as a wine bottle that transforms into a flower. There were also sections of live action where the animator’s hands would enter the scene. The film was created by drawing each frame on paper and then shooting each frame onto negative film, which gave the picture a blackboard look. This makes "Fantasmagorie" the first animated film created using what came to be known as traditional (hand-drawn) animation.
Following the successes of Blackton and Cohl, many other artists began experimenting with animation. One such artist was Winsor McCay, a successful newspaper cartoonist, who created detailed animations that required a team of artists and painstaking attention for detail. Each frame was drawn on paper; which invariably required backgrounds and characters to be redrawn and animated. Among McCay's most noted films are "Little Nemo" (1911), "Gertie the Dinosaur" (1914) and "The Sinking of the Lusitania" (1918).
The production of animated short films, typically referred to as "cartoons", became an industry of its own during the 1910s, and cartoon shorts were produced to be shown in movie theaters. The most successful early animation producer was John Randolph Bray, who, along with animator Earl Hurd, patented the cel animation process which dominated the animation industry for the rest of the decade.
Traditional animation.
Traditional animation (also called cel animation or hand-drawn animation) was the process used for most animated films of the 20th century. The individual frames of a traditionally animated film are photographs of drawings, which are first drawn on paper. To create the illusion of movement, each drawing differs slightly from the one before it. The animators' drawings are traced or photocopied onto transparent acetate sheets called cels, which are filled in with paints in assigned colors or tones on the side opposite the line drawings. The completed character cels are photographed one-by-one onto motion picture film against a painted background by a rostrum camera.
The traditional cel animation process became obsolete by the beginning of the 21st century. Today, animators' drawings and the backgrounds are either scanned into or drawn directly into a computer system. Various software programs are used to color the drawings and simulate camera movement and effects. The final animated piece is output to one of several delivery media, including traditional 35 mm film and newer media such as digital video. The "look" of traditional cel animation is still preserved, and the character animators' work has remained essentially the same over the past 70 years. Some animation producers have used the term "tradigital" to describe cel animation which makes extensive use of computer technology.
Examples of traditionally animated feature films include "Pinocchio" (United States, 1940), "Animal Farm" (United Kingdom, 1954), and "Akira" (Japan, 1988). Traditional animated films which were produced with the aid of computer technology include "The Lion King" (US, 1994) "Sen to Chihiro no Kamikakushi (Spirited Away)" (Japan, 2001), "Treasure Planet" (USA, 2002) and "Les Triplettes de Belleville" (2003).
Stop motion.
Stop-motion animation is used to describe animation created by physically manipulating real-world objects and photographing them one frame of film at a time to create the illusion of movement. There are many different types of stop-motion animation, usually named after the type of media used to create the animation. Computer software is widely available to create this type of animation.
Computer animation.
Computer animation encompasses a variety of techniques, the unifying factor being that the animation is created digitally on a computer.
2D animation.
2D animation figures are created and/or edited on the computer using 2D bitmap graphics or created and edited using 2D vector graphics. This includes automated computerized versions of traditional animation techniques such as of tweening, morphing, onion skinning and interpolated rotoscoping.
Examples: "Foster's Home for Imaginary Friends", "Danny Phantom", Waltz with Bashir
3D animation.
3D animation are digitally modeled and manipulated by an animator. In order to manipulate a mesh, it is given a digital skeletal structure that can be used to control the mesh. This process is called rigging. Various other techniques can be applied, such as mathematical functions (ex. gravity, particle simulations), simulated fur or hair, effects such as fire and water and the use of Motion capture to name but a few, these techniques fall under the category of 3d dynamics. Many 3D animations are very believable and are commonly used as Visual effects for recent movies.
Terms.
2D animation techniques tend to focus on image manipulation while 3D techniques usually build virtual worlds in which characters and objects move and interact. 3D animation can create images that seem real to the viewer.
---END.OF.DOCUMENT---
Afroasiatic languages.
The Afroasiatic languages constitute a language family with about 375 living languages and more than 350 million speakers spread throughout North Africa, the Horn of Africa, and Southwest Asia, as well as parts of the Sahel, West Africa and East Africa. The most widely spoken Afroasiatic language is Arabic, with 230 million speakers (all the colloquial varieties). In addition to languages now spoken, Afroasiatic includes several ancient languages, such as Ancient Egyptian, Biblical Hebrew, and Akkadian.
The term "Afroasiatic" (often now spelled as Afro-Asiatic) was coined by Maurice Delafosse (1914). It did not come into general use until it was adopted by Joseph Greenberg (1950) to replace the earlier term "Hamito-Semitic", following his demonstration that Hamitic is not a valid language family. The term "Hamito-Semitic" remains in use in the academic traditions of some European countries. Some authors now replace "Afro-Asiatic" with "Afrasian", or, reflecting an opinion that it is more African than Asian, "Afrasan". Individual scholars have called the family "Erythraean" (Tucker 1966) and "Lisramic" (Hodge 1972).
Classification history==.
In the 9th century, the Hebrew grammarian Judah ibn Quraysh of Tiaret in Algeria was the first to link two branches of Afroasiatic together; he perceived a relationship between Berber and Semitic. He knew of Semitic through Arabic, Hebrew, and Aramaic.
In the course of the 19th century, Europeans also began suggesting such relationships. In 1844, Theodor Benfey suggested a language family consisting of Semitic, Berber, and Cushitic (calling the latter "Ethiopic"). In the same year, T.N. Newman suggested a relationship between Semitic and Hausa, but this would long remain a topic of dispute and uncertainty.
Friedrich Müller named the traditional "Hamito-Semitic" family in 1876 in his "Grundriss der Sprachwissenschaft". He defined it as consisting of a Semitic group plus a "Hamitic" group containing Egyptian, Berber, and Cushitic; he excluded the Chadic group. These classifications relied in part on non-linguistic anthropological and racial arguments (see Hamitic hypothesis).
Leo Reinisch (1909) proposed linking Cushitic and Chadic, while urging a more distant affinity to Egyptian and Semitic, thus foreshadowing Greenberg, but his suggestion found little resonance.
Marcel Cohen (1924) rejected the idea of a distinct Hamitic subgroup and included Hausa (a Chadic language) in his comparative Hamito-Semitic vocabulary.
Joseph Greenberg (1950) strongly confirmed Cohen's rejection of "Hamitic", added (and sub-classified) the Chadic branch, and proposed the new name "Afroasiatic" for the family. Nearly all scholars have accepted Greenberg's classification.
In 1969, Harold Fleming proposed that what had previously been known as Western Cushitic is an independent branch of Afroasiatic, suggesting for it the new name Omotic. This proposal and name have met with widespread acceptance.
Several scholars, including Harold Fleming and Robert Hetzron, have since questioned the traditional inclusion of Beja in Cushitic.
Subgrouping.
Little agreement exists on the subgrouping of the five or six branches of Afroasiatic: Semitic, Egyptian, Berber, Chadic, Cushitic, and Omotic (if Omotic is not included in Cushitic). However, Christopher Ehret (1979), Harold Fleming (1981), and Joseph Greenberg (1981) all agree that the Omotic branch split from the rest first.
Position among the world's languages.
Afroasiatic is one of the four language families of Africa identified by Joseph Greenberg in his book "The Languages of Africa" (1963). It is the only one that extends outside of Africa, via the Semitic branch.
Origins and common features.
All Afroasiatic subfamilies show evidence of a causative affix "s", but a similar suffix also appears in other groups, such as the Niger-Congo languages.
Semitic, Berber, Cushitic (including Beja), and Chadic support possessive suffixes.
Tonal languages appear in the Omotic, Chadic, and Cushitic branches of Afroasiatic, according to Ehret (1996). The Semitic, Berber, and Egyptian branches do not use tones phonemically.
---END.OF.DOCUMENT---
Arithmetic mean.
In mathematics and statistics, the arithmetic mean (or simply the mean) of a list of numbers is the sum of all of the list divided by the number of items in the list. If the list is a statistical population, then the mean of that population is called a population mean. If the list is a statistical sample, we call the resulting statistic a sample mean.
The mean is the most commonly-used type of average and is often referred to simply as the "average". The term "mean" or "arithmetic mean" is preferred in mathematics and statistics to distinguish it from other averages such as the median and the mode.
Introduction.
If we denote a set of data by "X" = ("x"1, "x"2..., "x'n"), then the sample mean is typically denoted with a horizontal bar over the variable (formula_1, enunciated "x" bar").
The Greek letter μ is used to denote the arithmetic mean of an entire population. Or, for a random variable that has a defined mean, μ is the "probabilistic mean" or expected value of the random number. If the set "X" is a collection of random numbers with probabilistic mean of μ, then for any individual sample, "x'i", from that collection, μ = E is the expected value of that sample.
In practice, the difference between μ and formula_1 is that μ is typically unobservable because one observes only a sample rather than the whole population, and if the sample is drawn randomly, then one may treat formula_1, but not μ, as a random variable, attributing a probability distribution to it (the sampling distribution of the mean).
It is a U-statistic for the function formula_5 meaning that it is obtained by averaging a 1-sample statistic over the population.
If "X" is a random variable, then the expected value of "X" can be seen as the long-term arithmetic mean that occurs on repeated measurements of "X". This is the content of the law of large numbers. As a result, the sample mean is used to estimate unknown expected values.
Simple algebra will prove that a mean of "n" + 1 numbers is larger than the mean of "n" numbers if and only if the new number is larger than the old mean, smaller if and only if it is smaller, and remains stable if and only if it is equal to the old mean. The larger "n" is, the smaller is the magnitude of the change in the mean relative to the distance between the old mean and the new number.
Note that several other "means" have been defined, including the generalized mean, the generalized f-mean, the harmonic mean, the arithmetic-geometric mean, and various weighted means.
Not robust.
While the mean is often used to report central tendency, it is not a robust statistic, meaning that it is greatly influenced by outliers. Notably, for skewed distributions, the arithmetic mean may not accord with one's notion of "middle", and robust statistics such as the median may be a better description of central tendency.
A classic example is average income. The arithmetic mean may be misinterpreted as the median to imply that most people's incomes are higher than is in fact the case. When presented with an "average" one may be led to believe that "most" people's incomes are near this number. This "average" (arithmetic mean) income "is" higher than most people's incomes, because high income outliers skew the result higher (in contrast, the median income "resists" such skew). However, this "average" says nothing about the number of people near the median income (nor does it say anything about the modal income that most people are near). Nevertheless, because one might carelessly relate "average" and "most people" one might incorrectly assume that most people's incomes would be higher (nearer this inflated "average") than they are. For instance, reporting the "average" net worth in Medina, Washington as the arithmetic mean of all annual net worths would yield a surprisingly high number because of Bill Gates. Consider the scores (1, 2, 2, 2, 3, 9). The arithmetic mean is 3.17, but five out of six scores are below this.
Compounding.
If numbers "multiply" instead of "add," one should average using the geometric mean, not the arithmetic mean. This most often happens when computing the rate of return, as in finance.
For example, if a stock fell 10 % in the first year, and rose 30 % in the second year, then it would be incorrect to report its "average" increase per year over this two year period as the arithmetic mean (−10 % + 30 %)/2 = 10 %; the correct average in this case is the compound annual growth rate, which yields an annualized increase per year of only 8.2 %.
The reason for this is that each of those percents have different starting points: the 30% is 30% "of a smaller number". If the stock starts at $30 and falls 10 %, it is now at $27. If the stock then rises 30 %, it is now $35.1. The arithmetic mean of those rises is 10 %, but since the stock rose by $5.1 in 2 years, an average of 8.2 % would result in the final $35.1 figure [$30(1-10 %)(1+30 %) = $30(1+8.2 %)(1+8.2 %) = $35.1]. If one used the arithmetic mean 10 % in the same way, one would not get the actual increase [$30(1+10 %)(1+10 %) = $36.3].
Stated generally, compounding yields 90% * 130% = 117% overall growth, and annualizing yields formula_8, so 8.2% per year.
Directions.
Particular care must be taken when using cyclic data such as phases or angles. Naïvely taking the arithmetic mean of 1° and 359° yields a result of 180°.
In general application such an oversight will lead to the average value artificially moving towards the middle of the numerical range. A solution to this problem is to use the optimization formulation (viz, define the mean as the central point: the point about which one has the lowest dispersion), and redefine the difference as a modular distance (i.e., the distance on the circle: so the modular distance between 1° and 359° is 2°, not 358°).
---END.OF.DOCUMENT---
American Football Conference.
The American Football Conference (AFC) is one of the two conferences of the National Football League (NFL). This conference and its counterpart, the National Football Conference (NFC), currently contain 16 teams each, making up the 32 teams of the NFL.
Current teams.
Since 2002, the AFC has comprised 16 teams, organized into four divisions: North, South, East, West.
Season structure.
Each AFC team plays the other teams in their division twice (home and away) during the regular season, in addition to 10 other games assigned to their schedule by the NFL the previous May. Two of these games are assigned on the basis of the team's final division standing in the previous season. The remaining 8 games are split between the roster of two other NFL divisions. This assignment shifts each year. For instance, in the 2007 regular season, each team in the AFC West played one game against each team in both the AFC South and the NFC North. In this way division competition consists of common opponents, with the exception of the 2 games assigned on the strength of each team's prior division standing. (i.e. the division winner will face the other two division winners in the AFC divisions that they are not scheduled to play) The NFC operates according to the same system.
At the end of each football season, there are playoff games involving the top six teams in the AFC (the four division champions by place standing and the top two remaining non-division-champion teams ("wild cards") by record). The last two teams remaining play in the AFC Championship game with the winner receiving the Lamar Hunt Trophy. The AFC champion plays the NFC champion in the Super Bowl. After Super Bowl XLIII the AFC has won 19 Super Bowls to the 21 won by the NFC. Since losing 13 consecutive Super Bowls in the 1980s and 1990s (XIX–XXXI), the AFC has won nine of the last twelve. The losing coach of the AFC Championship game is the coach of the Pro Bowl the week after the Super Bowl.
History.
The AFC was created after the NFL merged with the American Football League (AFL) in 1970. All of the 10 former AFL teams along with the NFL's Cleveland Browns, Pittsburgh Steelers, and the then-Baltimore Colts joined the AFC.
Since the merger, five expansion teams have joined the AFC and two have left, thus making the current total 16. When the Seattle Seahawks and the Tampa Bay Buccaneers joined the league in 1976, they were temporarily placed in the NFC and AFC respectively. This arrangement lasted for one season only before the two teams switched conferences. The Seahawks eventually returned to the NFC as a result of the 2002 realignment. The expansion Jacksonville Jaguars joined the AFC in 1995.
Due to the relocation controversy of the Cleveland Browns, a new AFC franchise called the Baltimore Ravens was officially established in 1996 while the Browns were reactivated in 1999.
The Houston Texans were then added to the league in 2002, joining the AFC.
Logo.
The merged league created a new logo for the AFC that took elements of the old AFL logo, specifically the "A" and the six stars surrounding it. The AFC logo basically remained unchanged from 1970 to 2009. The 2010 NFL season introduced an updated AFC logo, with the most notable revision being the addition of a fourth star (representing the four divisions of the AFC), and moving the stars inside the letter, similar to the NFC logo.
---END.OF.DOCUMENT---
Animal Farm.
"Animal Farm" is a dystopian allegorical novella by George Orwell. Published in England on 17 August 1945, the book reflects events leading up to and during the Stalin era before World War II. Orwell, a democratic socialist and a member of the Independent Labour Party for many years, was a critic of Joseph Stalin and was suspicious of Moscow-directed Stalinism after his experiences with the NKVD during the Spanish Civil War. In a letter to Yvonne Davet, Orwell described "Animal Farm" as his novel "contre Stalin".
The original title was "Animal Farm: A Fairy Story", but "A Fairy Story" was dropped by the US publishers for its 1946 publication. Of all the translations during Orwell's lifetime, only Telugu kept the original title. Other variations in the title include: "A Satire" and "A Contemporary Satire". Orwell suggested for the French translation the title "Union des républiques socialistes animales", recalling the French name of the Soviet Union, "Union des républiques socialistes soviétiques", and which abbreviates URSA, which means "bear", a symbol of Russia, in Latin.
"Time" Magazine chose the book as one of the 100 best English-language novels (1923 to 2005); it also places at number 31 on the Modern Library List of Best 20th-Century Novels. It won a Retrospective Hugo Award in 1996 and is also included in the Great Books of the Western World.
Overview.
The novel addresses not only the corruption of the revolution by its leaders but also how wickedness, indifference, ignorance, greed and myopia destroy any possibility of a Utopia. While this novel portrays corrupt leadership as the flaw in revolution (and not the act of revolution itself), it also shows how potential ignorance and indifference to problems within a revolution could allow horrors to happen if smooth transition to a people's government isn't satisfied.
Plot summary.
Old Major, the old boar on the Manor Farm, calls the animals on the farm for a meeting, where he compares the humans to parasites and teaches the animals a revolutionary song, "Beasts of England."
When Major dies three days later, two young pigs, Snowball and Napoleon, assume command and turn his dream into a philosophy. The animals revolt and drive the drunken and irresponsible Mr. Jones from the farm, renaming it "Animal Farm."
The Seven Commandments of Animalism are written on the wall of a barn. The most important is the seventh, "All animals are equal." All the animals work, but the workhorse, Boxer, does more than others and adopts the maxim — "I will work harder."
Snowball attempts to teach the animals reading and writing; food is plentiful; and the farm runs smoothly. The pigs elevate themselves to positions of leadership and set aside special food items ostensibly for their personal health. Napoleon takes the pups from the farm dogs and trains them privately. When Mr. Jones tries retaking the farm, the animals defeat him at what they call the "Battle of the Cowshed." Napoleon and Snowball struggle for leadership. When Snowball announces his idea for a windmill, Napoleon opposes it. Snowball makes a speech in favour of the windmill, whereupon Napoleon has his dogs chase Snowball away. In Snowball's absence, Napoleon declares himself leader and makes changes. Meetings will no longer be held and instead a committee of pigs will run the farm.
Using a young pig named Squealer as a mouthpiece, Napoleon announces that Snowball stole the idea for the windmill from him. The animals work harder with the promise of easier lives with the windmill. After a violent storm, the animals find the windmill annihilated. Napoleon and Squealer convince the animals that Snowball destroyed the windmill, although the scorn of the neighbouring farmers suggests the windmill's walls were too thin. Once Snowball becomes a scapegoat, Napoleon begins purging the farm, killing animals he accuses of consorting with Snowball. Meanwhile, Boxer takes up a second maxim: "Napoleon is always right."
Napoleon abuses his powers, making life harder for the animals; the pigs impose more control while reserving privileges for themselves. The pigs rewrite history, villainizing Snowball and glorifying Napoleon. Squealer justifies every statement Napoleon makes, even the pigs' alteration of the Seven Commandments of Animalism. "No animal shall drink alcohol" is changed to "No animal shall drink alcohol "to excess" when the pigs discover the farmer's whisky. "Beasts of England" is banned as inappropriate, as according to Napoleon the dream of Animal Farm has been realized. It is replaced by an anthem glorifying Napoleon, who appears to be adopting the lifestyle of a man. The animals, though cold, starving, and overworked, remain convinced through psychological conditioning that they are better off than they were when ruled by Mr. Jones. Squealer abuses the animals' poor memories and invents numbers to show their improvement.
Mr. Frederick, one of the neighbouring farmers, swindles Napoleon by buying old wood with forged money, and then attacks the farm, using blasting powder to blow up the restored windmill. Though the animals win the battle, they do so at great cost, as many, including Boxer, are wounded. Boxer continues working harder and harder, until he collapses while working on the windmill. Napoleon sends for a van to take Boxer to the veterinarian, explaining that better care can be given there. Benjamin the donkey, who "could read as well as any pig", notices that the van belongs to "Alfred Simmonds, Horse Slaughterer and Glue Boiler", and attempts to mount a rescue; but the animals' attempts are futile. Squealer reports that the van was purchased by the hospital and the writing from the previous owner had not been repainted. He recounts a tale of Boxer's death in the hands of the best medical care. In reality, the pigs sent Boxer to his death in exchange for money to buy more whisky.
Years pass, and the pigs learn to walk upright, carry whips, and wear clothes. The Seven Commandments are reduced to a single phrase: "All animals are equal, but some animals are more equal than others." Napoleon holds a dinner party for the pigs and the humans of the area, who congratulate Napoleon on having the hardest-working animals in the country on the least feed. Napoleon announces an alliance with the humans, against the labouring classes of both "worlds". He abolishes practices and traditions related to the Revolution, and reverts the name of the farm to "Manor Farm".
The animals, overhearing the conversation, notice that the faces of the pigs have begun changing. During a poker match, an argument breaks out between Napoleon and Mr. Pilkington when they both play the Ace of Spades, and the animals realize that the faces of the pigs look like the faces of humans and no one can tell the difference between them.
Animalism.
Animalism is an allegorical mirror of the Soviet Union, particularly between the 1910s and the 1940s, as well as the evolution of the view of the Russian revolutionaries and government of how to practice it. It is invented by the highly respected pig Old Major. The pigs Snowball, Napoleon, and Squealer adapt Old Major's ideas into an actual philosophy, which they formally name Animalism. Soon after, Napoleon and Squealer indulge in the vices of humans (drinking alcohol, sleeping in beds, trading). Squealer is employed to alter the Seven Commandments to account for his humanization, which represents the Soviet government's tweaking of communist theory to make it more a reformation of capitalism than a replacement.
Later, Napoleon and his pigs are corrupted by the absolute power they hold over the farm. To maintain their popularity with the other animals, Squealer secretly paints additions to some commandments to benefit the pigs while keeping them free of accusations of breaking the laws (such as "No animal shall drink alcohol" having "to excess" appended to it and "No animal shall sleep in a bed" with "with sheets" added to it). Eventually the laws are replaced with
"All animals are equal, "but some animals are more equal than others", and "Four legs good, two legs "better!" as the pigs become more human.
Characters.
The events and characters in Animal Farm satirise Communism ("Animalism"), authoritarian government and human gullibility generally; Snowball is seen as Leon Trotsky and the head pig, Napoleon, is Stalin.
Equines.
There are four main equine characters: Boxer, Clover, and Mollie, who are horses, and Benjamin, who is a donkey. Boxer is a loyal, kind, dedicated, and respectful worker. He is physically the strongest animal on the farm, but naive and slow, which leaves him constantly stating "I will work harder" and "Napoleon is always right" despite the corruption. Clover is Boxer's companion, who constantly cares for him, and she also acts as the matriarch for the other horses, and other animals in general (such as the ducklings she shelters with her fore-legs and hooves during Old Major's speech). Mollie is a self-centred, self-indulgent and vain young white mare who likes wearing ribbons in her mane, eating sugar cubes, and being pampered and groomed by humans. She quickly leaves for another farm and is only once mentioned again. Benjamin is one of the longest-lived animals, has the worst temper and one of the few who can read. Benjamin is a very dedicated friend to Boxer, and does nothing to warn the other animals of the pigs' corruption, which he secretly realizes is steadily unfolding. When asked if he was happier post-Revolution than before the Revolution, Benjamin remarks, "Donkeys live a long time. None of you has ever seen a dead donkey." He is cynical and pessimistic, his most often made statement being "Life will go on as it has always gone on — that is, badly". But he is also one of the wisest animals on the farm, and is able to "read as well as any pig".
Origin.
George Orwell wrote the manuscript in 1943 and 1944 following his experiences during the Spanish Civil War, which he described in his 1938 "Homage to Catalonia".
In the preface of a 1947 Ukrainian edition of Animal Farm he explained how escaping the communist purges in Spain taught him "how easily totalitarian propaganda can control the opinion of enlightened people in democratic countries." This motivated Orwell to expose and strongly condemn what he saw as the Stalinist corruption of the original socialist ideals.
Orwell encountered great difficulty getting the manuscript published. Four publishers refused; one had initially accepted the work but declined after consulting with the Ministry of Information. Eventually Secker and Warburg published the first edition in 1945.
Significance.
In the Eastern Bloc both "Animal Farm" and later, also "Nineteen Eighty-Four" were on the list of forbidden books up until "die Wende" in 1989, and were only available via clandestine Samizdat networks.
The novel's "Battle of the Windmill" is referred to by Sant Singh Bal as one "of the important episodes which constitute the essence of the plot of the novel." Harold Bloom writes that the "Battle of the Windmill rings a special bell: the repulse of the Duke of Brunswick in 1792, following the Prussian bombardment that made the windmill of Valmy famous." By contrast, Peter Edgerly Firchow and Peter Hobley Davison consider that in real life, with events in "Animal Farm" mirroring those in the Soviet Union, this fictional battle represents the Great Patriotic War (World War II), especially the Battle of Stalingrad and the Battle of Moscow. Prestwick House's "Activity Pack" for "Animal Farm" also identifies the Battle of the Windmill as an allegory for World War II, while noting that the "catalyst for the Battle of the Windmill, though, is less clear." During the battle, Fredrick drills a hole and places explosives inside, and it is followed by "All the animals, except Napoleon" took cover; Orwell had the publisher alter this from "All the animals, including Napoleon" in recognition of Joseph Stalin's decision to remain in Moscow during the German advance.
The "Battle of the Cowshed" represents the allied invasion of the Soviet Russia in 1918, and the defeat of the White Russians in the Russian Civil War.
Efforts to find a publisher.
During World War II it became apparent to Orwell that anti-Soviet literature was not something which most major publishing houses would touch — including his regular publisher Gollancz. He also submitted the manuscript to Faber and Faber, where the poet T. S. Eliot (who was a director of the firm) also rejected it; Eliot wrote back to Orwell praising its "good writing" and "fundamental integrity" but declaring that they would only accept it for publication if they had some sympathy for the viewpoint "which I take to be generally Trotskyite". Eliot said he found the view "not convincing", and contended that the pigs were made out to be the best to run the farm; he posited that someone might argue "what was needed.. was not more communism but more public-spirited pigs".
Although it was written in 1943, "Animal Farm" was not published until 1945 due to paper rationing and fear of damaging the Anglo-Soviet alliance.
"The Freedom of the Press".
Orwell originally wrote a preface which complains about self-imposed British self-censorship and how the British people were suppressing criticism of the USSR, their World War II ally. "The sinister fact about literary censorship in England is that it is largely voluntary. ... Things are kept right out of the British press, not because the Government intervenes but because of a general tacit agreement that 'it wouldn't do' to mention that particular fact." The preface itself was censored and as of June 2009 has not been published with most editions of the book. His wife Eileen Blair had worked during the war at the Ministry of Information censoring newspapers.
Secker and Warburg published the first edition of Animal Farm in 1945 without any introduction. However, the publisher had provided space for a preface in the author's proof composited from the manuscript. For reasons unknown, no preface was supplied and all the page numbers needed to be redone at the last minute.
Years later, in 1972, Ian Angus found the original typescript titled "The Freedom of the Press", and Bernard Crick published it, together with his own introduction in The Times Literary Supplement on 15 September 1972 as "How the essay came to be written". Orwell's essay criticized British self-censorship by the press, specifically the suppression of unflattering descriptions of Stalin and the Soviet government. The same essay also appeared in the Italian 1976 Animal Farm edition, with another introduction by Crick, claiming to be the first edition with the preface. Other publishers were still declining to publish it.
Cultural references.
References to the novella are frequent in other works of popular culture, particularly in popular music and television series.
Adaptations.
"Animal Farm" has been adapted to film twice. The 1954 "Animal Farm" film was an animated feature and the 1999 "Animal Farm" film was a TV live action version, both differ from the novel. In the 1954 film Napoleon is overthrown in a second revolution while the 1999 film shows Napoleon's regime collapsing in on itself, as happened in the Soviet Union.
Editions.
On July 17, 2009, Amazon.com withdrew certain Amazon Kindle titles, including "Animal Farm" and "Nineteen Eighty-Four" by George Orwell, from sale, refunded buyers, and remotely deleted items from purchasers' devices after discovering that the publisher lacked rights to publish the titles in question. Notes and annotations for the books made by users on their devices were also deleted. After the move prompted outcry and comparisons to "Nineteen Eighty-Four" itself, Amazon spokesman Drew Herdener stated that the company is "… changing our systems so that in the future we will not remove books from customers' devices in these circumstances."
---END.OF.DOCUMENT---
Amphibian.
Amphibians (class Amphibia), such as frogs, toads, salamanders, newts, and caecilians, are ectothermic (or cold-blooded) animals that either metamorphose from a juvenile water-breathing form, to an adult air-breathing form, or paedomorph and retain some juvenile characteristics. Mudpuppies and waterdogs are good examples of paedomorphic species. Though amphibians typically have four limbs, the caecilians are notable for being limbless. Unlike other land vertebrates (amniotes), amphibians lay eggs in water. Amphibians are superficially similar to reptiles.
Amphibians are ecological indicators, and in recent decades there has been a dramatic decline in amphibian populations around the globe. Many species are now threatened or extinct.
Amphibians evolved in the Devonian Period and were top predators in the Carboniferous and Permian Periods, but many lineages were wiped out during the Permian–Triassic extinction. One group, the metoposaurs, remained important predators during the Triassic, but as the world became drier during the Early Jurassic they died out, leaving a handful of relict temnospondyls like "Koolasuchus" and the modern orders of Lissamphibia.
Etymology.
Amphibian is derived from the Ancient Greek term ἀμφίβιος "amphíbios" which means both kinds of life, "amphi" meaning “both” and "bio" meaning life. The term was initially used for all kinds of combined natures. Eventually it was used to refer to animals that live both in the water and on land.
Evolutionary history.
The first major groups of amphibians developed in the Devonian Period from fish similar to the modern coelacanth and lungfish which had evolved multi-jointed leg-like fins that enabled them to crawl along the sea bottom. These amphibians were as much as one to five meters in length. However, amphibians never developed the ability to live their entire lives on land, having to return to water to lay their shell-less eggs.
In the Carboniferous Period, the amphibians moved up in the food chain and began to occupy the ecological position currently occupied by crocodiles. These amphibians were notable for eating the mega insects on land and many types of fishes in the water. During the Triassic Period, the better land-adapted proto-crocodiles began to compete with amphibians, leading to their reduction in size and importance in the biosphere.
Taxonomy.
Of these only the last subclass includes recent species.
With the phylogenetic revolution, this classification has been modified, or changed, and the Labyrinthodontia discarded as being a paraphyletic group without unique defining features apart from shared primitive characteristics. Classification varies according to the preferred phylogeny of the author, whether they use a stem-based or node-based classification. Generally amphibians are defined as the group that includes the common ancestors of all living amphibians (frogs, salamanders, etc.) and all their descendants. This may also include extinct groups like the temnospondyls (traditionally placed in the disbanded subclass “labyrinthodontia”), and the Lepospondyls. This means that there are a now large number of basal Devonian and Carboniferous tetrapod groups, described as “amphibians” in earlier books, that are no longer placed in the formal Amphibia.
All recent amphibians are included in the subclass Lissamphibia, superorder Salientia, which is usually considered a clade (which means that it is thought that they evolved from a common ancestor apart from other extinct groups), although it has also been suggested that salamanders arose separately from a temnospondyl-like ancestor.
Authorities also disagree on whether Salientia is a Superorder that includes the order Anura, or whether Anura is a sub-order of the order Salientia. Practical considerations seem to favor using the former arrangement now.
The Lissamphibia, superorder Salientia, are traditionally divided into three orders, but an extinct salamander-like family, the Albanerpetontidae, is now considered part of the Lissamphibia, besides the superorder Salientia. Furthermore, Salientia includes all three recent orders plus a single Triassic proto-frog, "Triadobatrachus".
The actual number of species partly also depends on the taxonomic classification followed, the two most common classifications being the classification of the website AmphibiaWeb, University of California (Berkeley) and the classification by herpetologist Darrel Frost and The American Museum of Natural History, available as the online reference database Amphibian Species of the World. The numbers of species cited above follow Frost.
Reproductive system.
For the purpose of reproduction most amphibians require fresh water. A few (e.g. "Fejervarya raja") can inhabit brackish water and even survive (though not thrive) in seawater, but there are no true marine amphibians. Several hundred frog species in adaptive radiations (e.g., "Eleutherodactylus", the Pacific Platymantines, the Australo-Papuan microhylids, and many other tropical frogs), however, do not need any water for breeding in the wild. They reproduce via direct development, an ecological and evolutionary adaptation that has allowed them to be completely independent from free-standing water. Almost all of these frogs live in wet tropical rainforests and their eggs hatch directly into miniature versions of the adult, passing through the tadpole stage within the egg. Several species have also adapted to arid and semi-arid environments, but most of them still need water to lay their eggs. Symbiosis with single celled algae that lives in the jelly-like layer of the eggs has evolved several times. The larvae (tadpoles or polliwogs) breathe with exterior gills. After hatching, they start to transform gradually into the adult's appearance. This process is called metamorphosis. Typically, the animals then leave the water and become terrestrial adults, but there are many interesting exceptions to this general way of reproduction.
Conservation.
Dramatic declines in amphibian populations, including population crashes and mass localized extinction, have been noted in the past two decades from locations all over the world, and amphibian declines are thus perceived as one of the most critical threats to global biodiversity. A number of causes are believed to be involved, including habitat destruction and modification, over-exploitation, pollution, introduced species, climate change, endocrine-disrupting pollutants, destruction of the ozone layer (ultraviolet radiation has shown to be especially damaging to the skin, eyes, and eggs of amphibians), and diseases like chytridiomycosis. However, many of the causes of amphibian declines are still poorly understood, and are a topic of ongoing discussion. A global strategy to stem the crisis has been released in the form of the Amphibian Conservation Action Plan (available at http://www.amphibians.org). Developed by over 80 leading experts in the field, this call to action details what would be required to curtail amphibian declines and extinctions over the next 5 years - and how much this would cost. The Amphibian Specialist Group of the World Conservation Union (IUCN) is spearheading efforts to implement a comprehensive global strategy for amphibian conservation.
On January 21, 2008, Evolutionarily Distinct and Globally Endangered (EDGE), as given by chief Helen Meredith, identified nature's most endangered species: "The EDGE amphibians are amongst the most remarkable and unusual species on the planet and yet an alarming 85% of the top 100 are receiving little or no conservation attention." The top 10 endangered species (in the List of endangered animal species)
include: the Chinese giant salamander, a distant relative of the newt, the tiny Gardiner's Seychelles, the limbless Sagalla caecilian, South African ghost frogs, lungless Mexican salamanders, the Malagasy rainbow frog, Chile's Darwin frog (Rhinoderma rufum) and the Betic Midwife Toad.
---END.OF.DOCUMENT---
Alaska.
Alaska () is the largest state of the United States by area; it is situated in the northwest extremity of the North American continent, with Canada to the east, the Arctic Ocean to the north, and the Pacific Ocean to the west and south, with Russia further west across the Bering Strait. Approximately half of Alaska's 698,473 residents live within the Anchorage metropolitan area. As of 2009, Alaska remains the least densely populated state of the U.S.
The U.S. Senate approved the purchase of Alaska from the Russian Empire on March 30, 1867, for $7.2 million at about two cents per acre ($4.74/km2). The land went through several administrative changes before becoming an organized territory on May 11, 1912, and the 49th state of the U.S. on January 3, 1959. The name "Alaska" (Аляска) was already introduced in the Russian colonial time, when it was used only for the peninsula and is derived from the Aleut "alaxsxaq", meaning "the mainland" or more literally, "the object towards which the action of the sea is directed". It is also known as Alyeska, the "great land", an Aleut word derived from the same root.
Geography.
Alaska has a longer coastline than all the other U.S. states combined. It is the only non-contiguous U.S. state on continental North America; about of British Columbia (Canada) separate Alaska from Washington state. Alaska is thus an exclave of the United States. It is technically part of the continental U.S., but is often not included in colloquial use; Alaska is not part of the contiguous U.S., often called "the Lower 48." The capital city, Juneau, is situated on the mainland of the North American continent, but is not connected by road to the rest of the North American highway system.
The state is bordered by the Yukon Territory and British Columbia in Canada, to the east, the Gulf of Alaska and the Pacific Ocean to the south, the Bering Sea, Bering Strait, and Chukchi Sea to the west and the Arctic Ocean to the north. Alaska's territorial waters touch Russia's territorial waters in the Bering Strait, as the Russian and Alaskan islands are only apart. As it extends into the eastern hemisphere, it is technically both the westernmost and easternmost state in the United States, as well as also being the northernmost.
Alaska is the largest state in the United States in land area at, over twice the size of Texas, the next largest state. Alaska is larger than all but 18 sovereign countries.
Counting territorial waters, Alaska is larger than the combined area of the next three largest states: Texas, California, and Montana. It is also larger than the combined area of the 22 smallest U.S. states.
The International Date Line was drawn west of 180° to keep the whole state, and thus the entire North American continent, within the same legal day.
Natural features.
With its myriad islands, Alaska has nearly of tidal shoreline. The Aleutian Islands chain extends west from the southern tip of the Alaska Peninsula. Many active volcanoes are found in the Aleutians. Unimak Island, for example, is home to Mount Shishaldin, which is an occasionally smoldering volcano that rises to above the North Pacific. It is the most perfect volcanic cone on Earth, even more symmetrical than Japan's Mount Fuji. The chain of volcanoes extends to Mount Spurr, west of Anchorage on the mainland. Alaska has more volcanoes than any other state. Geologists have identified Alaska as part of Wrangellia, a large region consisting of multiple states and Canadian provinces in the Pacific Northwest which is actively undergoing continent building.
One of the world's largest tides occurs in Turnagain Arm, just south of Anchorage – tidal differences can be more than. (Many sources say Turnagain has the second-greatest tides in North America, but several areas in Canada have larger tides.)
Alaska has more than three million lakes. Marshlands and wetland permafrost cover (mostly in northern, western and southwest flatlands). Glacier ice covers some of land and of tidal zone. The Bering Glacier complex near the southeastern border with Yukon covers alone. With over 100,000 of them, Alaska has half of the world's glaciers.
Land ownership.
According to an October 1998 report by the United States Bureau of Land Management, approximately 65% of Alaska is owned and managed by the U.S. federal government as public lands, including a multitude of national forests, national parks, and national wildlife refuges. Of these, the Bureau of Land Management manages 87 million acres (350,000 km²), or 23.8% of the state. The Arctic National Wildlife Refuge is managed by the United States Fish and Wildlife Service. It is the world's largest wildlife refuge, comprising.
Of the remaining land area, the State of Alaska owns; another are owned by 12 regional and dozens of local Native corporations created under the Alaska Native Claims Settlement Act. Thus, indirectly, the 84,000 Eskimo, Aleut and American Indian inhabitants of Alaska own one-ninth of the state. Various private interests own the remaining land, totaling about one percent of the state.
Climate.
The climate in Juneau and the southeast panhandle is a mid-latitude oceanic climate (Köppen climate classification "Cfb") in the southern sections and a subarctic oceanic climate (Köppen "Cfc") in the northern parts. On an annual basis, the panhandle is both the wettest and warmest part of Alaska with milder temperatures in the winter and high precipitation throughout the year. Juneau averages over of precipitation a year, while other areas receive over. This is also the only region in Alaska in which the average daytime high temperature is above freezing during the winter months.
The climate of Anchorage and south central Alaska is mild by Alaskan standards due to the region's proximity to the seacoast. While the area gets less rain than southeast Alaska, it gets more snow, and days tend to be clearer. On average, Anchorage receives of precipitation a year, with around of snow, although there are areas in the south central which receive far more snow. It is a subarctic climate (Köppen "Dfc") due to its brief, cool summers.
The climate of Western Alaska is determined in large part by the Bering Sea and the Gulf of Alaska. It is a subarctic oceanic climate in the southwest and a continental subarctic climate farther north. The temperature is somewhat moderate considering how far north the area is. This area has a tremendous amount of variety in precipitation. The northern side of the Seward Peninsula is technically a desert with less than of precipitation annually, while some locations between Dillingham and Bethel average around of precipitation.
The climate of the interior of Alaska is subarctic. Some of the highest and lowest temperatures in Alaska occur around the area near Fairbanks. The summers may have temperatures reaching into the 90s°F (the low to mid 30s °C), while in the winter, the temperature can fall below −60 °F (-52 °C). Precipitation is sparse in the Interior, often less than a year, but what precipitation falls in the winter tends to stay the entire winter.
The highest and lowest recorded temperatures in Alaska are both in the Interior. The highest is 100 °F (38 °C) in Fort Yukon (which is just inside the arctic circle) on June 27, 1915, tied with Pahala, Hawaii as the lowest high temperature in the United States. The lowest official Alaska temperature is −80 °F (-62 °C) in Prospect Creek on January 23, 1971, one degree above the lowest temperature recorded in continental North America (in Snag, Yukon, Canada).
The climate in the extreme north of Alaska is Arctic (Köppen "ET") with long, very cold winters and short, cool summers. Even in July, the average low temperature in Barrow is 34 °F (1 °C). Precipitation is light in this part of Alaska, with many places averaging less than per year, mostly as snow which stays on the ground almost the entire year.
History.
The first European contact with Alaska occurred in 1741, when Vitus Bering led an expedition for the Russian Navy aboard the "St. Peter". After his crew returned to Russia bearing sea otter pelts judged to be the finest fur in the world, small associations of fur traders began to sail from the shores of Siberia towards the Aleutian islands. The first permanent European settlement was founded in 1784, and the Russian-American Company carried out an expanded colonization program during the early to mid-1800s. New Archangel on Kodiak Island was Alaska's first capital, but for a century under both Russia and the U.S. Sitka was the capital. The Russians never fully colonized Alaska, and the colony was never very profitable. William H. Seward, the U.S. Secretary of State, negotiated the Alaskan purchase with the Russians in 1867 for $7.2 million. Alaska was loosely governed by the military initially, and was unofficially a territory of the United States from 1884 on.
In the 1890s, gold rushes in Alaska and the nearby Yukon Territory brought thousands of miners and settlers to Alaska. Alaska was granted official territorial status in 1912. At this time the capital was moved to Juneau.
During World War II, the Aleutian Islands Campaign focused on the three outer Aleutian Islands – Attu, Agattu and Kiska – that were invaded by Japanese troops and occupied between June 1942 and August 1943. Unalaska/Dutch Harbor became a significant base for the U.S. Army Air Corps and Navy submariners.
The U.S. Lend-Lease program involved the flying of American warplanes through Canada to Fairbanks and thence Nome; Soviet pilots took possession of these aircraft, ferrying them to fight the German invasion of the Soviet Union. The construction of military bases contributed to the population growth of some Alaskan cities.
Statehood was approved on July 7, 1958. Alaska was officially proclaimed a state on January 3, 1959.
In 1964, the massive "Good Friday Earthquake" killed 131 people and destroyed several villages, mainly by the resultant tsunamis. It was the third most powerful earthquake in the recorded history of the world, with a moment magnitude of 9.2. It was over one thousand times more powerful than the 1989 San Francisco earthquake. Luckily, the epicenter was in an unpopulated area or thousands more would have been killed.
The 1968 discovery of oil at Prudhoe Bay and the 1977 completion of the Trans-Alaska Pipeline led to an oil boom. In 1989, the "Exxon Valdez" hit a reef in the Prince William Sound, spilling over 11 million gallons of crude oil over 1,100 miles (1,600 km) of coastline. Today, the battle between philosophies of development and conservation is seen in the contentious debate over oil drilling in the Arctic National Wildlife Refuge.
Demographics.
The United States Census Bureau, as of July 1, 2008, estimated Alaska's population at 686,293, which represents an increase of 59,361, or 9.5%, since the last census in 2000. This includes a natural increase since the last census of 60,994 people (that is 86,062 births minus 25,068 deaths) and a decrease due to net migration of 5,469 people out of the state. Immigration from outside the U.S. resulted in a net increase of 4,418 people, and migration within the country produced a net loss of 9,887 people. In 2000 Alaska ranked the 48th state by population, ahead of Vermont and Wyoming (and Washington D.C.). Alaska is the least densely populated state, and one of the most sparsely populated areas in the world, at 1.0 person per square mile (0.42/km²), with the next state, Wyoming, at 5.1 per square mile (1.97/km²). Alaska is the largest U.S. state by area, and the sixth wealthiest (per capita income).
Race and ancestry.
According to the 2000 U.S. Census, White Americans made up 69.3% of Alaska's population. African Americans made up 3.5% of Alaska's population. In addition, American Indians and Alaska Natives were the largest minority group; they made up 15.6% of Alaska's population. Asian Americans made up 4.0% of Alaska's population. Pacific Islander Americans made up 0.5% of Alaska's population. Individuals from some other race made up 1.6% of Alaska's population while individuals from two or more races made up 5.4% of the state's population. In addition, Hispanics and Latinos made up 4.1% of Alaska's population.
In terms of ancestry, German Americans were the largest single ethnic group in Alaska; they made up 16.6% of Alaska's population and they were the only ethnic group in the state to number over 100,000 members. Irish Americans made up 10.8% of Alaska's population while English Americans made up 9.6% of the state's population. Norwegian Americans made up 4.2% of Alaska's population and French Americans made up 3.2% of the state's population.
As of the 2005–2007 American Community Survey conducted by the U.S. Census Bureau, White Americans made up 68.5% of Alaska's population. Blacks or African Americans made up 3.8% of Alaska's population. American Indians and Alaska Natives made up 13.4% of Alaska's population; still remaining the largest minority group. Asian Americans made up 4.6% of Alaska's population. Pacific Islander Americans remained at 0.5% of the state's population. Individuals from some other race made up 1.9% of Alaska's population while individuals from two or more races made up 7.2% of the state's population. Hispanics or Latinos made up 5.5% of Alaska's population.
In terms of ancestry, German Americans remained the largest single ethnic group in Alaska; they made up 19.3% of Alaska's population and were still the only ethnic group in the state with over 100,000 members. Irish Americans made up 12.5% of Alaska's population while English Americans made up 10.8% of the state's population. Norwegian Americans remained at 4.2% of Alaska's population and French Americans made up 3.6% of the state's population.
Languages.
According to the 2005–2007 American Community Survey, 84.7% of people over the age of five speak only English at home. About 3.5% speak Spanish at home. About 2.2% speak another Indo-European language at home and about 4.3% speak an Asian language at home. And about 5.3% speak other languages at home.
A total of 5.2% of Alaskans speak one of the state's 22 indigenous languages, known locally as "native languages". These languages belong to two major language families: Eskimo-Aleut and Na-Dene. As the homeland of these two major language families of North America, Alaska has been described as the crossroads of the continent, providing evidence for the recent settlement of North America by way of the Bering land bridge.
Religion.
Alaska has been identified, along with Pacific Northwest states Washington and Oregon, as being the least religious in the U.S. According to statistics collected by the Association of Religion Data Archives, about 39% of Alaska residents were members of religious congregations. Evangelical Protestants had 78,070 members, Roman Catholics had 54,359, and mainline Protestants had 37,156. After Catholicism, the largest single denominations are The Church of Jesus Christ of Latter Day Saints (Mormons/LDS) with 29,460, Southern Baptists with 22,959, and Orthodox with 20,000. The large Eastern Orthodox (with 49 parishes and up to 50,000 followers) population is a result of early Russian colonization and missionary work among Alaska Natives. In 1795, the First Russian Orthodox Church was established in Kodiak. Intermarriage with Alaskan Natives helped the Russian immigrants integrate into society. As a result, an increasing number of Russian Orthodox churches gradually became established within Alaska. Alaska also has the largest Quaker population (by percentage) of any state. In 2003 there were 3,000 Jews in Alaska (for whom observance of the mitzvah may pose special problems). Estimates for the number of Alaskan Muslims range from 2,000 to 5,000. Alaskan Hindus often share venues and celebrations with members of other religious communities including Sikhs and Jains.
Economy.
The 2007 gross state product was $44.9 billion, 45th in the nation. Its per capita personal income for 2007 was $40,042, ranking 15th in the nation. The oil and gas industry dominates the Alaskan economy, with more than 80% of the state's revenues derived from petroleum extraction. Alaska's main export product (excluding oil and natural gas) is seafood, primarily salmon, cod, Pollock and crab. Agriculture represents only a fraction of the Alaskan economy. Agricultural production is primarily for consumption within the state and includes nursery stock, dairy products, vegetables, and livestock. Manufacturing is limited, with most foodstuffs and general goods imported from elsewhere. Employment is primarily in government and industries such as natural resource extraction, shipping, and transportation. Military bases are a significant component of the economy in both Fairbanks and Anchorage. Federal subsidies are also an important part of the economy, allowing the state to keep taxes low. Its industrial outputs are crude petroleum, natural gas, coal, gold, precious metals, zinc and other mining, seafood processing, timber and wood products. There is also a growing service and tourism sector. Tourists have contributed to the economy by supporting local lodging.
Energy.
Alaska has vast energy resources. Major oil and gas reserves are found in the Alaska North Slope (ANS) and Cook Inlet basins. According to the Energy Information Administration, Alaska ranks second in the nation in crude oil production. Prudhoe Bay on Alaska's North Slope is the highest yielding oil field in the United States and on North America, typically producing about. The Trans-Alaska Pipeline can pump up to of crude oil per day, more than any other crude oil pipeline in the United States. Additionally, substantial coal deposits are found in Alaska's bituminous, sub-bituminous, and lignite coal basins. The United States Geological Survey estimates that there are of undiscovered, technically recoverable gas from natural gas hydrates on the Alaskan North Slope. Alaska also offers some of the highest hydroelectric power potential in the country from its numerous rivers. Large swaths of the Alaskan coastline offer wind and geothermal energy potential as well.
Alaska's economy depends heavily on increasingly expensive diesel fuel for heating, transportation, electric power and light. Though wind and hydroelectric power are abundant and underdeveloped, proposals for state-wide energy systems (e.g. with special low-cost electric interties) were judged uneconomical (at the time of the report, 2001) due to low (<$0.50/Gal) fuel prices, long distances and low population. The cost of a gallon of gas in urban Alaska today is usually $0.30-$0.60 higher than the national average; prices in rural areas are generally significantly higher but vary widely depending on transportation costs, seasonal usage peaks, nearby petroleum development infrastructure and many other factors.
Alaska accounts for one-fifth (20 percent) of domestically produced United States oil production. Prudhoe Bay (North America's largest oil field) alone accounts for 8% of the U.S. domestic oil production.
Permanent Fund.
The Alaska Permanent Fund is a legislatively controlled appropriation established in 1976 to manage a surplus in state petroleum revenues from the recently constructed Trans-Alaska Pipeline System. From its initial principal of $734,000, the fund has grown to $40 billion as a result of oil royalties and capital investment programs. Starting in 1982, dividends from the fund's annual growth have been paid out each year to eligible Alaskans, ranging from $331.29 in 1984 to $3,269.00 in 2008 (which included a one-time $1200 "Resource Rebate"). Every year, the state legislature takes out 8 percent from the earnings, puts 3 percent back into the principal for inflation proofing, and the remaining 5 percent is distributed to all qualifying Alaskans. To qualify for the Alaska State Permanent Fund one must have lived in the state for a minimum of 12 months, and maintain constant residency.
Cost of living.
The cost of goods in Alaska has long been higher than in the contiguous 48 states. This has changed for the most part in Anchorage and to a lesser extent in Fairbanks, where the cost of living has dropped somewhat in the past five years. Federal government employees, particularly United States Postal Service (USPS) workers and active-duty military members, receive a Cost of Living Allowance usually set at 25% of base pay because, while the cost of living has gone down, it is still one of the highest in the country.
The introduction of big-box stores in Anchorage, Fairbanks (Wal-Mart in March 2004), and Juneau also did much to lower prices. However, rural Alaska suffers from extremely high prices for food and consumer goods, compared to the rest of the country due to the relatively limited transportation infrastructure. Many rural residents come into these cities and purchase food and goods in bulk from warehouse clubs like Costco and Sam's Club. Some have embraced the free shipping offers of some online retailers to purchase items much more cheaply than they could in their own communities, if they are available at all.
Agriculture.
Due to the northern climate and steep terrain, relatively little farming occurs in Alaska. Most farms are in either the Matanuska Valley, about northeast of Anchorage, or on the Kenai Peninsula, about southwest of Anchorage. The short 100-day growing season limits the crops that can be grown, but the long sunny summer days make for productive growing seasons. The primary crops are potatoes, carrots, lettuce, and cabbage. Farmers exhibit produce at the Alaska State Fair. "Alaska Grown" is used as an agricultural slogan.
Alaska has an abundance of seafood, with the primary fisheries in the Bering Sea and the North Pacific, and seafood is one of the few food items that is often cheaper within the state than outside it. Many Alaskans fish the rivers during salmon season to gather significant quantities of their household diet while fishing for subsistence, sport, or both.
Hunting for subsistence, primarily caribou, moose, and Dall sheep is still common in the state, particularly in remote Bush communities. An example of a traditional native food is Akutaq, the Eskimo ice cream, which can consist of reindeer fat, seal oil, dried fish meat and local berries.
Most food in Alaska is transported into the state from "outside", and shipping costs make food in the cities relatively expensive. In rural areas, subsistence hunting and gathering is an essential activity because imported food is prohibitively expensive. The cost of importing food to villages begins at 7¢ per pound (15¢/kg) and rises rapidly to 50¢ per pound ($1.10/kg) or more. The cost of delivering a seven-pound gallon of milk is about $3.50 in many villages where per capita income can be $20,000 or less. Fuel for snow machines and boats that consume a couple of gallons per hour can exceed $8.00 per gallon.
Roads.
Alaska has few road connections compared to the rest of the U.S. The state's road system covers a relatively small area of the state, linking the central population centers and the Alaska Highway, the principal route out of the state through Canada. The state capital, Juneau, is not accessible by road, only a car ferry, which has spurred several debates over the decades about moving the capital to a city on the road system, or building a road connection from Haines. The western part of Alaska has no road system connecting the communities with the rest of Alaska.
One unique feature of the Alaska Highway system is the Anton Anderson Memorial Tunnel, an active Alaska Railroad tunnel recently upgraded to provide a paved roadway link with the isolated community of Whittier on Prince William Sound to the Seward Highway about southeast of Anchorage. At the tunnel was the longest road tunnel in North America until 2007. The tunnel is the longest combination road and rail tunnel in North America.
Rail.
Built around 1915, the Alaska Railroad (ARR) played a key role in the development of Alaska through the 20th century. It links north Pacific shipping through providing critical infrastructure with tracks that run from Seward to Interior Alaska by way of South Central Alaska, passing through Anchorage, Eklutna, Wasilla, Talkeetna, Denali, and Fairbanks, with spurs to Whittier, Palmer and North Pole. The cities, towns, villages, and region served by ARR tracks are known statewide as "The Railbelt". In recent years, the ever-improving paved highway system began to eclipse the railroad's importance in Alaska's economy.
The railroad, though famed for its summertime tour passenger service, played a vital role in Alaska's development, moving freight into Alaska while transporting natural resources southward (i.e., coal from the Usibelli coal mine near Healy to Seward and gravel from the Matanuska Valley to Anchorage).
The Alaska Railroad was one of the last railroads in North America to use cabooses in regular service and still uses them on some gravel trains. It continues to offer one of the last flag stop routes in the country. A stretch of about of track along an area north of Talkeetna remains inaccessible by road; the railroad provides the only transportation to rural homes and cabins in the area; until construction of the Parks Highway in the 1970s, the railroad provided the only land access to most of the region along its entire route.
In northern Southeast Alaska, the White Pass and Yukon Route also partly runs through the State from Skagway northwards into Canada (British Columbia and Yukon Territory), crossing the border at White Pass Summit. This line is now mainly used by tourists, often arriving by cruise liner at Skagway. It featured in the 1983 BBC television series Great Little Railways.
Marine transport.
Most cities, towns and villages in the state do not have road or highway access; the only modes of access involve travel by air, river, or the sea.
Alaska's well-developed state-owned ferry system (known as the Alaska Marine Highway) serves the cities of Alaska Panhandle, the Gulf Coast and the Alaska Peninsula. The system also operates a ferry service from Bellingham, Washington and Prince Rupert, British Columbia in Canada through the Inside Passage to Skagway. The Inter-Island Ferry Authority also serves as an important marine link for many communities in the Prince of Wales Island region of Southeast and works in concert with the Alaska Marine Highway.
In recent years, large cruise ships began creating a summertime tourism market, mainly connecting the Pacific Northwest to Southeast Alaska and, to a lesser degree, towns along the north gulf coast. Several times each summer, the population of Ketchikan sharply rises for a few hours when two ships dock to debark more than a thousand passengers each while four other ships lie at anchor nearby, waiting their turn at the dock.
Air transport.
Cities not served by road, sea, or river can be reached only by air, foot, dogsled, or snowmachine accounting for Alaska's extremely well-developed bush air services—an Alaskan novelty. Anchorage itself, and to a lesser extent Fairbanks, are served by many major airlines. Because of limited highway access, air travel remains the most efficient form of transportation in and out of the state. Anchorage recently completed extensive remodeling and construction at Ted Stevens Anchorage International Airport to help accommodate the upsurge in tourism (in 2000–2001, the latest year for which data is available, 2.4 million total arrivals to Alaska were counted, 1.7 million by air travel; 1.4 million were visitors).
Regular flights to most villages and towns within the state that are commercially viable are challenging to provide, so they are heavily subsidized by the federal government through the Essential Air Service program. Alaska Airlines is the only major airline offering in-state travel with jet service (sometimes in combination cargo and passenger Boeing 737-400s) from Anchorage and Fairbanks to regional hubs like Bethel, Nome, Kotzebue, Dillingham, Kodiak, and other larger communities as well as to major Southeast and Alaska Peninsula communities. The bulk of remaining commercial flight offerings come from small regional commuter airlines such as Era Aviation, PenAir, and Frontier Flying Service. The smallest towns and villages must rely on scheduled or chartered bush flying services using general aviation aircraft such as the Cessna Caravan, the most popular aircraft in use in the state. Much of this service can be attributed to the Alaska bypass mail program which subsidizes bulk mail delivery to Alaskan rural communities. The program requires 70% of that subsidy to go to carriers who offer passenger service to the communities. Many communities have small air taxi services, such as Hudson's Air Service, Kantishna Air Taxi, and Talkeetna Air Taxi. These operations, though now catering primarily to tourists, originated from the demand for customized transport to remote areas. Perhaps the most quintessentially Alaskan plane is the bush seaplane. The world's busiest seaplane base is Lake Hood, located next to Ted Stevens Anchorage International Airport, where flights bound for remote villages without an airstrip carry passengers, cargo, and many items from stores and warehouse clubs. Alaska has the highest number of pilots per capita of any U.S. state: out of the estimated 663,661 residents, 8,550 are pilots, or about one in 78.
Other transport.
Another Alaskan transportation method is the dogsled. In modern times (that is, any time after the mid-late 1920s), dog mushing is more of a sport than a true means of transportation. Various races are held around the state, but the best known is the Iditarod Trail Sled Dog Race, a 1150-mile (1850 km) trail from Anchorage to Nome (although the mileage varies from year to year, the official distance is set at 1049 miles). The race commemorates the famous 1925 serum run to Nome in which mushers and dogs like Togo and Balto took much-needed medicine to the diphtheria-stricken community of Nome when all other means of transportation had failed. Mushers from all over the world come to Anchorage each March to compete for cash, prizes, and prestige. The "Serum Run" is another sled dog race that more accurately follows the route of the famous 1925 relay, leaving from the community of Nenana (southwest of Fairbanks) to Nome.
In areas not served by road or rail, primary transportation in summer is by all-terrain vehicle and in winter by snowmobile or "snow machine," as it is commonly referred to in Alaska.
State government.
Like all other U.S. states, Alaska is governed as a republic, with three branches of government: an executive branch consisting of the Governor of Alaska and the other independently elected constitutional officers; a legislative branch consisting of the Alaska House of Representatives and Alaska Senate; and a judicial branch consisting of the Alaska Supreme Court and lower courts.
The State of Alaska employs approximately 15,000 employees statewide.
The Alaska Legislature consists of a 40-member House of Representatives and a 20-member Senate. Senators serve four year terms and House members two. The Governor of Alaska serves four-year terms. The lieutenant governor runs separately from the governor in the primaries, but during the general election, the nominee for governor and nominee for lieutenant governor run together on the same ticket.
Alaska's court system has four levels: the Alaska Supreme Court, the court of appeals, the superior courts and the district courts. The superior and district courts are trial courts. Superior courts are courts of general jurisdiction, while district courts only hear certain types of cases, including misdemeanor criminal cases and civil cases valued up to $100,000. The Supreme Court and the Court Of Appeals are appellate courts. The Court Of Appeals is required to hear appeals from certain lower-court decisions, including those regarding criminal prosecutions, juvenile delinquency, and habeas corpus. The Supreme Court hears civil appeals and may in its discretion hear criminal appeals.
State politics.
Although Alaska entered the union as a Democratic state, since the early 1970s Alaska has been characterized as a Republican-leaning state. Local political communities have often worked on issues related to land use development, fishing, tourism, and individual rights. Alaska Natives, while organized in and around their communities, have been active within the Native corporations. These have been given ownership over large tracts of land, which require stewardship.
Alaska is the only state in which possession of one ounce or less of marijuana in one's home is completely legal under state law, though the federal law remains in force.
The state has an independence movement favoring a vote on secession from the United States, with the Alaska Independence Party labeled as one of "the most significant state-level third parties operating in the 20th century".
Six Republicans and four Democrats have served as governor of Alaska. In addition, Republican Governor Wally Hickel was elected to the office for a second term in 1990 after leaving the Republican party and briefly joining the Alaskan Independence Party ticket just long enough to be reelected. He subsequently officially rejoined the Republican party in 1994.
Taxes.
To finance state government operations, Alaska depends primarily on petroleum revenues and federal subsidies. This allows it to have the lowest individual tax burden in the United States, and be one of only five states with no state sales tax, one of seven states that do not levy an individual income tax, and one of two states that has neither. The Department of Revenue Tax Division reports regularly on the state's revenue sources. The Department also issues an annual summary of its operations, including new state laws that directly affect the tax division.
While Alaska has no state sales tax, 89 municipalities collect a local sales tax, from 1–7.5%, typically 3–5%. Other local taxes levied include raw fish taxes, hotel, motel, and bed-and-breakfast 'bed' taxes, severance taxes, liquor and tobacco taxes, gaming (pull tabs) taxes, tire taxes and fuel transfer taxes. A part of the revenue collected from certain state taxes and license fees (such as petroleum, aviation motor fuel, telephone cooperative) is shared with municipalities in Alaska.
Fairbanks has one of the highest property taxes in the state as no sales or income taxes are assessed in the Fairbanks North Star Borough (FNSB). A sales tax for the FNSB has been voted on many times, but has yet to be approved, leading law makers to increase taxes dramatically on other goods such as liquor and tobacco.
In 2008 the Tax Foundation ranked Alaska as having the 4th most "business friendly" tax policy. More "friendly" states were Wyoming, Nevada, and South Dakota.
Federal politics.
In presidential elections, the state's electoral college votes have been won by the Republican nominee in every election since statehood, except for 1964. No state has voted for a Democratic presidential candidate fewer times. Alaska supported Democratic nominee Lyndon B. Johnson in the landslide year of 1964, although the 1960 and 1968 elections were close. Republican John McCain defeated Democrat Barack Obama in Alaska, 59.49% to 37.83%. McCain's running mate was Sarah Palin, the state's governor and the first Alaskan on a major party ticket. The Alaska Bush, the city of Juneau and midtown and downtown Anchorage have been strongholds of the Democratic party. Matanuska-Susitna Borough and South Anchorage typically have the strongest Republican showing. As of 2004, well over half of all registered voters have chosen "Non-Partisan" or "Undeclared" as their affiliation, despite recent attempts to close primaries.
Because of its population relative to other U.S. states, Alaska has only one member in the U.S. House of Representatives. This seat is currently being held by Republican Don Young, who was re-elected to his 19th consecutive term in 2008.
On November 19, 2008, Democrat Mark Begich, mayor of Anchorage, defeated long-time Republican senator Ted Stevens. Stevens had been convicted on seven felony counts of failing to report gifts on Senate financial discloser forms one week before the election. The conviction was set aside in April 2009 after evidence of prosecutorial misconduct emerged.
Republican Frank Murkowski held the state's other senatorial position. After being elected governor in 2002, he resigned from the Senate and appointed his daughter, State Representative Lisa Murkowski as his successor. In response to a subsequent ballot initiative, the state legislature attempted to amend the law to limit the length of gubernatorial appointments. She won a full six-year term in 2004. In 2006 Frank Murkowski was defeated in the Republican primary by Sarah Palin, who in 2008 became the Republican nominee for Vice President of the United States.
Cities, towns and boroughs.
Alaska is not divided into counties, as most of the other U.S. states, but it is divided into "boroughs". Many of the more densely populated parts of the state are part of Alaska's sixteen boroughs, which function somewhat similarly to counties in other states. However, unlike county-equivalents in the other 49 states, the boroughs do not cover the entire land area of the state. The area not part of any borough is referred to as the Unorganized Borough. The Unorganized Borough has no government of its own, but the U.S. Census Bureau in cooperation with the state divided the Unorganized Borough into 11 census areas solely for the purposes of statistical analysis and presentation. A recording district is a mechanism for administration of the public record in Alaska. The state is divided into 34 recording districts which are centrally administered under a State Recorder. All recording districts use the same acceptance criteria, fee schedule, etc., for accepting documents into the public record.
Whereas many U.S. states use a three-tiered system of decentralization—state/county/township—most of Alaska uses only two tiers—state/borough. Owing to the low population density, most of the land is located in the Unorganized Borough which, as the name implies, has no intermediate borough government of its own, but is administered directly by the state government. Currently (2000 census) 57.71% of Alaska's area has this status, with 13.05% of the population. For statistical purposes the United States Census Bureau divides this territory into census areas. Anchorage merged the city government with the Greater Anchorage Area Borough in 1975 to form the Municipality of Anchorage, containing the city proper and the communities of Eagle River, Chugiak, Peters Creek, Girdwood, Bird, and Indian. Fairbanks has a separate borough (the Fairbanks North Star Borough) and municipality (the City of Fairbanks).
The state's most populous city is Anchorage, home to 278,700 people in 2006, 225,744 of whom live in the urbanized area. The richest location in Alaska by per capita income is Halibut Cove ($89,895). Yakutat City, Sitka, Juneau, and Anchorage are the four largest cities in the U.S. by area.
Education.
The Alaska Department of Education and Early Development administers many school districts in Alaska. In addition, the state operates a boarding school, Mt. Edgecumbe High School in Sitka; and provides partial funding for other boarding schools including, Nenana Student Living Center in Nenana, and The Galena Interior Learning Academy in Galena.
There are more than a dozen colleges and universities in Alaska. Accredited universities in Alaska include the University of Alaska Anchorage, University of Alaska Fairbanks, University of Alaska Southeast, and Alaska Pacific University. 43% of the population attends or attended college.
Alaska has had a problem with a "brain drain". Many of its young people, including most of the highest academic achievers, leave the state after high school graduation and do not return. The University of Alaska has attempted to combat this by offering partial four-year scholarships to the top 10% of Alaska high school graduates, via the Alaska Scholars Program.
Public health and public safety.
Alaska residents have long had a problem with alcohol use and abuse. Many rural communities in Alaska have outlawed its import. This problem directly relates to Alaska's high rate of Fetal alcohol syndrome (FAS) as well as contributing to the high rate of suicides and teenage pregnancies. Suicide rates for rural residents are higher than urban.
Domestic abuse and other violent crimes are also at high levels in the state; this is in part linked to alcohol abuse.
Culture.
Some of Alaska's popular annual events are the Iditarod Trail Sled Dog Race that starts in Anchorage and ends in Nome, World Ice Art Championships in Fairbanks, the Alaska Hummingbird Festival in Ketchikan, the Sitka Whale Fest, and the Stikine River Garnet Fest in Wrangell. The Stikine River features the largest springtime concentration of American Bald Eagles in the world.
The Alaska Native Heritage Center celebrates the rich heritage of Alaska's 11 cultural groups. Their purpose is to enhance self-esteem among Native people and to encourage cross-cultural exchanges among all people. The Alaska Native Arts Foundation promotes and markets Native art from all regions and cultures in the State, both on the internet; at its gallery in Anchorage, 500 West Sixth Avenue, and at the Alaska House New York, 109 Mercer Street in SoHo.
Alaska Natives – Inuit, Inupiaq or Yupik drummers and dancers – give informal performances in the lobby of the Alaska Native Medical Center in Anchorage on weekday evenings.
Libraries.
The four main libraries in the state are the Alaska State Library in Juneau, the Elmer E. Rasmuson Library in Fairbanks, the Z. J. Loussac Library in Anchorage, and the APU Consortium Library, also in Anchorage. Alaska is one of three states (the others are Delaware and Rhode Island) that does not have a Carnegie library.
Music.
Influences on music in Alaska include the traditional music of Alaska Natives as well as folk music brought by later immigrants from Russia and Europe. Prominent musicians from Alaska include singer Jewel, traditional Aleut flautist Mary Youngblood, folk singer-songwriter Libby Roderick, Christian music singer/songwriter Lincoln Brewster, metal/post hardcore band 36 Crazyfists and the groups Pamyua and Portugal. The Man.
There are many established music festivals in Alaska, including the Alaska Folk Festival, the Fairbanks Summer Arts Festival the Anchorage Folk Festival, the Athabascan Old-Time Fiddling Festival, the Sitka Jazz Festival, and the Sitka Summer Music Festival. The most prominent symphony in Alaska is the Anchorage Symphony Orchestra, though the Fairbanks Symphony Orchestra and Juneau Symphony are also notable. The Anchorage Opera is currently the state's only professional opera company, though there are several volunteer and semi-professional organizations in the state as well.
The official state song of Alaska is "Alaska's Flag", which was adopted in 1955; it celebrates the flag of Alaska.
Movies filmed in Alaska.
Alaska's first independent picture all made on place was in the silent years. The Chechahcos, was released in 1924 by the Alaska Moving Picture Corp. It was the only film the company made.
One of the most prominent movies filmed in Alaska is MGM's Academy Award winning classic "Mala The Magnificent" starring Alaska's own Ray Mala. In 1932 an expedition set out from MGM's studios in Hollywood to Alaska to film what was then billed as "The Biggest Picture Ever Made." Upon arriving in Alaska, they set up "Camp Hollywood" in Northwest Alaska, where they lived during the duration of the filming. Louis B. Mayer spared no expense in making sure they had everything they needed during their stay—he even sent the famous chef from the Hotel Roosevelt on Hollywood Blvd (the site of the first Oscars) with them to Alaska to cook for them. When "Eskimo" premiered at the famed Astor Theatre in Times Square, New York, the studio received the largest amount of feedback in the history of the studio up to that time. "Eskimo" was critically acclaimed and released worldwide; as a result Inupiat Eskimo actor Ray Mala became an international movie star. "Eskimo" is significant for the following: winning the very first Oscar for Best Film Editing at the Academy Awards, for forever preserving Inupiat culture on film, and for being the first motion picture to be filmed in an all native language (Inupiat).
The psychological thriller "Insomnia", starring Al Pacino and Robin Williams was shot in Canada, but was set in Alaska. The 2007 horror feature "30 Days of Night" is set in Barrow, Alaska but was filmed in New Zealand. Most films and television shows set in Alaska are not filmed there; for example, "Northern Exposure", set in the fictional town of Cicely, Alaska, was actually filmed in Roslyn, Washington.
The 1983 Disney movie "Never Cry Wolf" was at least partially shot in Alaska. The 1991 film "White Fang", starring Ethan Hawke, was filmed in and around Haines, Alaska. The 1999 John Sayles film "Limbo", starring David Strathairn, Mary Elizabeth Mastrantonio and Kris Kristofferson, was filmed in Juneau.
The 2007 film directed by Sean Penn, "Into The Wild" was partially filmed and set in Alaska. The film, which is based on the novel of the same name, follows the adventures of Christopher McCandless, who died in a remote abandoned bus in Alaska in 1992.
---END.OF.DOCUMENT---
Aldous Huxley.
Aldous Leonard Huxley (26 July 1894 – 22 November 1963) was an English writer and one of the most prominent members of the famous Huxley family. He spent the later part of his life in the United States, living in Los Angeles from 1937 until his death in 1963. Best known for his novels including "Brave New World" and wide-ranging output of essays, Huxley also edited the magazine "Oxford Poetry", and published short stories, poetry, travel writing, and film stories and scripts.
Aldous Huxley was a humanist and pacifist, and he was latterly interested in spiritual subjects such as parapsychology and philosophical mysticism. He is also well known for advocating and taking psychedelics.
By the end of his life Huxley was considered, in some academic circles, a leader of modern thought and an intellectual of the highest rank, and highly regarded as one of the most prominent explorers of visual communication and sight-related theories as well.
Early years.
Aldous Huxley was born in Godalming, Surrey, UK in 1894. He was the third son of the writer and school-master Leonard Huxley and first wife, Julia Arnold who founded Prior's Field School. Julia was the niece of Matthew Arnold and the sister of Mrs. Humphrey Ward. Aldous was the grandson of Thomas Henry Huxley, the zoologist, agnostic and controversialist ("Darwin's Bulldog"). His brother Julian Huxley and half-brother Andrew Huxley also became outstanding biologists. Huxley had another brother Noel Trevenen (1891–1914) who committed suicide after a period of clinical depression.
Huxley began his learning in his father's well-equipped botanical laboratory, then continued in a school named Hillside. His teacher was his mother who supervised him for several years until she became terminally ill. After Hillside, he was educated at Eton College. Huxley's mother died in 1908, when he was fourteen. In 1911, he suffered an illness (keratitis punctata) which "left [him] practically blind for two to three years". Aldous's near-blindness disqualified him from service in the First World War. Once his eyesight recovered sufficiently, he was able to study English literature at Balliol College, Oxford. In 1916 he edited "Oxford Poetry" and later graduated with first class honours.
Following his education at Balliol, Huxley was financially indebted to his father and had to earn a living. He taught French for a year at Eton, where Eric Blair (later known by the pen name George Orwell) and Stephen Runciman were among his pupils, but was remembered as an incompetent and hopeless teacher who couldn’t keep discipline. Nevertheless, Blair and others were impressed by his use of words. For a short while in 1918, he was employed acquiring provisions at the Air Ministry.
Significantly, Huxley also worked for a time in the 1920s at the technologically-advanced Brunner and Mond chemical plant in Billingham, Teesside, and the most recent introduction to his famous science fiction novel "Brave New World" (1932) states that this experience of "an ordered universe in a world of planless incoherence" was one source for the novel.
Huxley completed his first (unpublished) novel at the age of seventeen and began writing seriously in his early twenties. His earlier work includes important novels on the dehumanizing aspects of scientific progress, most famously "Brave New World", and on pacifist themes (for example, "Eyeless in Gaza"). In "Brave New World" Huxley portrays a society operating on the principles of mass production and Pavlovian conditioning. Huxley was strongly influenced by F. Matthias Alexander and included him as a character in "Eyeless in Gaza".
Middle years.
During the First World War, Huxley spent much of his time at Garsington Manor, home of Lady Ottoline Morrell, working as a farm labourer. Here he met several Bloomsbury figures including Bertrand Russell and Clive Bell. Later, in "Crome Yellow" (1921) he caricatured the Garsington lifestyle. In 1919 he married Maria Nys (10 September 1899 - 12 February 1955), a Belgian woman he met at Garsington. They had one child, Matthew Huxley (19 April 1920 - 10 February 2005), who had a career as an epidemiologist. The family lived in Italy part of the time in the 1920s, where Huxley would visit his friend D. H. Lawrence. Following Lawrence's death in 1930, Huxley edited Lawrence's letters (1933).
In 1937, Huxley moved to Hollywood, California with his wife Maria, son Matthew, and friend Gerald Heard. He lived in the U.S., mainly in southern California, until his death, but also for a time in Taos, New Mexico, where he wrote "Ends and Means" (published in 1937). In this work he examines the fact that although most people in modern civilization agree that they want a world of "liberty, peace, justice, and brotherly love", they have not been able to agree on how to achieve it.
Heard introduced Huxley to Vedanta (Veda-Centric Hinduism), meditation, and vegetarianism through the principle of ahimsa. In 1938 Huxley befriended J. Krishnamurti, whose teachings he greatly admired. He also became a Vedantist in the circle of Hindu Swami Prabhavananda, and introduced Christopher Isherwood to this circle. Not long after, Huxley wrote his book on widely held spiritual values and ideas, "The Perennial Philosophy", which discussed the teachings of renowned mystics of the world.
Huxley became a close friend of Remsen Bird, president of Occidental College. He spent much time at the college, which is in the Eagle Rock neighborhood of Los Angeles. The college appears as "Tarzana College" in his satirical novel "After Many a Summer" (1939). The novel won Huxley that year's James Tait Black Memorial Prize for fiction. Huxley also incorporated Bird into the novel.
During this period Huxley earned some Hollywood income as a writer. In March 1938, his friend Anita Loos, a novelist and screenwriter, put him in touch with Metro-Goldwyn-Mayer who hired Huxley for "Madame Curie" which was originally to star Greta Garbo and be directed by George Cukor. (The film was eventually filmed by MGM in 1943 with a different director and stars.) Huxley received screen credit for "Pride and Prejudice" (1940) and was paid for his work on a number of other films, including "Jane Eyre" (1944).
However, his experience in Hollywood was not a success. When he wrote a synopsis of "Alice in Wonderland", Walt Disney rejected it on the grounds that "he could only understand every third word". Huxley's leisurely development of ideas, it seemed, was not suitable for the movie moguls, who demanded fast, dynamic dialogue above all else.
On 21 October 1949, Huxley wrote to George Orwell, author of "Nineteen Eighty-Four", congratulating Orwell on "how fine and how profoundly important the book is". In his letter to Orwell, he predicted: "Within the next generation I believe that the world's leaders will discover that infant conditioning and narco-hypnosis are more efficient, as instruments of government, than clubs and prisons, and that the lust for power can be just as completely satisfied by suggesting people into loving their servitude as by flogging them and kicking them into obedience."
Post-war.
After the Second World War Huxley applied for United States citizenship, but his application was continuously deferred on the grounds that he would not say he would take up arms to defend the U.S., so he withdrew it. Nevertheless, he remained in the country, and in 1959 he turned down an offer of a Knight Bachelor by the Macmillan government. During the 1950s Huxley's interest in the field of psychical research grew keener, and his later works are strongly influenced by both mysticism and his experiences with psychedelic drugs.
In October 1930, the occultist Aleister Crowley dined with Huxley in Berlin, and to this day rumours persist that Crowley introduced Huxley to peyote on that occasion. He was introduced to mescaline (considered to be the key active ingredient of peyote) by the psychiatrist Humphry Osmond in 1953. Through Dr. Osmond, Huxley met millionaire Alfred Matthew Hubbard who would deal with LSD on a wholesale basis. On 24 December 1955, Huxley took his first dose of LSD. Indeed, Huxley was a pioneer of self-directed psychedelic drug use "in a search for enlightenment", famously taking 100 micrograms of LSD as he lay dying. His psychedelic drug experiences are described in the essays "The Doors of Perception" (the title deriving from some lines in the book "The Marriage of Heaven and Hell" by William Blake), and "Heaven and Hell". Some of his writings on psychedelics became frequent reading among early hippies. While living in Los Angeles, Huxley was a friend of Ray Bradbury. According to Sam Weller's biography of Bradbury, the latter was dissatisfied with Huxley, especially after Huxley encouraged Bradbury to take psychedelic drugs.
In 1955, Huxley's wife, Maria, died of breast cancer. In 1956 he married Laura Archera (1911–2007), also an author. She wrote "This Timeless Moment", a biography of Huxley. In 1960 Huxley himself was diagnosed with cancer, and in the years that followed, with his health deteriorating, he wrote the Utopian novel "Island", and gave lectures on "Human Potentialities" at the Esalen institute, which were fundamental to the forming of the Human Potential Movement.
On his deathbed, unable to speak, Huxley made a written request to his wife for "LSD, 100 µg, intramuscular". According to her account of his death, in "This Timeless Moment", she obliged with an injection at 11:45 am and another a couple of hours later. He died at 5:21 pm on 22 November 1963, aged 69. Huxley's ashes were interred in the family grave at the Watts Cemetery, home of the Watts Mortuary Chapel in Compton, a village near Guildford, Surrey, England.
Media coverage of his death was overshadowed by the assassination of President John F. Kennedy, on the same day, as was the death of the Irish author C. S. Lewis. This coincidence was the inspiration for Peter Kreeft's book '.
Huxley's only child, Matthew Huxley, was also an author, as well as an educator, anthropologist, and prominent epidemiologist. Aldous Huxley is also survived by two grandchildren.
Association with Vedanta.
Beginning in 1939 and continuing until his death in 1963, Huxley had an extensive association with the Vedanta Society of Southern California, founded and headed by Swami Prabhavananda. Together with Gerald Heard, Christopher Isherwood, and other followers he was initiated by the Swami and was taught meditation and spiritual practices.
In 1944 Huxley wrote the introduction to the "Bhagavad Gita: The Song of God", translated by Swami Prabhavanada and Christopher Isherwood, which was published by The Vedanta Society of Southern California.
From 1941 through 1960 Huxley contributed 48 articles to "Vedanta and the West", published by the Society. He also served on the editorial board with Isherwood, Heard, and playwright John van Druten from 1951 through 1962.
Huxley also occasionally lectured at the Hollywood and Santa Barbara Vedanta temples. Two of those lectures have been released on CD: "Knowledge and Understanding" and "Who Are We" from 1955.
After the publication of "The Doors of Perception", Huxley and the Swami disagreed about the meaning and importance of the LSD drug experience, which may have caused the relationship to cool, but Huxley continued to write articles for the Society's journal, lecture at the temple, and attend social functions.
Literary themes.
"Crome Yellow" (1921) attacks Victorian and Edwardian social principles which led to World War I and its terrible aftermath. Together with Huxley's second novel, "Antic Hay" (1923), the book expresses much of the mood of disenchantment of the early 1920s. It was intended to reflect, as Huxley stated in a letter to his father, "the life and opinions of an age which has seen the violent disruption of almost all the standards, conventions and values current in the present epoch."
Huxley's reputation for iconoclasm and emancipation grew. He was condemned for his explicit discussion of sex and free thought in his fiction. "Antic Hay", for example, was burned in Cairo and in the years that followed many of Huxley's books were received with disapproval or banned at one time or another. The exclusion of "Brave New World", "Point Counter Point" and "Island" from "Time" magazine's Best 100 novels list in 2006 created an uproar.
Huxley, however, said that a novel should be full of interesting opinions and arresting ideas, describing his aim as a novelist as being 'to arrive, technically, at a perfect fusion of the novel and the essay'; and with "Point Counter Point" (1928), Huxley wrote his first true 'novel of ideas', the type of thought-provoking fiction with which he is now associated.
One of his main ideas was pessimism about the cultural future of society, a pessimism which sprang largely from his visit to the United States between September 1925 and June 1926. He recounted his experiences in "Jesting Pilate" (1926): "The thing which is happening in America is a reevaluation of values, a radical alteration (for the worse) of established standards", and it was soon after this visit that he conceived the idea of writing a satire of what he had encountered.
"Brave New World" (1932) as well as "Island" (1962) form the cornerstone of Huxley's damning indictment of commercialism based upon goods generally manufactured from other countries. Indeed also, "Brave New World" (along with Orwell's "Nineteen Eighty-Four" and Yevgeni Zamyatin's "We") helped form the anti-utopian or dystopian tradition in literature and has become synonymous with a future world in which the human spirit is subject to conditioning and control. "Island" acts as an antonym to "Brave New World"; it is described as "one of the truly great philosophical novels".
He devoted his time at his small house at Llano in the Mojave Desert to a life of contemplation, mysticism, and experimentation with hallucinogenic drugs. His suggestions in The Doors of Perception (1954) that mescaline and lysergic acid were 'drugs of unique distinction' which should be exploited for the 'supernaturally brilliant' visionary experience they offered provoked even more outrage than his passionate defense of the Bates method in "The Art of Seeing" (1942). However, the book went on to become a cult text in the psychedelic 1960s, and inspire the name of the rock band The Doors (although it was originally derived from William Blake's "Marriage of Heaven and Hell"). Huxley also appears on the sleeve of The Beatles' landmark 1967 album "Sgt. Pepper's Lonely Hearts Club Band".
Eyesight.
With respect to details about the true quality of Huxley’s eyesight at specific points in his life, there are differing accounts. Around 1939, Huxley encountered the Bates Method for better eyesight, and a teacher, Margaret Corbett, who was able to teach him in the method. In 1940, Huxley relocated from Hollywood to a "ranchito" in the high desert hamlet of Llano, California in northernmost Los Angeles County. Huxley then said that his sight improved dramatically with the Bates Method and the extreme and pure natural lighting of the southwestern American desert. He reported that for the first time in over 25 years, he was able to read without glasses and without strain. He even tried driving a car along the dirt road beside the ranch. He wrote a book about his successes with the Bates Method, "The Art of Seeing" which was published in 1942 (US), 1943 (UK). It was from this period, with the publication of the generally disputed theories contained in the latter book, that a growing degree of popular controversy arose over the subject of Huxley’s eyesight.
"Then suddenly he faltered—and the disturbing truth became obvious. He wasn't reading his address at all. He had learned it by heart. To refresh his memory he brought the paper closer and closer to his eyes. When it was only an inch or so away he still couldn't read it, and had to fish for a magnifying glass in his pocket to make the typing visible to him. It was an agonizing moment."
"...Although I feel it was an injustice to treat Aldous as though he were blind, it is true there were many indications of his impaired vision. For instance, although Aldous did not wear glasses, he would quite often use a magnifying lens..."
"The most characteristic fact about the functioning of the total organism, or any part of the organism, is that it is not constant, but highly variable."
Nevertheless, the topic of Huxley’s eyesight continues to endure similar, significant controversy, regardless of how trivial a subject matter it might initially appear.
Awards.
In 1959 Aldous Huxley received the American Academy of Arts and Letters Award of Merit for the novel "Brave New World". He received the James Tait Black Memorial Prize in 1939 for "After Many a Summer Dies the Swan".
In 1962, Huxley was awarded the Companion of Literature by the Royal Society of Literature.
Films.
Notable works include the original screenplay for Disney's animated "Alice in Wonderland" (which was rejected because it was too literary), two productions of "Brave New World", one of "Point Counter Point", one of "Eyeless in Gaza", and one of "Ape and Essence". He was a credited screenwriter for "Pride and Prejudice" (1940), co-authored the screenplay for "Jane Eyre" (1944) with John Houseman, "A Woman's Vengeance" (1947), and contributed to the screenplays of "Madame Curie" (1943) and "Alice in Wonderland" (1951) without credit.
Director Ken Russell's 1971 film "The Devils", starring Vanessa Redgrave and Oliver Reed, was adapted from Huxley's "The Devils of Loudun". A made-for-television adaptation of "Brave New World" was made in 1990.
---END.OF.DOCUMENT---
Aberdeen (disambiguation).
Aberdeen is a city in Scotland, United Kingdom.
---END.OF.DOCUMENT---
Alkane.
Alkanes, also known as paraffins, are chemical compounds that consist only of the elements carbon (C) and hydrogen (H) (i.e., hydrocarbons), wherein these atoms are linked together exclusively by single bonds (i.e., they are saturated compounds) without any cyclic structure (i.e. loops). Alkanes belong to a homologous series of organic compounds in which the members differ by a constant relative molecular mass of 14.
Each carbon atom must have 4 bonds (either C-H or C-C bonds), and each hydrogen atom must be joined to a carbon atom (H-C bonds). A series of linked carbon atoms is known as the carbon skeleton or carbon backbone. In general, the number of carbon atoms is often used to define the size of the alkane (e.g., C2-alkane).
An alkyl group is a functional group or side-chain that, like an alkane, consists solely of singly-bonded carbon and hydrogen atoms, for example a methyl or ethyl group.
Saturated hydrocarbons can be linear (general formula) wherein the carbon atoms are joined in a snake-like structure, branched (general formula, "n" > 3) wherein the carbon backbone splits off in one or more directions, or cyclic (general formula, "n" > 2) wherein the carbon backbone is linked so as to form a loop. According to the definition by IUPAC, the former two are alkanes, whereas the third group is called cycloalkanes. Saturated hydrocarbons can also combine any of the linear, cyclic (e.g., polycyclic) and branching structures, and they are still alkanes (no general formula) as long as they are acyclic (i.e., having no loops).
The simplest possible alkane (the parent molecule) is methane, CH4. There is no limit to the number of carbon atoms that can be linked together, the only limitation being that the molecule is acyclic, is saturated, and is a hydrocarbon. Saturated oils and waxes are examples of larger alkanes where the number of carbons in the carbon backbone tends to be greater than 10.
Alkanes are not very reactive and have little biological activity. Alkanes can be viewed as a molecular tree upon which can be hung the interesting biologically active/reactive portions (functional groups) of the molecule.
Isomerism.
butane is the only C4H6 compound and has no isomer; tetrahedrane (not shown) is the only C4H4 compound and has also no isomer.
Branched alkanes can be chiral: 3-methylhexane and its higher homologues are chiral due to their stereogenic center at carbon atom number 3. Chiral alkanes are of certain importance in biochemistry, as they occur as sidechains in chlorophyll and tocopherol (vitamin E). Chiral alkanes can be resolved into their enantiomers by enantioselective chromatography.
In addition to these isomers, the chain of carbon atoms may form one or more loops. Such compounds are called cycloalkanes.
Nomenclature.
The IUPAC nomenclature (systematic way of naming compounds) for alkanes is based on identifying hydrocarbon chains. Unbranched, saturated hydrocarbon chains are named systematically with a Greek numerical prefix denoting the number of carbons and the suffix "-ane".
August Wilhelm von Hofmann suggested systematizing nomenclature by using the whole sequence of vowels a, e, i, o and u to create suffixes -ane, -ene, -ine (or -yne), -one, -une, for the hydrocarbons. The first three name hydrocarbons with single, double and triple bonds; "-one" represents a ketone; "-ol" represents an alcohol or OH group; "-oxy-" means an ether and refers to oxygen between two carbons, so that methoxy-methane is the IUPAC name for dimethyl ether.
It is difficult or impossible to find compounds with more than one IUPAC name. This is because shorter chains attached to longer chains are prefixes and the convention includes brackets. Numbers in the name, referring to which carbon a group is attached to, should be as low as possible, so that 1- is implied and usually omitted from names of organic compounds with only one side-group; "1-" is implied in Nitro-octane. Symmetric compounds will have two ways of arriving at the same name.
Linear alkanes.
Straight-chain alkanes are sometimes indicated by the prefix "n-" (for "normal") where a non-linear isomer exists. Although this is not strictly necessary, the usage is still common in cases where there is an important difference in properties between the straight-chain and branched-chain isomers, e.g., "n"-hexane or 2- or 3-methylpentane.
These names were derived from methanol, ether, propionic acid and butyric acid, respectively. Alkanes with five or more carbon atoms are named by adding the suffix -ane to the appropriate numerical multiplier prefix
with elision of any terminal vowel ("-a" or "-o") from the basic numerical term. Hence, pentane, C5H12; hexane, C6H14; heptane, C7H16; octane, C8H18; etc. The prefix is generally Greek, with the exceptions of nonane which has a Latin prefix, and undecane and tridecane which have mixed-language prefixes. For a more complete list, see List of alkanes.
Branched alkanes.
Simple branched alkanes often have a common name using a prefix to distinguish them from linear alkanes, for example "n"-pentane, isopentane, and neopentane.
IUPAC naming conventions can be used to produce a systematic name.
Cyclic alkanes.
So-called cyclic alkanes are, in the technical sense, "not" alkanes, but cycloalkanes. They are hydrocarbons just like alkanes, but contain one or more rings.
Simple cycloalkanes have a prefix "cyclo-" to distinguish them from alkanes. Cycloalkanes are named as per their acyclic counterparts with respect to the number of carbon atoms, e.g., cyclopentane (C5H10) is a cycloalkane with 5 carbon atoms just like pentane (C5H12), but they are joined up in a five-membered ring. In a similar manner, propane and cyclopropane, butane and cyclobutane, etc.
Substituted cycloalkanes are named similar to substituted alkanes — the cycloalkane ring is stated, and the substituents are according to their position on the ring, with the numbering decided by Cahn-Ingold-Prelog rules.
Trivial names.
The trivial (non-systematic) name for alkanes is "paraffins." Together, alkanes are known as the "paraffin series". Trivial names for compounds are usually historical artifacts. They were coined before the development of systematic names, and have been retained due to familiar usage in industry. Cycloalkanes are also called naphthenes.
It is almost certain that the term paraffin stems from the petrochemical industry. Branched-chain alkanes are called "isoparaffins". The use of the term "paraffin" is a general term and often does not distinguish between a pure compounds and mixtures of isomers with the same chemical formula (i.e., like a chemical anagram), e.g., pentane and isopentane.
Boiling point.
Alkanes experience inter-molecular van der Waals forces. Stronger inter-molecular van der Waals forces give rise to greater boiling points of alkanes.
Under standard conditions, from CH4 to C4H10 alkanes are gaseous; from C5H12 to C17H36 they are liquids; and after C18H38 they are solids. As the boiling point of alkanes is primarily determined by weight, it should not be a surprise that the boiling point has almost a linear relationship with the size (molecular weight) of the molecule. As a rule of thumb, the boiling point rises 20 - 30 °C for each carbon added to the chain; this rule applies to other homologous series.
A straight-chain alkane will have a boiling point higher than a branched-chain alkane due to the greater surface area in contact, thus the greater van der Waals forces, between adjacent molecules. For example, compare isobutane (2-methylpropane) and n-butane (butane), which boil at -12 and 0 °C, and 2,2-dimethylbutane and 2,3-dimethylbutane which boil at 50 and 58 °C, respectively. For the latter case, two molecules 2,3-dimethylbutane can "lock" into each other better than the cross-shaped 2,2-dimethylbutane, hence the greater van der Waals forces.
On the other hand, cycloalkanes tend to have higher boiling points than their linear counterparts due to the locked conformations of the molecules, which give a plane of intermolecular contact.
Melting point.
The melting points of the alkanes follow a similar trend to boiling points for the same reason as outlined above. That is, (all other things being equal) the larger the molecule the higher the melting point. There is one significant difference between boiling points and melting points. Solids have more rigid and fixed structure than liquids. This rigid structure requires energy to break down. Thus the stronger better put together solid structures will require more energy to break apart. For alkanes, this can be seen from the graph above (i.e., the blue line). The odd-numbered alkanes have a lower trend in melting points than even numbered alkanes. This is because even numbered alkanes pack well in the solid phase, forming a well-organised structure, which requires more energy to break apart. The odd-number alkanes pack less well and so the "looser" organised solid packing structure requires less energy to break apart.
The melting points of branched-chain alkanes can be either higher or lower than those of the corresponding straight-chain alkanes, again depending on the ability of the alkane in question to packing well in the solid phase: This is particularly true for isoalkanes (2-methyl isomers), which often have melting points higher than those of the linear analogues.
Conductivity.
Alkanes do not conduct electricity, nor are they substantially polarized by an electric field. For this reason they do not form hydrogen bonds and are insoluble in polar solvents such as water. Since the hydrogen bonds between individual water molecules are aligned away from an alkane molecule, the coexistence of an alkane and water leads to an increase in molecular order (a reduction in entropy). As there is no significant bonding between water molecules and alkane molecules, the second law of thermodynamics suggests that this reduction in entropy should be minimised by minimising the contact between alkane and water: Alkanes are said to be hydrophobic in that they repel water.
Their solubility in nonpolar solvents is relatively good, a property that is called lipophilicity. Different alkanes are, for example, miscible in all proportions among themselves.
The density of the alkanes usually increases with increasing number of carbon atoms, but remains less than that of water. Hence, alkanes form the upper layer in an alkane-water mixture.
Molecular geometry===.
The molecular structure of the alkanes directly affects their physical and chemical characteristics. It is derived from the electron configuration of carbon, which has four valence electrons. The carbon atoms in alkanes are always sp3 hybridised, that is to say that the valence electrons are said to be in four equivalent orbitals derived from the combination of the 2s orbital and the three 2p orbitals. These orbitals, which have identical energies, are arranged spatially in the form of a tetrahedron, the angle of cos−1(−⅓) ≈ 109.47° between them.
Bond lengths and bond angles.
An alkane molecule has only C – H and C – C single bonds. The former result from the overlap of a sp³-orbital of carbon with the 1s-orbital of a hydrogen; the latter by the overlap of two sp³-orbitals on different carbon atoms. The bond lengths amount to 1.09×10−10 m for a C – H bond and 1.54×10−10 m for a C – C bond.
The spatial arrangement of the bonds is similar to that of the four sp³-orbitals—they are tetrahedrally arranged, with an angle of 109.47° between them. Structural formulae that represent the bonds as being at right angles to one another, while both common and useful, do not correspond with the reality.
Conformation.
The structural formula and the bond angles are not usually sufficient to completely describe the geometry of a molecule. There is a further degree of freedom for each carbon – carbon bond: the torsion angle between the atoms or groups bound to the atoms at each end of the bond. The spatial arrangement described by the torsion angles of the molecule is known as its conformation.
Ethane forms the simplest case for studying the conformation of alkanes, as there is only one C – C bond. If one looks down the axis of the C – C bond, one will see the so-called Newman projection. The hydrogen atoms on both the front and rear carbon atoms have an angle of 120° between them, resulting from the projection of the base of the tetrahedron onto a flat plane. However, the torsion angle between a given hydrogen atom attached to the front carbon and a given hydrogen atom attached to the rear carbon can vary freely between 0° and 360°. This is a consequence of the free rotation about a carbon – carbon single bond. Despite this apparent freedom, only two limiting conformations are important: eclipsed conformation and staggered conformation.
The two conformations, also known as rotamers, differ in energy: The staggered conformation is 12.6 kJ/mol lower in energy (more stable) than the eclipsed conformation (the least stable).
This difference in energy between the two conformations, known as the torsion energy, is low compared to the thermal energy of an ethane molecule at ambient temperature. There is constant rotation about the C-C bond. The time taken for an ethane molecule to pass from one staggered conformation to the next, equivalent to the rotation of one CH3-group by 120° relative to the other, is of the order of 10−11 seconds.
The case of higher alkanes is more complex but based on similar principles, with the antiperiplanar conformation always being the most favoured around each carbon-carbon bond. For this reason, alkanes are usually shown in a zigzag arrangement in diagrams or in models. The actual structure will always differ somewhat from these idealised forms, as the differences in energy between the conformations are small compared to the thermal energy of the molecules: Alkane molecules have no fixed structural form, whatever the models may suggest.
Spectroscopic properties.
Virtually all organic compounds contain carbon – carbon and carbon – hydrogen bonds, and so show some of the features of alkanes in their spectra. Alkanes are notable for having no other groups, and therefore for the "absence" of other characteristic spectroscopic features.
Infrared spectroscopy.
The carbon–hydrogen stretching mode gives a strong absorption between 2850 and 2960 cm−1, while the carbon–carbon stretching mode absorbs between 800 and 1300 cm−1. The carbon–hydrogen bending modes depend on the nature of the group: methyl groups show bands at 1450 cm−1 and 1375 cm−1, while methylene groups show bands at 1465 cm−1 and 1450 cm−1. Carbon chains with more than four carbon atoms show a weak absorption at around 725 cm−1.
NMR spectroscopy.
The proton resonances of alkanes are usually found at δH = 0.5 – 1.5. The carbon-13 resonances depend on the number of hydrogen atoms attached to the carbon: δC = 8 – 30 (primary, methyl, -CH3), 15 – 55 (secondary, methylene, -CH2-), 20 – 60 (tertiary, methyne, C-H) and quaternary. The carbon-13 resonance of quaternary carbon atoms is characteristically weak, due to the lack of Nuclear Overhauser effect and the long relaxation time, and can be missed in weak samples, or sample that have not been run for a sufficiently long time.
Mass spectrometry.
Alkanes have a high ionisation energy, and the molecular ion is usually weak. The fragmentation pattern can be difficult to interpret, but, in the case of branched chain alkanes, the carbon chain is preferentially cleaved at tertiary or quaternary carbons due to the relative stability of the resulting free radicals. The fragment resulting from the loss of a single methyl group (M−15) is often absent, and other fragment are often spaced by intervals of fourteen mass units, corresponding to sequential loss of CH2-groups.
Chemical properties.
In general, alkanes show a relatively low reactivity, because their C bonds are relatively stable and cannot be easily broken. Unlike most other organic compounds, they possess no functional groups.
They react only very poorly with ionic or other polar substances. The acid dissociation constant (pKa) values of all alkanes are above 60, hence they are practically inert to acids and bases (see: carbon acids). This inertness is the source of the term "paraffins" (with the meaning here of "lacking affinity"). In crude oil the alkane molecules have remained chemically unchanged for millions of years.
However redox reactions of alkanes, in particular with oxygen and the halogens, are possible as the carbon atoms are in a strongly reduced condition; in the case of methane, the lowest possible oxidation state for carbon (−4) is reached. Reaction with oxygen leads to combustion without any smoke; with halogens, substitution. In addition, alkanes have been shown to interact with, and bind to, certain transition metal complexes in (See: carbon-hydrogen bond activation).
Free radicals, molecules with unpaired electrons, play a large role in most reactions of alkanes, such as cracking and reformation where long-chain alkanes are converted into shorter-chain alkanes and straight-chain alkanes into branched-chain isomers.
In highly branched alkanes, the bond angle may differ significantly from the optimal value (109.5°) in order to allow the different groups sufficient space. This causes a tension in the molecule, known as steric hindrance, and can substantially increase the reactivity.
Reactions with oxygen (combustion reaction).
See the alkane heat of formation table for detailed data.
The standard enthalpy change of combustion, Δc"H"o, for alkanes increases by about 650 kJ/mol per CH2 group. Branched-chain alkanes have lower values of Δc"H"o than straight-chain alkanes of the same number of carbon atoms, and so can be seen to be somewhat more stable.
Reactions with halogens.
Alkanes react with halogens in a so-called "free radical halogenation" reaction. The hydrogen atoms of the alkane are progressively replaced by halogen atoms. Free-radicals are the reactive species that participate in the reaction, which usually leads to a mixture of products. The reaction is highly exothermic, and can lead to an explosion.
Cracking.
Cracking breaks larger molecules into smaller ones. This can be done with a thermal or catalytic method. The thermal cracking process follows a homolytic mechanism with formation of free-radicals. The catalytic cracking process involves the presence of acid catalysts (usually solid acids such as silica-alumina and zeolites), which promote a heterolytic (asymmetric) breakage of bonds yielding pairs of ions of opposite charges, usually a carbocation and the very unstable hydride anion. Carbon-localized free-radicals and cations are both highly unstable and undergo processes of chain rearrangement, C-C scission in position beta (i.e., cracking) and intra- and intermolecular hydrogen transfer or hydride transfer. In both types of processes, the corresponding reactive intermediates (radicals, ions) are permanently regenerated, and thus they proceed by a self-propagating chain mechanism. The chain of reactions is eventually terminated by radical or ion recombination.
Isomerization and reformation.
Isomerization and reformation are processes in which straight-chain alkanes are heated in the presence of a platinum catalyst. In isomerization, the alkanes become branched-chain isomers. In reformation, the alkanes become cycloalkanes or aromatic hydrocarbons, giving off hydrogen as a by-product. Both of these processes raise the octane number of the substance.
Other reactions.
Alkanes will react with steam in the presence of a nickel catalyst to give hydrogen. Alkanes can be chlorosulfonated and nitrated, although both reactions require special conditions. The fermentation of alkanes to carboxylic acids is of some technical importance. In the Reed reaction, sulfur dioxide, chlorine and light convert hydrocarbons to sulfonyl chlorides.
Occurrence of alkanes in the Universe.
Alkanes form a small portion of the atmospheres of the outer gas planets such as Jupiter (0.1% methane, 0.0002% ethane), Saturn (0.2% methane, 0.0005% ethane), Uranus (1.99% methane, 0.00025% ethane) and Neptune (1.5% methane, 1.5 ppm ethane). Titan (1.6% methane), a satellite of Saturn, was examined by the "Huygens" probe, which indicate that Titan's atmosphere periodically rains liquid methane onto the moon's surface. Also on Titan, a methane-spewing volcano was spotted and this volcanism is believed to be a significant source of the methane in the atmosphere. There also appear to be Methane/Ethane lakes near the north polar regions of Titan, as discovered by Cassini's radar imaging. Methane and ethane have also been detected in the tail of the comet Hyakutake. Chemical analysis showed that the abundances of ethane and methane were roughly equal, which is thought to imply that its ices formed in interstellar space, away from the Sun, which would have evaporated these volatile molecules. Alkanes have also been detected in meteorites such as carbonaceous chondrites.
Occurrence of alkanes on Earth.
Traces of methane gas (about 0.0001% or 1 ppm) occur in the Earth's atmosphere, produced primarily by organisms such as Archaea, found for example in the gut of cows.
These hydrocarbons collected in porous rocks, located beneath an impermeable cap rock and so are trapped. Unlike methane, which is constantly reformed in large quantities, higher alkanes (alkanes with 9 or more carbon atoms) rarely develop to a considerable extent in nature. These deposits, e.g., oil fields, have formed over millions of years and once exhausted cannot be readily replaced. The depletion of these hydrocarbons is the basis for what is known as the energy crisis.
Solid alkanes are known as tars and are formed when more volatile alkanes such as gases and oil evaporate from hydrocarbon deposits. One of the largest natural deposits of solid alkanes is in the asphalt lake known as the Pitch Lake in Trinidad and Tobago.
Methane is also present in what is called biogas, produced by animals and decaying matter, which is a possible renewable energy source.
Alkanes have a low solubility in water, so the content in the oceans is negligible; however, at high pressures and low temperatures (such as at the bottom of the oceans), methane can co-crystallize with water to form a solid methane hydrate. Although this cannot be commercially exploited at the present time, the amount of combustible energy of the known methane hydrate fields exceeds the energy content of all the natural gas and oil deposits put together;methane extracted from methane hydrate is considered therefore a candidate for future fuels.
Biological occurrence.
Although alkanes occur in nature in various way, they do not rank biologically among the essential materials. Cycloalkanes with 14 to 18 carbon atoms occur in musk, extracted from deer of the family Moschidae. All further information refers to (acyclic) alkanes.
Certain types of bacteria can metabolise alkanes: they prefer even-numbered carbon chains as they are easier to degrade than odd-numbered chains.
Methanogens are also the producers of marsh gas in wetlands, and release about two billion tonnes of methane per year—the atmospheric content of this gas is produced nearly exclusively by them. The methane output of cattle and other herbivores, which can release up to 150 litres per day, and of termites, is also due to methanogens. They also produce this simplest of all alkanes in the intestines of humans. Methanogenic archaea are, hence, at the end of the carbon cycle, with carbon being released back into the atmosphere after having been fixed by photosynthesis. It is probable that our current deposits of natural gas were formed in a similar way.
Alkanes also play a role, if a minor role, in the biology of the three eukaryotic groups of organisms: fungi, plants and animals. Some specialised yeasts, e.g., "Candida tropicale", "Pichia" sp., "Rhodotorula" sp., can use alkanes as a source of carbon and/or energy. The fungus "Amorphotheca resinae" prefers the longer-chain alkanes in aviation fuel, and can cause serious problems for aircraft in tropical regions.
In plants, the solid long-chain alkanes are found in the plant cuticle and epicuticular wax of many species, but are only rarely major constituents. They protect the plant against water loss, prevent the leaching of important minerals by the rain, and protect against bacteria, fungi, and harmful insects. The carbon chains in plant alkanes are usually odd-numbered, between twenty-seven and thirty-three carbon atoms in length and are made by the plants by decarboxylation of even-numbered fatty acids. The exact composition of the layer of wax is not only species-dependent, but changes also with the season and such environmental factors as lighting conditions, temperature or humidity.
Alkanes are found in animal products, although they are less important than unsaturated hydrocarbons. One example is the shark liver oil, which is approximately 14% pristane (2,6,10,14-tetramethylpentadecane, C19H40). Their occurrence is more important in pheromones, chemical messenger materials, on which above all insects are dependent for communication. With some kinds, as the support beetle "Xylotrechus colonus", primarily pentacosane (C25H52), 3-methylpentaicosane (C26H54) and 9-methylpentaicosane (C26H54), they are transferred by body contact. With others like the tsetse fly "Glossina morsitans morsitans", the pheromone contains the four alkanes 2-methylheptadecane (C18H38), 17,21-dimethylheptatriacontane (C39H80), 15,19-dimethylheptatriacontane (C39H80) and 15,19,23-trimethylheptatriacontane (C40H82), and acts by smell over longer distances, a useful characteristic for pest control. Waggle-dancing honeybees produce and release two alkanes, tricosane and pentacosane.
Ecological relations.
One example, in which both plant and animal alkanes play a role, is the ecological relationship between the sand bee ("Andrena nigroaenea") and the early spider orchid ("Ophrys sphegodes"); the latter is dependent for pollination on the former. Sand bees use pheromones in order to identify a mate; in the case of "A. nigroaenea", the females emit a mixture of tricosane (C23H48), pentacosane (C25H52) and heptacosane (C27H56) in the ratio 3:3:1, and males are attracted by specifically this odour. The orchid takes advantage of this mating arrangement to get the male bee to collect and disseminate its pollen; parts of its flower not only resemble the appearance of sand bees, but also produce large quantities of the three alkanes in the same ratio as female sand bees. As a result numerous males are lured to the blooms and attempt to copulate with their imaginary partner: although this endeavour is not crowned with success for the bee, it allows the orchid to transfer its pollen,
which will be dispersed after the departure of the frustrated male to different blooms.
Petroleum refining.
As stated earlier, the most important source of alkanes is natural gas and crude oil. Alkanes are separated in an oil refinery by fractional distillation and processed into many different products.
Fischer-Tropsch.
The Fischer-Tropsch process is a method to synthesize liquid hydrocarbons, including alkanes, from carbon monoxide and hydrogen. This method is used to produce substitutes for petroleum distillates.
Laboratory preparation.
Alkanes or alkyl groups can also be prepared directly from alkyl halides in the Corey-House-Posner-Whitesides reaction. The Barton-McCombie deoxygenation removes hydroxyl groups from alcohols e.g.
Applications.
The applications of a certain alkane can be determined quite well according to the number of carbon atoms. The first four alkanes are used mainly for heating and cooking purposes, and in some countries for electricity generation. Methane and ethane are the main components of natural gas; they are normally stored as gases under pressure. It is, however, easier to transport them as liquids: This requires both compression and cooling of the gas.
Propane and butane can be liquefied at fairly low pressures, and are well known as liquified petroleum gas (LPG). Propane, for example, is used in the propane gas burner, butane in disposable cigarette lighters. The two alkanes are used as propellants in aerosol sprays.
From pentane to octane the alkanes are reasonably volatile liquids. They are used as fuels in internal combustion engines, as they vaporise easily on entry into the combustion chamber without forming droplets, which would impair the uniformity of the combustion. Branched-chain alkanes are preferred as they are much less prone to premature ignition, which causes knocking, than their straight-chain homologues. This propensity to premature ignition is measured by the octane rating of the fuel, where 2,2,4-trimethylpentane ("isooctane") has an arbitrary value of 100, and heptane has a value of zero. Apart from their use as fuels, the middle alkanes are also good solvents for nonpolar substances.
Alkanes from nonane to, for instance, hexadecane (an alkane with sixteen carbon atoms) are liquids of higher viscosity, less and less suitable for use in gasoline. They form instead the major part of diesel and aviation fuel. Diesel fuels are characterised by their cetane number, cetane being an old name for hexadecane. However, the higher melting points of these alkanes can cause problems at low temperatures and in polar regions, where the fuel becomes too thick to flow correctly.
Alkanes from hexadecane upwards form the most important components of fuel oil and lubricating oil. In latter function, they work at the same time as anti-corrosive agents, as their hydrophobic nature means that water cannot reach the metal surface. Many solid alkanes find use as paraffin wax, for example, in candles. This should not be confused however with true wax, which consists primarily of esters.
Alkanes with a chain length of approximately 35 or more carbon atoms are found in bitumen, used, for example, in road surfacing. However, the higher alkanes have little value and are usually split into lower alkanes by cracking.
Some synthetic polymers such as polyethylene and polypropylene are alkanes with chains containing hundreds of thousands of carbon atoms. These materials are used in innumerable applications, and billions of kilograms of these materials are made and used each year.
Environmental transformations.
When released in the environment, alkanes don't undergo rapid biodegradation, because they haven't functional groups (like hydroxyl or carbonyl) that are needed by most organismsm in order to metabolize the compound.
However, some bacteria can metabolize some alkanes (expecially those linear and short), by oxidizing the terminal carbon atom. The product is an alcohol, that could be next oxidized to an aldehyde, and finally to a carboxylic acid. The resulting fatty acid could be metabolized through the fatty acid degradation pathway.
Hazards.
Methane is explosive when mixed with air (1 – 8% CH4) and is a strong greenhouse gas: Other lower alkanes can also form explosive mixtures with air. The lighter liquid alkanes are highly flammable, although this risk decreases with the length of the carbon chain. Pentane, hexane, heptane, and octane are classed as "dangerous for the environment" and "harmful". The straight-chain isomer of hexane is a neurotoxin. Halogen-rich alkanes, like chloroform, can be carcinogenic as well.
---END.OF.DOCUMENT---
Appeal.
In law, an appeal is a process for requesting a formal change to an official decision.
The specific procedures for appealing, including even whether there is a right of appeal from a particular type of decision, can vary greatly from country to country. Even within a jurisdiction, the nature of an appeal can vary greatly depending on the type of case.
An appellate court is a court that hears cases on appeal from another court. Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds. These grounds typically could include errors of law, fact, or procedure (in the United States, due process).
In different jurisdictions, appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts.
Who can appeal.
A party who files an appeal is called an "appellant" or "petitioner", and a party on the other side is called a "respondent" (in most common-law countries) or an "appellee" (in the United States). A "cross-appeal" is an appeal brought by the respondent. For example, suppose at trial the judge found for the plaintiff and ordered the defendant to pay $50,000. If the defendant files an appeal arguing that he should not have to pay any money, then the plaintiff might file a cross-appeal arguing that the defendant should have to pay $200,000 instead of $50,000.
The appellant is the party who, having lost part or all their claim in a lower court decision, is appealing to a higher court to have their case reconsidered. This is usually done on the basis that the lower court judge erred in the application of law, but it may also be possible to appeal on the basis of court misconduct, or that a finding of fact was entirely unreasonable to make on the evidence.
The appellant in the new case can be either the plaintiff (or "claimant"), defendant, or respondent (appellee) from the lower case, depending on who was the losing party. The winning party from the lower court, however, is now the respondent. In unusual cases the appellant can be the victor in the court below, but still appeal. For example, in "Doyle v Olby (Ironmongers) Ltd" [1969] 2 QB 158, the claimant appealed (successfully) on the basis that, although he won in the court below, the lower court had applied the wrong measure of damages and he had not been fully recompensed.
An appellee is the party to an appeal in which the lower court judgment was in its favor. The appellee is required to respond to the petition, oral arguments, and legal briefs of the appellant. In general, the appellee takes the procedural posture that the lower court's decision should be affirmed.
Ability to appeal.
An appeal "as of right" is one that is guaranteed by statute or some underlying constitutional or legal principle. The appellate court cannot refuse to listen to the appeal. An appeal "by leave" or "permission" requires the appellant to move for leave to appeal; in such a situation either or both of the lower court and the appellate court may have the discretion to grant or refuse the appellant's demand to appeal the lower court's decision. A good example of this is the U.S. Supreme Court in which at least three justices must agree to hear the case if there is a constitutional issue.
In tort, equity, or other civil matters either party to a previous case may file an appeal. In criminal matters, however, the state or prosecution generally has no appeal "as of right". And due to the double jeopardy principle, in the United States the state or prosecution may never appeal a jury or bench verdict of acquittal. But in some jurisdictions, the state or prosecution may appeal "as of right" from a trial court's dismissal of an indictment in whole or in part or from a trial court's granting of a defendant's suppression motion. Likewise, in some jurisdictions, the state or prosecution may appeal an issue of law "by leave" from the trial court and/or the appellate court. The ability of the prosecution to appeal a decision in favor of a defendant varies significantly internationally. All parties must present grounds to appeal, or it will not be heard.
By convention in some law reports, the appellant is named first. This can mean that where it is the defendant who appeals, the name of the case in the law reports reverses (in some cases twice) as the appeals work their way up the court hierarchy. This is not always true, however. In the United States federal courts, the parties' names always stay in the same order as the lower court when an appeal is taken to the circuit courts of appeals, and are re-ordered only if the appeal reaches the United States Supreme Court.
Direct or collateral.
Many jurisdictions recognize two types of appeals, particularly in the criminal context. The first is the traditional "direct" appeal in which the appellant files an appeal with the next higher court of review. The second is the collateral appeal or post-conviction petition, in which the petitioner-appellant files the appeal in a court of first instance—usually the court that tried the case.
The key distinguishing factor between direct and collateral appeals is that the former only reviews evidence that was presented in the trial court, but the latter allows review of evidence dehors the record: depositions, affidavits, and witness statements that did not come in at trial. The standard for post-conviction relief is high, typically requiring the petitioner to demonstrate that the evidence presented was not available in the usual course of trial discovery.
Relief in post-conviction is rare and is most often found in capital or violent felony cases. The typical scenario involves an incarcerated defendant locating DNA evidence demonstrating the defendant's actual innocence.
Types of appeal.
There are a number of appeal actions, their differences being potentially confusing, thus bearing some explanation. Three of the most common are an appeal to which the defendant has as a right, a writ of certiorari and a writ of habeas corpus.
An appeal to which the defendant has a right cannot be abridged by the court which is, by designation of its jurisdiction, obligated to hear the appeal. In such an appeal, the appellant feels that some error has been made in his trial, necessitating an appeal. A matter of importance is the basis on which such an appeal might be filed: generally appeals as a matter of right may only address issues which were originally raised in trial (as evidenced by documentation in the official record). Any issue not raised in the original trial may not be considered on appeal and will be considered estoppel. A convenient test for whether a petition is likely to succeed on the grounds of error is confirming that (1) a mistake was indeed made (2) an objection to that mistake was presented by counsel and (3) that mistake negatively affected the defendant’s trial.
A writ of certiorari, otherwise know as simply as cert, is an order by a higher court directing a lower court to send record of a case for review, and is the next logical step in post-trial procedure. While states may have similar processes, a writ of cert is usually only issued, in the United States, by the Supreme Court, although some states retain this procedure. Unlike the aforementioned appeal, a writ of cert is not a matter of right. A writ of cert will have to be petitioned for, the higher court issuing such writs on limited bases according to constraints such as time. In another sense, a writ of cert is like an appeal in its constraints; it too may only seek relief on grounds raised in the original trial.
A writ of habeas corpus is the last opportunity for the defendant to find relief against his guilty conviction. Habeas corpus may be pursued if a defendant is unsatisfied with the outcome of his appeal and has been refused (or did not pursue) a writ of cert, at which point he may petition one of several courts for a writ of habeas corpus. Again, these are granted at the discretion of the court and require a petition. Like appeals or writs of cert, a writ of habeas corpus may overturn a defendant's guilty conviction by finding some error in the original trial. The major difference is that writs of habeas corpus may, and often, focus on issues that lay outside the original premises of the trial, i.e., issues that could not be raised by appeal or writs of cert. These often fall in two logical categories: (1) that the trial lawyer was ineffectual or incompetent or (2) that some constitutional right has been violated.
Notice of appeal.
A notice of appeal is a form or document that in many cases is required to begin an appeal. The form is completed by the appellant or by the appellant's legal representative. The nature of this form can vary greatly from country to country and from court to court within a country.
The specific rules of the legal system will dictate exactly how the appeal is officially begun. For example, the appellant might have to file the notice of appeal with the appellate court, or with the court from which the appeal is taken, or both.
Some courts have samples of a notice of appeal on the court's own web site.
The deadline for beginning an appeal can often be very short: traditionally, it is measured in days, not years. This can vary from country to country, as well as within a country, depending on the specific rules in force.
How an appeal is processed.
Generally speaking the appellate court examines the record of evidence presented in the trial court and the law that the lower court applied and decides whether that decision was legally sound or not. The appellate court will typically be deferential to the lower court's findings of fact (such as whether a defendant committed a particular act), unless clearly erroneous, and so will focus on the court's application of the law to those facts (such as whether the act found by the court to have occurred fits a legal definition at issue).
If the appellate court finds no defect, it "affirms" the judgment. If the appellate court does find a legal defect in the decision "below" (i.e., in the lower court), it may "modify" the ruling to correct the defect, or it may nullify ("reverse" or "vacate") the whole decision or any part of it. It may, in addition, send the case back ("remand" or "remit") to the lower court for further proceedings to remedy the defect.
In some cases, an appellate court may review a lower court decision "de novo" (or completely), challenging even the lower court's findings of fact. This might be the proper standard of review, for example, if the lower court resolved the case by granting a pre-trial motion to dismiss or motion for summary judgment which is usually based only upon written submissions to the trial court and not on any trial testimony.
Another situation is where appeal is by way of "re-hearing". Certain jurisdictions permit certain appeals to cause the trial to be heard afresh in the appellate court. An example would be an appeal from a magistrates' court to the Crown Court in England and Wales.
Sometimes, the appellate court finds a defect in the procedure the parties used in filing the appeal and dismisses the appeal without considering its merits, which has the same effect as affirming the judgment below. (This would happen, for example, if the appellant waited too long, under the appellate court's rules, to file the appeal.) In England and many other jurisdictions, however, the phrase "appeal dismissed" is equivalent to the U.S. term "affirmed"; and the phrase "appeal allowed" is equivalent to the U.S. term "reversed".
Generally, there is no trial in an appellate court, only consideration of the record of the evidence presented to the trial court and all the pre-trial and trial court proceedings are reviewed—unless the appeal is by way of re-hearing, new evidence will usually only be considered on appeal in "very" rare instances, for example if that material evidence was unavailable to a party for some very significant reason such as prosecutorial misconduct.
In some systems, an appellate court will only consider the written decision of the lower court, together with any written evidence that was before that court and is relevant to the appeal. In other systems, the appellate court will normally consider the record of the lower court. In those cases the record will first be certified by the lower court.
The appellant has the opportunity to present arguments for the granting of the appeal and the appellee (or respondent) can present arguments against it. Arguments of the parties to the appeal are presented through their appellate lawyers, if represented, or "pro se" if the party has not engaged legal representation. Those arguments are presented in written briefs and sometimes in oral argument to the court at a hearing. At such hearings each party is allowed a brief presentation at which the appellate judges ask questions based on their review of the record below and the submitted briefs.
It is important to note that in an adversarial system appellate courts do not have the power to review lower court decisions unless a party appeals it. Therefore if a lower court has ruled in an improper manner or against legal precedent that judgment will stand even if it might have been overturned on appeal.
United States.
The United States legal system generally recognizes two types of appeals: a trial "de novo" or an appeal on the record.
A trial de novo is usually available for review of informal proceedings conducted by some minor judicial tribunals in proceedings that do not provide all the procedural attributes of a formal judicial trial. If unchallenged, these decisions have the power to settle more minor legal disputes once and for all. If a party is dissatisfied with the finding of such a tribunal, one generally has the power to request a trial "de novo" by a court of record. In such a proceeding, all issues and evidence may be developed newly, as though never heard before, and one is not restricted to the evidence heard in the lower proceeding. Sometimes, however, the decision of the lower proceeding is itself admissible as evidence, thus helping to curb frivolous appeals.
In an appeal on the record from a decision in a judicial proceeding, both appellant and respondent are bound to base their arguments wholly on the proceedings and body of evidence as they were presented in the lower tribunal. Each seeks to prove to the higher court that the result they desired was the just result. Precedent and case law figure prominently in the arguments. In order for the appeal to succeed, the appellant must prove that the lower court committed reversible error, that is, an impermissible action by the court acted to cause a result that was unjust, and which would not have resulted had the court acted properly. Some examples of reversible error would be erroneously instructing the jury on the law applicable to the case, permitting seriously improper argument by an attorney, admitting or excluding evidence improperly, acting outside the court's jurisdiction, injecting bias into the proceeding or appearing to do so, juror misconduct, etc. The failure to formally object at the time, to what one views as improper action in the lower court, may result in the affirmance of the lower court's judgment on the grounds that one did not "preserve the issue for appeal" by objecting.
In cases where a judge rather than a jury decided issues of fact, an appellate court will apply an "abuse of discretion" standard of review. Under this standard, the appellate court gives deference to the lower court's view of the evidence, and reverses its decision only if it were a clear abuse of discretion. This is usually defined as a decision outside the bounds of reasonableness. On the other hand, the appellate court normally gives less deference to a lower court's decision on issues of law, and may reverse if it finds that the lower court applied the wrong legal standard.
In some rare cases, an appellant may successfully argue that the law under which the lower decision was rendered was unconstitutional or otherwise invalid, or may convince the higher court to order a new trial on the basis that evidence earlier sought was concealed or only recently discovered. In the case of new evidence, there must be a high probability that its presence or absence would have made a material difference in the trial. Another issue suitable for appeal in criminal cases is effective assistance of counsel. If a defendant has been convicted and can prove that his lawyer did not adequately handle his case "and" that there is a reasonable probability that the result of the trial would have been different had the lawyer given competent representation, he is entitled to a new trial.
In the United States, a lawyer traditionally starts an oral argument to any appellate court with the words "May it please the court."
After an appeal is heard, the "mandate" is a formal notice of a decision by a court of appeal; this notice is transmitted to the trial court and, when filed by the clerk of the trial court, constitutes the final judgment on the case, unless the appeal court has directed further proceedings in the trial court. The mandate is distinguished from the appeal court's opinion, which sets out the legal reasoning for its decision. In some U.S. jurisdictions the mandate is known as the "remittitur".
Appellate review.
Appellate review is the general term for the process by which courts with appellate jurisdiction take jurisdiction of matters decided by lower courts. It is distinguished from judicial review, which refers to the court's overriding constitutional or statutory right to determine if a legislative act or administrative decision is defective for jurisdictional or other reasons (which may vary by jurisdiction).
In most jurisdictions the normal and preferred way of seeking appellate review is by filing an appeal of the final judgment. Generally, an appeal of the judgment will also allow appeal of all other orders or rulings made by the trial court in the course of the case. This is because such orders cannot be appealed "as of right". However, certain critical interlocutory court orders, such as the denial of a request for an interim injunction, or an order holding a person in contempt of court, can be appealed immediately although the case may otherwise not have been fully disposed of.
In American law, there are two distinct forms of appellate review, "direct" and "collateral". For example, a criminal defendant may be convicted in state court, and lose on "direct appeal" to higher state appellate courts, and if unsuccessful, mount a "collateral" action such as filing for a writ of habeas corpus in the federal courts. Generally speaking, "[d]irect appeal statutes afford defendants the opportunity to challenge the merits of a judgment and allege errors of law or fact.... [Collateral review], on the other hand, provide[s] an independent and civil inquiry into the validity of a conviction and sentence, and as such are generally limited to challenges to constitutional, jurisdictional, or other fundamental violations that occurred at trial." "Graham v. Borgen", __ F 3d. __ (7th Cir. 2007) (no. 04-4103) (slip op. at 7) (citation omitted).
In Anglo-American common law courts, appellate review of lower court decisions may also be obtained by filing a petition for review by prerogative writ in certain cases. There is no corresponding right to a writ in any pure or continental civil law legal systems, though some mixed systems such as Quebec recognize these prerogative writs.
---END.OF.DOCUMENT---
Answer.
Generally, an answer is a reply to a question or is a solution, a retaliation, or a response that is relevant to the said question.
In law, an answer was originally a solemn assertion in opposition to some one or something, and thus generally any counter-statement or defense, a reply to a question or objection, or a correct solution of a problem.
In the common law, an answer is the first pleading by a defendant, usually filed and served upon the plaintiff within a certain strict time limit after a civil complaint or criminal information or indictment has been served upon the defendant. It may have been preceded by an "optional" "pre-answer" motion to dismiss or demurrer; if such a motion is unsuccessful, the defendant "must" file an answer to the complaint or risk an adverse default judgment.
The "answer" establishes which allegations (cause of action in civil matters) set forth by the complaining party will be contested by the defendant, and states all the defendant's defenses, thus establishing the nature and parameters of the controversy to be decided by the court.
In a criminal case, there is usually an arraignment or some other kind of appearance before defendant comes to court. The pleading in the criminal case, which is entered on the record in open court, is usually either guilty or not guilty. Generally speaking in private, civil cases there is no plea entered of guilt or innocence. There is only a judgment that grants money damages or some other kind of equitable remedy such as restitution or a permanent injunction. Criminal cases may lead to fines or other punishment, such as imprisonment.
The famous Latin "Responsa Prudentium" ("answers of the learned ones") were the accumulated views of many successive generations of Roman lawyers, a body of legal opinion which gradually became authoritative.
In music an "answer" (also known as countersubject) is the technical name in counterpoint for the repetition or modification by one part or instrument of a theme proposed by another.
---END.OF.DOCUMENT---
Appellate court.
An appellate court is any court of law that is empowered to hear an appeal of a trial court or other lower tribunal. In most jurisdictions, the court system is divided into at least three levels: the trial court, which initially hears cases and reviews evidence and testimony to determine the facts of the case; at least one intermediate appellate court; and a supreme court (or court of last resort) which primarily reviews the decisions of the intermediate courts. A supreme court is therefore itself a kind of appellate court. Appellate courts worldwide can operate by varying rules. For example, the Isle of Man's traditional local appellate court is the Staff of Government Division which has only two Justices, titled "Deemsters," whose decisions are joined to the original trial decision. They almost always have a majority, if either Deemster agrees with the trial Judge.
Institutional titles.
Many US jurisdictions title their appellate court a Court of Appeal or Court of Appeals. Historically, others have titled their appellate court a Court of Errors (or Court of Errors and Appeals), on the premise that it was intended to correct errors made by lower courts. Examples of such courts include the New Jersey Court of Errors and Appeals (which existed from 1844 to 1947), the Connecticut Supreme Court of Errors (which has been renamed the Connecticut Supreme Court), the Kentucky Court of Errors (since renamed the Kentucky Supreme Court), and the Mississippi High Court of Errors and Appeals (since renamed the Supreme Court of Mississippi). In some jurisdictions, courts able to hear appeals are known as an Appellate Division.
Depending on the system, certain courts may serve as both trial courts and appellate courts, hearing appeals of decisions made by courts with more limited jurisdiction. Some jurisdictions have specialized appellate courts, such as the Texas Court of Criminal Appeals, which only hears appeals raised in criminal cases, and the United States Court of Appeals for the Federal Circuit, which has general jurisdiction but derives most of its caseload from patent cases, on the one hand, and appeals from the Court of Federal Claims on the other.
Authority to review.
The authority of appellate courts to review a decisions of lower courts varies widely from one jurisdiction to another. In some places, the appellate court has limited powers of review. For example, in the United States, both state and federal appellate courts are usually restricted to examining whether the court below made the correct legal determinations, rather than hearing direct evidence and determining what the facts of the case were. Furthermore, U.S. appellate courts are usually restricted to hearing appeals based on matters that were originally brought up before the trial court. Hence, such an appellate court will not consider an appellant's argument if it is based on a theory that is raised for the first time in the appeal.
In most U.S. states, and in U.S. federal courts, parties before the court are allowed one appeal as of right. This means that a party who is unsatisfied with the outcome of a trial may bring an appeal to contest that outcome. However, appeals may be costly, and the appellate court must find an error on the part of the court below that justifies upsetting the verdict. Therefore, only a small proportion of trial court decisions result in appeals. Some appellate courts, particularly supreme courts, have the power of discretionary review, meaning that they can decide whether they will hear an appeal brought in a particular case.
---END.OF.DOCUMENT---
America the Beautiful.
"America the Beautiful" is an American patriotic song. The lyrics were written by Katharine Lee Bates and the music composed by church organist and choirmaster Samuel A. Ward. Bates originally wrote the words as a poem, "Pikes Peak", first published in the July 4th edition of the church periodical "The Congregationalist" in 1895. The poem was titled "America" for publication. Ward had originally written the music, "Materna", for the 1600s hymn "O Mother dear, Jerusalem" in 1882. Ward's music combined with the Bates poem was first published in 1910 and titled "America the Beautiful". The song is one of the most beloved and popular of the many American patriotic songs. From time to time it has been proposed as a replacement for "The Star-Spangled Banner" as the National Anthem.
History.
In 1893, at the age of thirty-three Katharine Lee Bates, an English professor at Wellesley College, had taken a train trip to Colorado Springs, Colorado, to teach a short summer school session at Colorado College. Several of the sights on her trip inspired her, and they found their way into her poem, including the World's Columbian Exposition in Chicago, the "White City" with its promise of the future contained within its alabaster buildings; the wheat fields of America's heartland Kansas, through which her train was riding on July 4; and the majestic view of the Great Plains from high atop Zebulon's Pikes Peak.
On the pinnacle of that mountain, the words of the poem started to come to her, and she wrote them down upon returning to her hotel room at the original Antlers Hotel. The poem was initially published two years later in "The Congregationalist," to commemorate the Fourth of July. It quickly caught the public's fancy. Amended versions were published in 1904 and 1913.
Several existing pieces of music were adapted to the poem. A hymn tune composed by Samuel A. Ward was generally considered the best music as early as 1910 and is still the popular tune today. Just as Bates had been inspired to write her poem, Ward too was inspired to compose his tune. The tune came to him while he was on a ferryboat trip from Coney Island back to his home in New York City, after a leisurely summer day in 1882, and he immediately wrote it down. He was so anxious to capture the tune in his head, he asked fellow passenger friend Harry Martin for his shirt cuff to write the tune on, thus perhaps the "off the cuff" analogy. He composed the tune for the old hymn "O Mother Dear, Jerusalem", retitling the work "Materna". Ward's music combined with Bates' poem were first published together in 1910 and titled, "America the Beautiful".
Ward died in 1903, not knowing the national stature his music would attain, as the music was only first applied to the song in 1904. Miss Bates was more fortunate, as the song's popularity was well-established by her death in 1929.
At various times in the more than 100 years that have elapsed since the song as we know it was born, particularly during the John F. Kennedy administration, there have been efforts to give "America the Beautiful" legal status either as a national hymn, or as a national anthem equal to, or in place of, "The Star-Spangled Banner", but so far this has not succeeded. Proponents prefer "America the Beautiful" for various reasons, saying it is easier to sing, more melodic, and more adaptable to new orchestrations while still remaining as easily recognizable as "The Star-Spangled Banner." Some prefer "America the Beautiful" over "The Star-Spangled Banner" due to the latter's war-oriented imagery. (Others prefer "The Star-Spangled Banner" for the same reason.) While that national dichotomy has stymied any effort at changing the tradition of the national anthem, "America the Beautiful" continues to be held in high esteem by a large number of Americans.
Popularity of the song increased greatly following the September 11, 2001 attacks; at some sporting events it was sung in addition to the traditional singing of the national anthem. During the first taping of the "Late Show with David Letterman" following the attacks, CBS newsman Dan Rather cried briefly as he quoted the fourth verse.
Ray Charles is credited with the song's most well known rendition in current times (although Elvis Presley had good success with it in the 1970s). His recording is very commonly played at major sporting events, such as the Super Bowl; Charles gave a live performance of the song prior to Super Bowl XXXV, the last Super Bowl played before the September 11 terrorist attacks. His unique take on it places the third verse first, after which he sings the usual first verse. In the third verse (see below), the author scolds the materialistic and self-serving robber barons of her day, and urges America to live up to its noble ideals and to honor, with both word and deed, the memory of those who died for their country. Symbolically, Marian Anderson (a noted opera singer of her day) sang a rendition of America on the steps of the Lincoln Memorial in 1939 after being refused use of Constitution Hall by the Daughters of the American Revolution because of her skin color.
An all-star version of "America the Beautiful" performed by country music singers Trace Adkins, Billy Dean, Vince Gill, Carolyn Dawn Johnson, Toby Keith, Brenda Lee, Lonestar, Martina McBride, Jamie O'Neal, Kenny Rogers and Keith Urban reached #58 on the "Billboard" Hot Country Singles & Tracks chart in July 2001. The song re-entered the chart following the September 11 terrorist attacks.
When Richard Nixon visited the People's Republic of China in 1972, this song was played by Chinese as the welcome music. Interestingly, the Chinese characters for United States literally mean "Beautiful Country."
The song is often included in songbooks in a wide variety of religious congregations in the United States.
Idioms.
"From sea to shining sea" is an American idiom meaning from the Pacific Ocean to the Atlantic Ocean (or vice versa). Many songs have used this term, including the American patriotic songs "America, The Beautiful" and "God Bless the USA". In addition to these, it is also featured in Schoolhouse Rock's "Elbow Room". A term similar to this is the Canadian motto "A Mari Usque Ad Mare" ("From sea to sea.")
Lyrics.
God shed his grace on thee
And crown thy good with brotherhood
Who more than self their country loved
God shed his grace on thee
And crown thy good with brotherhood
God shed his grace on thee
Till souls wax fair as earth and air
God shed his grace on thee
God shed his grace on thee
Till selfish gain no longer stain
God shed his grace on thee
Till nobler men keep once again
---END.OF.DOCUMENT---
Assistive technology.
Assistive technology (AT) is a generic term that includes assistive, adaptive, and rehabilitative devices for people with disabilities and includes the process used in selecting, locating, and using them.
The Technology-Related Assistance for Individuals with Disabilities Act of 1988 (US Public Law 100-407) states that it is "technology designed to be utilized in an assistive technology device or assistive technology service."
AT promotes greater independence by enabling people to perform tasks that they were formerly unable to accomplish, or had great difficulty accomplishing, by providing enhancements to or changed methods of interacting with the technology needed to accomplish such tasks.
Likewise, disability advocates point out that technology is often created without regard to people with disabilities, creating unnecessary barriers to hundreds of millions of people.
Assistive technology and universal accessibility.
Universal (or broadened) accessibility, or universal design means greater usability, particularly for people with disabilities.
Universally accessible technology yields great rewards to the typical user as well; good accessible design "is" universal design. One example is the "curb cuts" (or dropped curbs) in the sidewalk at street crossings. While these curb cuts enable pedestrians with mobility impairments to cross the street, they also aid parents with carriages and strollers, shoppers with carts, and travellers and workers with pull-type bags.
As an example, the modern telephone is inaccessible to people who are deaf or hard of hearing. Combined with a text telephone (also known as a TDD Telecommunications device for the deaf and in the USA generally called a TTY[TeleTYpewriter]), which converts typed characters into tones that may be sent over the telephone line, a deaf person is able to communicate immediately at a distance. Together with "relay" services, in which an operator reads what the deaf person types and types what a hearing person says, the deaf person is then given access to everyone's telephone, not just those of people who possess text telephones. Many telephones now have volume controls, which are primarily intended for the benefit of people who are hard of hearing, but can be useful for all users at times and places where there is significant background noise. Some have larger keys well-spaced to facilitate accurate dialing.
Also, a person with a mobility impairment can have difficulty using calculators. Speech recognition software recognizes short commands and makes use of calculators easier.
People with learning disabilities like dyslexia or dysgraphia are using text-to-speech (TTS) software for reading and spelling programs for assistance in writing texts.
Computers with their peripheral devices, editing, spellchecking and speech synthesis software are becoming the core-stones of the assistive technologies coming for relief to the people with learning disabilities and to the people with visual impairments. The assisting spelling programs and voice facilities are bringing better and more convenient text reading and writing experience to the general public.
Toys which have been adapted to be used by children with disabilities may have advantages for non-disabled children as well. The Lekotek movement assists parents by lending assistive technology toys and expertise to families.
The following professionals may be certified by RESNA (RESNA.org) to serve the assistive technology needs of individuals: occupational therapists, physical therapists, speech language pathologists/audiologists, orthotists and prosthetists, educators, and a variety of other rehabilitation and health professionals.
Personal Emergency Response Systems.
Personal Emergency Response Systems (PERS), or Telecare (UK term), are a particular sort of assistive technology that use electronic sensors connected to an alarm system to help caregivers manage risk and help vulnerable people stay independent at home longer. An example would be the systems being put in place for senior people such as fall detectors, thermometers (for hypothermia risk), flooding and unlit gas sensors (for people with mild dementia). Notably, these alerts can be customized to the particular person's risks. When the alert is triggered, a message is sent to a carer or contact centre who can respond appropriately.
Technology similar to PERS can also be used to act within a person's home rather than just to respond to a detected crisis. Using one of the examples above, gas sensors for people with dementia can be used to trigger a device that turns off the gas and tells someone what has happened.
Designing for people with dementia is a good example of how the design of the interface of a piece of AT is critical to its usefulness. People with dementia or any other identified user group must be involved in the design process to make sure that the design is accessible and usable. In the example above, a voice message could be used to remind the person with dementia to turn off the gas himself, but whose voice should be used, and what should the message say? Questions like these must be answered through user consultation, involvement and evaluation.
Accessible computer input.
Sitting at a desk with a QWERTY keyboard and a mouse remains the dominant way of interacting with a personal computer. Some Assistive Technology reduces the strain of this way of work through ergonomic accessories with height-adjustable furniture, footrests, wrist rests, and arm supports to ensure correct posture. Keyguards fit over the keyboard to help prevent unintentional keypresses.
More ambitiously, and quite crucially when keyboard or mouse prove unusable, AT can also replace the keyboard and mouse with alternative devices such as the LOMAK keyboard, trackballs, joysticks, graphics tablets, touchpads, touch screens, foot mice, a microphone with speech recognition software, sip-and-puff input, switch access, and vision-based input devices, such as eye trackers which allow the user to control the mouse with their eyes.
Visual impairment.
Choice of appropriate hardware and software will depend on the user's level of functional vision.
Augmentative and Alternative Communication (AAC).
Augmentative and alternative communication is a well defined specialty within AT. It involves ways of communication that either enhance or replace verbal language. When combined with Applied Behavior Analysis (ABA) teaching methods, AAC has improved communication skills in children with Autism.
---END.OF.DOCUMENT---
Abacus.
The abacus, also called a counting frame, is a calculating tool used primarily in parts of Asia for performing arithmetic processes. Today, abacuses are often constructed as a bamboo frame with beads sliding on wires, but originally they were beans or stones moved in grooves in sand or on tablets of wood, stone, or metal. The abacus was in use centuries before the adoption of the written modern numeral system and is still widely used by merchants, traders and clerks in Asia, Africa, and elsewhere. The user of an abacus is called an abacist.
Etymology.
The use of the word "abacus" dates before 1387 AD, when a Middle English work borrowed the word from Latin to describe a sandboard abacus. The Latin word came from "abakos", the Greek genitive form of "abax" ("calculating-table"), from Hebrew "ābāq" (אבק), "dust". The preferred plural of "abacus" is a subject of disagreement, with both "abacuses" and "abaci" in use.
Mesopotamian abacus.
The period 2700–2300 BC saw the first appearance of the Sumerian abacus, a table of successive columns which delimited the successive orders of magnitude of their sexagesimal number system.
Some scholars point to a character from the Babylonian cuneiform which may have been derived from a representation of the abacus. It is the belief of Carruccio (and other Old Babylonian scholars) that Babylonians "may have used the abacus for the operations of addition and subtraction; however, this primitive device proved difficult to use for more complex calculations".
Egyptian abacus.
The use of the abacus in Ancient Egypt is mentioned by the Greek historian Herodotus, who writes that the manner of this disk's usage by the Egyptians was opposite in direction when compared with the Greek method. Archaeologists have found ancient disks of various sizes that are thought to have been used as counters. However, wall depictions of this instrument have not been discovered, casting some doubt over the extent to which this instrument was used.
Iranian Persian abacus.
During the Achaemenid Persian Empire, around 600 BC, Iranians first began to use the abacus. Under Parthian and Sassanian Iranian empires, scholars concentrated on exchanging knowledge and inventions by the countries around them – India, China, and the Roman Empire, when it is thought to be expanded over the other countries.
Greek abacus.
The earliest archaeological evidence for the use of the Greek abacus dates to the 5th century BC. The Greek abacus was a table of wood or marble, pre-set with small counters in wood or metal for mathematical calculations. This Greek abacus saw use in Achaemenid Persia, the Etruscan civilization, Ancient Rome and, until the French Revolution, the Western Christian world.
A tablet found on the Greek island Salamis in 1846 AD dates back to 300 BC, making it the oldest counting board discovered so far. It is a slab of white marble long, wide, and thick, on which are 5 groups of markings. In the center of the tablet is a set of 5 parallel lines equally divided by a vertical line, capped with a semicircle at the intersection of the bottom-most horizontal line and the single vertical line. Below these lines is a wide space with a horizontal crack dividing it. Below this crack is another group of eleven parallel lines, again divided into two sections by a line perpendicular to them, but with the semicircle at the top of the intersection; the third, sixth and ninth of these lines are marked with a cross where they intersect with the vertical line.
Roman abacus.
The normal method of calculation in ancient Rome, as in Greece, was by moving counters on a smooth table. Originally pebbles, calculi, were used. Later, and in medieval Europe, jetons were manufactured. Marked lines indicated units, fives, tens etc. as in the Roman numeral system. This system of 'counter casting' continued into the late Roman empire and in medieval Europe, and persisted in limited use into the nineteenth century.
Writing in the 1st century BC, Horace refers to the wax abacus, a board covered with a thin layer of black wax on which columns and figures were inscribed using a stylus.
One example of archaeological evidence of the Roman abacus, shown here in reconstruction, dates to the 1st century AD. It has eight long grooves containing up to five beads in each and eight shorter grooves having either one or no beads in each. The groove marked I indicates units, X tens, and so on up to millions. The beads in the shorter grooves denote fives –five units, five tens etc., essentially in a bi-quinary coded decimal system, obviously related to the Roman numerals. The short grooves on the right may have been used for marking Roman ounces.
Chinese abacus.
The earliest known written documentation of the Chinese abacus dates to the 2nd century BC.
The Chinese abacus, known as the "suànpán"(算盤, lit. "Counting tray"), is typically tall and comes in various widths depending on the operator. It usually has more than seven rods. There are two beads on each rod in the upper deck and five beads each in the bottom for both decimal and hexadecimal computation. The beads are usually rounded and made of a hardwood. The beads are counted by moving them up or down towards the beam. If you move them toward the beam, you count their value. If you move away, you don't count their value. The suanpan can be reset to the starting position instantly by a quick jerk along the horizontal axis to spin all the beads away from the horizontal beam at the center.
Suanpans can be used for functions other than counting. Unlike the simple counting board used in elementary schools, very efficient suanpan techniques have been developed to do multiplication, division, addition, subtraction, square root and cube root operations at high speed. There are currently schools teaching students how to use it.
In the famous long scroll "Along the River During the Qingming Festival" painted by Zhang Zeduan (1085–1145 AD) during the Song Dynasty (960–1297 AD), a suanpan is clearly seen lying beside an account book and doctor's prescriptions on the counter of an apothecary's (Feibao).
The similarity of the Roman abacus to the Chinese one suggests that one could have inspired the other, as there is some evidence of a trade relationship between the Roman Empire and China. However, no direct connection can be demonstrated, and the similarity of the abaci may be coincidental, both ultimately arising from counting with five fingers per hand. Where the Roman model (like most modern Japanese) has 4 plus 1 bead per decimal place, the standard suanpan has 5 plus 2, allowing use with a hexadecimal numeral system. Instead of running on wires as in the Chinese and Japanese models, the beads of Roman model run in grooves, presumably making arithmetic calculations much slower.
Another possible source of the suanpan is Chinese counting rods, which operated with a decimal system but lacked the concept of zero as a place holder. The zero was probably introduced to the Chinese in the Tang Dynasty (618-907 AD) when travel in the Indian Ocean and the Middle East would have provided direct contact with India, allowing them to acquire the concept of zero and the decimal point from Indian merchants and mathematicians.
Indian abacus.
First century sources, such as the "Abhidharmakosa" describe the knowledge and use of abacus in India. Around the 5th century, Indian clerks were already finding new ways of recording the contents of the Abacus. Hindu texts used the term "shunya" (zero) to indicate the empty column on the abacus..
Japanese abacus.
In Japanese, the abacus is called "soroban" (, lit. "Counting tray"), imported from China around 1600. The 1/4 abacus appeared circa 1930, and it is preferred and still manufactured in Japan today even with the proliferation, practicality, and affordability of pocket electronic calculators. The use of the soroban is still taught in Japanese primary schools as a part of mathematics.
Korean abacus.
The Chinese abacus migrated from China to Korea around 1400 AD. Koreans call it "jupan" (주판), "supan" (수판) or "jusan" (주산).
Native American abaci.
Some sources mention the use of an abacus called a "nepohualtzintzin" in ancient Mayan culture. This Mesoamerican abacus used a 5-digit base-20 system.
The word Nepohualtzintzin comes from the Nahuatl and it is formed by the roots; Ne - personal -; pohual or pohualli - the account -; and tzintzin - small similar elements. And its complete meaning is taken as: counting with small similar elements by somebody. Its use was taught in the "Kalmekak" to the "temalpouhkeh", who were students dedicated to take the accounts of skies, from childhood. Unfortunately the Nepohualtzintzin and its teaching were among the victims of the conquering destruction, when a diabolic origin was attributed to them after observing the tremendous properties of representation, precision and speed of calculations..
This arithmetic tool is based on the vigesimal system (base 20). For the aztec the count by 20s was completely natural, since the use of "huaraches" (native sandals) allowed them to also use the toes for their calculations. In this way, the amount of 20 meant to them a complete human being. The Nepohualtzintzin is divided in two main parts separated by a bar or intermediate cord. In the left part there are four beads, which in the first row have unitary values (1, 2, 3, and 4), and in the right side there are three beads with values of 5, 10, and 15 respectively. In order to know the value of the respective beads of the upper rows, it is enough to multiply by 20 (by each row), the value of the corresponding account in the first row.
Altogether, there are 13 rows with 7 beads in each one, which makes up 91 beads in each Nepohualtzintzin. This is a basic number to understand the close relation conceived between the exact accounts and the natural phenomena. This is so that one Nepohualtzintzin (91) represents the number of days that a season of the year lasts, two Nepohualtzitzin (182) is the number of days of the corn's cycle, from its sowing to its harvest, three Nepohualtzintzin (273) is the number of days of a baby's gestation, and four Nepohualtzintzin (364) complete a cycle and approximate a year (1 1/4 days short). It is worth to mention that in the Nepohualtzintzin, amounts in the rank from 10 to the 18 can be calculated, with floating point, which allows calculating stellar as well as infinitesimal amounts with absolute precision.
The rediscovering of the Nepohualtzintzin is due to the teacher David Esparza Hidalgo, who in his wandering by all Mexico has found diverse engravings and paintings of this instrument and has reconstructed several of them made in gold, jade, incrustations of shell, etc. There have also been found very old Nepohualtzintzin attributed to the Olmeca culture, and even some bracelets of Mayan origin, as well as a diversity of forms and materials in other cultures.
The quipu of the Incas was a system of knotted cords used to record numerical data, like advanced tally sticks – but not used to perform calculations. Calculations were carried out using a yupana (quechua for "counting tool"; see figure) which was still in use after the conquest of Peru. The working principle of a yupana is unknown, but in 2001 an explanation of the mathematical basis of these instruments was proposed. By comparing the form of several yupanas, researchers found that calculations were based using the Fibonacci sequence 1, 1, 2, 3, 5 and powers of 10, 20 and 40 as place values for the different fields in the instrument. Using the Fibonacci sequence would keep the number of grains within any one field at minimum.
Russian abacus.
The Russian abacus, the "schety" (счёты), usually has a single slanted deck, with ten beads on each wire (except one wire which has four beads, for quarter-ruble fractions. This wire is usually near the user). (Older models have another 4-bead wire for quarter-kopeks, which were minted until 1916.) The Russian abacus is often used vertically, with wires from left to right in the manner of a book. The wires are usually bowed to bulge upward in the center, to keep the beads pinned to either of the two sides. It is cleared when all the beads are moved to the right. During manipulation, beads are moved to the left. For easy viewing, the middle 2 beads on each wire (the 5th and 6th bead) usually are of a different colour from the other eight beads. Likewise, the left bead of the thousands wire (and the million wire, if present) may have a different color.
As a simple, cheap and reliable device, the Russian abacus was in use in all shops and markets throughout the former Soviet Union, and the usage of it was taught in most schools until the 1990s. Even the 1874 invention of mechanical calculator, Odhner arithmometer, had not replaced them in Russia and likewise the mass production of Felix arithmometers since 1924 did not significantly reduce their use in the Soviet Union. Russian abacus began to lose popularity only after the mass production of microcalculators had started in the Soviet Union in 1974. On Today it is regarded as an archaism and replaced by microcalculator.
The Russian abacus was brought to France around 1820 by the mathematician Jean-Victor Poncelet, who served in Napoleon's army and had been a prisoner of war in Russia. The abacus had fallen out of use in western Europe in the 16th century with the rise of decimal notation and algorismic methods. To Poncelet's French contemporaries, it was something new. Poncelet used it, not for any applied purpose, but as a teaching and demonstration aid.
School abacus.
Around the world, abaci have been used in pre-schools and elementary schools as an aid in teaching the numeral system and arithmetic.
In Western countries, a bead frame similar to the Russian abacus but with straight wires and a vertical frame has been common (see image). It is still often seen as a plastic or wooden toy.
The type of abacus shown here is often used to represent numbers without the use of place value. Each bead and each wire has the same value and used in this way it can represent numbers up to 100.
Uses by the blind.
An adapted abacus, invented by Tim Cranmer, called a Cranmer abacus is still commonly used by individuals who are blind. A piece of soft fabric or rubber is placed behind the beads so that they do not move inadvertently. This keeps the beads in place while the users feel or manipulate them. They use an abacus to perform the mathematical functions multiplication, division, addition, subtraction, square root and cubic root.
Although blind students have benefited from talking calculators, the abacus is still very often taught to these students in early grades, both in public schools and state schools for the blind. The abacus teaches mathematical skills that can never be replaced with talking calculators and is an important learning tool for blind students. Blind students also complete mathematical assignments using a braille-writer and Nemeth code (a type of braille code for mathematics) but large multiplication and long division problems can be long and difficult. The abacus gives blind and visually impaired students a tool to compute mathematical problems that equals the speed and mathematical knowledge required by their sighted peers using pencil and paper. Many blind people find this number machine a very useful tool throughout life.
Binary Abacus.
An abacus that explains how computers manipulate numbers.
The abacus shows how numbers, letters, and signs can be stored in a binary system on a computer, or via ASCII.
The device consists of a series of beads on parallel wires arranged in three separate rows. The beads represent a switch on the computer in either an 'on' or 'off' position.
In 1985, Dr. Robert C. Good, Jr. of the Widener University School of Engineering published on the binary abacus.
---END.OF.DOCUMENT---
Asphalt.
Asphalt () is a sticky, black and highly viscous liquid or semi-solid that is present in most crude petroleums and in some natural deposits sometimes termed asphaltum. It is most commonly modelled as a colloid, with "asphaltenes" as the dispersed phase and ' as the continuous phase (though there is some disagreement amongst chemists regarding its structure). One writer states that although a "considerable amount of work has been done on the composition of asphalt, it is exceedingly difficult to separate individual hydrocarbon in pure form", and "it is almost impossible to separate and identify all the different molecules of asphalt, because the number of molecules with different chemical structure is extremely large".
In U.S. and Polish terminology, asphalt (or asphalt cement) is the carefully refined residue from the distillation process of selected crude oils. Outside these countries, the product is often called bitumen.
The primary use of asphalt is in road construction, where it is used as the glue or binder for the aggregate particles. The road surfacing material is usually called 'asphaltic concrete', AC in North America, or 'asphalt' elsewhere. Within North America the apparent interchangeability of the words asphalt and 'bitumen' causes confusion outside the road construction industry despite quite clear definitions within industry circles.
Etymology.
The word asphalt is derived from the late Middle English: from French asphalte, based on Late Latin asphalton, asphaltum, from the Greek ásphalton, ásphaltos ("άσφαλτος"), a word of uncertain origin meaning "asphalt/bitumen/pitch" which some derive from α- "without" and σφάλλω "to make fall". Note that in French, the term asphalte is used for naturally-occurring bitumen-soaked limestone deposits, and for specialised manufactured products with fewer voids or greater bitumen content than the "asphaltic concrete" used to pave roads.
Another description has it that the term derives from the Accadian term "asphaltu" or "sphallo," meaning "to split." It was later adopted from the Homeric Greeks as a verb
meaning "to make firm or stable," "to secure". It is a significant fact that the first use of asphalt by the ancients was in the nature of a cement for securing or joining together various objects, and it thus seems likely that the name itself was expressive of this application. From the Greek, the word passed into late Latin, and thence into French ("asphalte") and English ("asphalt"). The expression "bitumen" originated in the Sanskrit, where we find the words "jatu," meaning "pitch," and "jatu-krit," meaning "pitch creating," "pitch producing" (referring to coniferous or resinous trees). The Latin equivalent is claimed by some to be originally 'gwitu-men' (pertaining to pitch), and by others, "pixtumens" (exuding or bubbling pitch), which was subsequently shortened to "bitumen," thence passing via French into English. From the same root is derived the Anglo Saxon word "cwidu" (Mastix), the German word "Kitt" (cement or mastic) and the old Norse word "kvada".
Background.
Asphalt or bitumen can sometimes be confused with tar, which is a similar black thermo-plastic material produced by the destructive distillation of coal. During the early- and mid-twentieth century when town gas was produced, tar was a readily available product and extensively used as the binder for road aggregates. The addition of tar to macadam roads led to the word tarmac, which is now used in common parlance to refer to road making materials. However, since the 1970s, when natural gas succeeded town gas, asphalt (bitumen) has completely overtaken the use of tar in these applications.
Asphalt can be separated from the other components in crude oil (such as naphtha, gasoline and diesel) by the process of fractional distillation, usually under vacuum conditions. A better separation can be achieved by further processing of the heavier fractions of the crude oil in a de-asphalting unit, which uses either propane or butane in a supercritical phase to dissolve the lighter molecules which are then separated. Further processing is possible by "blowing" the product: namely reacting it with oxygen. This makes the product harder and more viscous.
Natural deposits of asphalt include lake asphalts (primarily from the Pitch Lake in Trinidad and Tobago and Bermudez Lake in Venezuela), Gilsonite, the Dead Sea, and Tar Sands. Asphalt was mined at Ritchie Mines in Macfarlan in Ritchie County, West Virginia in the United States from 1852 to 1873.
Asphalt is typically stored and transported at temperatures around 150 degrees Celsius (300 °F). Sometimes diesel oil or kerosene are mixed in before shipping to retain liquidity; upon delivery, these lighter materials are separated out of the mixture. This mixture is often called bitumen feedstock, or BFS. Some dump trucks route the hot engine exhaust through pipes in the dump body to keep the material warm. The backs of tippers carrying asphalt, as well as some handling equipment, are also commonly sprayed with a releasing agent before filling to aid release. Diesel oil is sometimes used as a release agent, although it can mix with and thereby reduce the quality of the asphalt.
Ancient times.
In the ancient Middle East, natural asphalt deposits were used for mortar between bricks and stones, to cement parts of carvings such as eyes into place, for ship caulking, and for waterproofing. The Persian word for asphalt is "mumiya", which is related to the English word mummy. Asphalt was also used by ancient Egyptians to embalm mummies.
In the ancient Far East, natural asphalt was slowly boiled to get rid of the higher fractions, leaving a material of higher molecular weight which is thermoplastic and when layered on objects, became quite hard upon cooling. This was used to cover objects that needed waterproofing, such as scabbards and other items. Statuettes of household deities were also cast with this type of material in Japan, and probably also in China.
In North America, archaeological recovery has indicated that asphaltum was sometimes used to apply stone projectile points to a wooden shaft.
Early use in Europe.
The use of asphalt in the United Kingdom and United States was preceded by its use in Europe.
An 1838 edition of "Mechanics Magazine" cites an early use of asphalt in France. A pamphlet dated 1621, by "a certain Monsieur d'Eyrinys, states that he had discovered the existence (of asphaltum) in large quantities in the vicinity of Neufchatel", and that he proposed to use it in a variety of ways - "principally in the construction of air-proof granaries, and in protecting, by means of the arches, the water-courses in the city of Paris from the intrusin of dirt and filth", which at that time made the water unusable. "He expatiates also on the excellence of this material for forming level and durable terraces" in palaces, "the notion of forming such terraces in the streets not one likely to cross the brain of a Parisian of that generation". But it was generally neglected in France until the revolution of 1830. Then, in the 1830s, there was a surge of interest, and asphalt became widely used "for pavements, flat roofs, and the lining of cisterns, and in England, some use of it had been made of it for similar purposes". Its rise in Europe was "a sudden phenomenon", after natural deposits were found "in France at Osbann (BasRhin), the Parc (l'Ain) and the Puy-de-la-Poix (Puy-de-Dome)", although it could also be made artificially.
Early use in the United Kingdom.
William Salmon's "Polygraphice" (1673) provides a recipe for varnish used in etching, consisting of three ounces of virgin wax, two ounces of mastic, and one ounce of asphaltum.
In Britain, the first patent was 'Cassell's patent asphalte or bitumen' in 1834. Then on 25 November 1837, Richard Tappin Claridge patented the use of Seyssel asphalt (patent #7849), for use in asphalte pavement, having seen it employed in France and Belgium when visiting with Frederick Walter Simms, who worked with him on the introduction of asphalt to Britain. Dr T. Lamb Phipson claims that his father, Samuel Ryland Phipson, a friend of Claridge, was also "instrumental in introducing the asphalte pavement (in 1836)".
In 1838, Claridge obtained patents in Scotland on 27 March, and Ireland on 23 April, and in 1851 he sought to extend the duration of all three patents. He formed "Claridge's Patent Asphalte Company" for the purpose of introducing to Britain "Asphalte in its natural state from the mine at Pyrimont Seysell in France", and "laid one of the first asphalt pavements in Whitehall". Trials were made of the pavement in 1838 on the footway in Whitehall, the stable at Knightsbridge Barracks, "and subsequently on the space at the bottom of the steps leading from Waterloo Place to St. James Park". "The formation in 1838 of Claridge's Patent Asphalte Company (with a distinguished list of aristocratic patrons, and Marc and Isambard Brunel as, respectively, a trustee and consulting engineer), gave an enormous impetus to the development of a British asphalt industry". "By the end of 1838, at least two other companies, Robinson's and the Bastenne company, were in production", with asphalt being laid as paving at Brighton, Herne Bay, Canterbury, Kensington, the Strand, and a large floor area in Bunhill-row, while meantime Claridge's Whitehall paving "continue(d) in good order". Indeed in 1838, there was a flurry of entrepreneurial activity over asphalt. On the London stockmarket, there were various claims as to the priority of asphalt quality from France, Germany and England. And numerous patents were granted in France, with similar numbers of patent applications being denied in England due to their similarity to each other. In England, "Claridge's was the type most used in the 1840s and 50s" Claridge's own company ceased operating in 1917.
Early use in the United States.
The first use of asphaltum in the New World was by indigenous Indian tribes. On the west coast, as early as the 1200s, the Tongva and Chumash Nations collected the naturally occurring asphaltum that seeped to the surface above underlying petroleum deposits. Both tribes used the substance as an adhesive. It is found on many different artifacts of tools and ceremonial items. For example, it was used on rattles to adhere gourds or turtle shells to rattle handles. It was also used in decorations. Small round shell beads were often set in asphatum to provide decorations. It was used as a sealant on baskets to make them water tight for carrying water. Asphaltum was used also to seal the planks on ocean-going canoes.
Roads in the US have been paved with asphalt since at least 1870, when a street in front of Newark, NJ's City Hall was paved. In 1876, asphalt was used to pave Pennsylvania Avenue in Washington, DC, in time for the celebration of the national centennial. Asphalt was also used for flooring, paving and waterproofing of baths and swimming pools during the early 1900s, following similar trends in Europe.
Rolled asphalt concrete.
The largest use of asphalt is for making asphalt concrete for road surfaces and accounts for approximately 85% of the asphalt consumed in the United States. Asphalt pavement material is commonly composed of 5 percent asphalt cement and 95 percent aggregates (stone, sand, and gravel). Due to its highly viscous nature, asphalt cement must be heated so that it can be mixed with the aggregates at the asphalt mixing plant. There are about 4,000 asphalt mixing plants in the U.S.
Asphalt road surface is the most widely recycled material in the US, both by gross tonnage and by percentage. According to a report issued by the Federal Highway Administration and the United States Environmental Protection Agency, 80% of the asphalt from road surfaces' that is removed each year during widening and resurfacing projects is reused as part of new roads, roadbeds, shoulders and embankments.
Roofing shingles account for most of the remaining asphalt consumption. Other uses include cattle sprays, fence post treatments, and waterproofing for fabrics.
Asphalt is widely used in airports around the world. Due to the sturdiness, it is widely used for runways dedicated to aircraft landing and taking off.
Mastic asphalt.
Mastic asphalt is a type of asphalt which differs from dense graded asphalt (asphalt concrete) in that it has a higher bitumen (binder) content, usually around 7–10% of the whole aggregate mix, as opposed to rolled asphalt, which has only around 5% added bitumen. This thermoplastic substance is widely used in the building industry for waterproofing flat roofs and tanking underground. Mastic asphalt is heated to a temperature of and is spread in layers to form a impervious barrier about thick. There is a proper apprenticeship and trainees go to college to learn this trade.
Asphalt emulsion.
A number of technologies allow asphalt to be mixed at much lower temperatures. These involve mixing the asphalt with petroleum solvents to form "cutbacks" with reduced melting point or mixtures with water to turn the asphalt into an emulsion. Asphalt emulsions contain up to 70% asphalt and typically less than 1.5% chemical additives. There are two main types of emulsions with different affinity for aggregates, cationic and anionic. Asphalt emulsions are used in a wide variety of applications. Chipseal involves spraying the road surface with asphalt emulsion followed by a layer of crushed rock or gravel. Slurry Seal involves the creation of a mixture of asphalt emulsion and fine crushed aggregate that is spread on the surface of a road. Cold mixed asphalt can also be made from asphalt emulsion to create pavements similar to hot-mixed asphalt, several inches in depth and asphalt emulsions are also blended into recycled hot-mix asphalt to create low cost pavements.
Alternatives and bioasphalt.
Certain activist groups have become increasingly concerned about the global peak oil and climate change problem in recent years due to by-products that are released into the atmosphere. Most of the emissions are derived primarily from burning fossil fuels. This has led to the introduction of petroleum bitumen alternatives that are more environmentally friendly and non-toxic.
---END.OF.DOCUMENT---
Apollo 8.
Apollo 8 was the first human spaceflight mission to escape from the gravitational field of planet Earth; the first to be captured by and escape from the gravitational field of another celestial body; and the first crewed voyage to return to planet Earth from another celestial body - Earth's Moon. The three-man crew of Mission Commander Frank Borman, Command Module Pilot James Lovell, and Lunar Module Pilot William Anders became the first humans to see the far side of the Moon with their own eyes, as well as the first humans to see planet Earth from beyond low Earth orbit. The mission was accomplished with the first manned launch of a Saturn V rocket. Apollo 8 was the second manned mission of the Apollo Program.
Originally planned as a low Earth orbit Lunar Module/Command Module test, the mission profile was changed to the more ambitious lunar orbital flight in August 1968 when the Lunar Module scheduled for the flight became delayed. The new mission's profile, procedures and personnel requirements left an uncharacteristically short time frame for training and preparation, thus placing more demands than usual on the time, talent, and discipline of the crew.
After launching on December 21, 1968, the crew took three days to travel to the Moon. They orbited ten times over the course of 20 hours, during which the crew made a Christmas Eve television broadcast in which they read the first 10 verses from the Book of Genesis. At the time, the broadcast was the most watched TV program ever. Apollo 8's successful mission paved the way for Apollo 11 to fulfill U.S. President John F. Kennedy's goal of landing a man on the Moon before the end of the decade.
Backup crew.
Lovell was originally the CMP on the back-up crew, with Michael Collins as the prime crew's CMP. However, Collins was replaced in July 1968, after suffering a cervical disc herniation that required surgery to repair.
Aldrin was originally the backup LMP. When Lovell was rotated to the prime crew, no one with experience on CSM 103 (the specific spacecraft used for the mission) was available, so Aldrin was moved to CMP and Fred Haise brought in as backup LMP. Armstrong went on to command Apollo 11, where Aldrin was returned to the Lunar Module Pilot position. Michael Collins was assigned as Command Module Pilot, although Aldrin was seated in the CMP position for Apollo 11's launch due to his training advantage via Apollo 8. Fred Haise later flew on Apollo 13.
Mission control.
The Earth-based mission control teams for Apollo 8 consisted of astronauts assigned to the support crew, as well as non-astronaut flight directors and their staffs. The support crew members were not trained to fly the mission, but were able to stand in for astronauts in meetings and be involved in the minutiae of mission planning, while the prime and backup crews trained. They also served as capcoms during the mission. For Apollo 8, these crew members included astronauts John S. Bull, Vance D. Brand, Gerald P. Carr, and Ken Mattingly. The mission control teams on Earth rotated in three shifts, each led by a flight director. The directors for Apollo 8 included Cliff Charlesworth (Green team), Glynn Lunney (Black team), and Milton Windler (Maroon team).
Mission insignia.
The triangular shape of the insignia symbolizes the shape of the Apollo command module. It shows a red figure 8 looping around the earth and moon representing the mission number as well as the circumlunar nature of the mission. On the red number 8 are the names of the three astronauts.
The initial design of the insignia was developed by Jim Lovell. Lovell reportedly sketched the initial design while riding in the backseat of a T-38 flight from California to Houston, shortly after learning of the re-designation of the flight to become a lunar orbital mission.
Planning.
Apollo 4 and Apollo 6 had been "A" missions, each launching an unmanned Block I production model of the Apollo Command and Service Modules into Earth Orbit., scheduled for October 1968, would be a manned Earth Orbit flight of the CSM, completing the objectives for Mission "C".
Further missions relied on the readiness of the Lunar Module (LM). Production of the LM was behind schedule, with the first model arriving at Cape Canaveral in June 1968. Even then, significant defects were discovered, leading Grumman, the lead contractor for the LM, to predict that the first mission-ready LM would not be ready until at least February 1969. This would mean delaying the proposed "D" mission and endangering the program's goal of a lunar landing before the end of 1969. Even more pressing was a CIA report that the Soviets were expected to attempt to send cosmonauts on a Zond circumlunar mission before the end of the year. If the Soviets were successful in being first to get humans around the Moon, then that would greatly detract from having Americans being first to land on the Moon.
George Low, the Manager of the Apollo Spacecraft Program Office, proposed a solution in August. Since the Service Module (CSM) would be ready three months before the Lunar Module, a CSM-only mission could be flown in December 1968. Instead of just repeating the "C" mission flight of Apollo 7, this CSM could be sent all the way to the Moon, with the possibility of entering a lunar orbit. The new mission would also allow NASA to test lunar landing procedures that would otherwise have to wait until Apollo 10, the scheduled "F" mission.
Almost every senior manager at NASA agreed with this new mission, citing both confidence in the hardware and personnel, and the potential for a significant morale boost provided by a circumlunar flight. The only person who needed some convincing was James E. Webb, the NASA administrator. With the rest of his agency in support of the new mission, Webb eventually approved the mission change. The mission was officially changed from a "D" mission to a "C-Prime" Lunar Orbit mission, but was still referred to in press releases as an Earth Orbit mission at Webb's direction. No public announcement was made about the change in mission until November 12, three weeks after Apollo 7's successful Earth Orbit mission and less than 40 days before launch.
With the change in mission for Apollo 8, Director of Flight Crew Operations Deke Slayton decided to swap the crews of the D and E missions. James McDivitt, the original commander of the D mission, has said he was never offered the circumlunar flight, but would probably have turned it down, as he wanted to fly the lunar module. Borman, on the other hand, jumped at the chance: his original mission would just have been a repeat of the previous flight, except in a higher orbit. This swap also meant a swap of spacecraft, requiring Borman's crew to use CSM-103, while McDivitt's crew would use CSM-104.
On September 9, the crew entered the simulators to begin their preparation for the flight. By the time the mission flew, the crew had spent seven hours training for every actual hour of flight. Although all crew members were trained in all aspects of the mission, it was necessary to specialize. Borman, as commander, was given training on controlling the spacecraft during the re-entry. Lovell was trained on navigating the spacecraft in case communication was lost with the Earth. Anders was placed in charge of checking that the spacecraft was in working order.
The crew, now living in the crew quarters at Kennedy Space Center, received a visit from Charles Lindbergh and his wife, Anne Morrow Lindbergh, the night before the launch. They talked about how before his 1927 flight, Lindbergh had used a piece of string to measure the distance from New York City to Paris on a globe and from that calculated the fuel needed for the flight. The total was a tenth of the amount that the Saturn V would burn every second.
The next day, the Lindberghs watched the launch of Apollo 8 from a nearby dune. Anne Morrow Lindbergh would later write a book about the Apollo program, entitled "Earth Shine", which mentions both the launch and the mission.
Saturn V.
The Saturn V rocket used by Apollo 8 was designated SA-503, or the "03rd" model of the Saturn V ("5") Rocket to be used in the Saturn-Apollo ("SA") program. When it was erected in the Vertical Assembly Building on December 20, 1967, it was thought that the rocket would be used for an unmanned Earth-orbit test flight carrying a boilerplate Command/Service Module. Apollo 6 had suffered several major problems during its April 1968 flight, including severe pogo oscillation during its first stage, two second stage engine failures, and a third stage that failed to reignite in orbit. Without assurances that these problems had been rectified, NASA administrators could not justify risking a manned mission until additional unmanned test flights proved that the Saturn V was ready.
Teams from the Marshall Space Flight Center (MSFC) went to work on the problems. Of primary concern was the pogo oscillation, which would not only hamper engine performance, but could exert significant g-forces on a crew. A task force of contractors, NASA agency representatives, and MSFC researchers concluded that the engines vibrated at a frequency similar to the frequency at which the spacecraft itself vibrated, causing a resonance effect that induced oscillations in the rocket. A system using helium gas to absorb some of these vibrations was installed.
Of equal importance was the failure of three engines during flight. Researchers quickly determined that a leaking hydrogen fuel line ruptured when exposed to vacuum, causing a loss of fuel pressure in engine two. When an automatic shutoff attempted to close the liquid hydrogen valve and shut down engine two, it accidentally shut down engine three's liquid oxygen due to a miswired connection. As a result, engine three failed within one second of engine two's shutdown. Further investigation revealed the same problem for the third-stage engine — a faulty igniter line. The team modified the igniter lines and fuel conduits, hoping to avoid similar problems on future launches.
The teams tested their solutions in August 1968 at the Marshall Space Flight Center. A Saturn stage IC was equipped with shock absorbing devices to demonstrate the team's solution to the problem of pogo oscillation, while a Saturn Stage II was retrofitted with modified fuel lines to demonstrate their resistance to leaks and ruptures in vacuum conditions. Once NASA administrators were convinced that the problems were solved, they gave their approval for a manned mission using SA-503.
The Apollo 8 spacecraft was placed on top of the rocket on September 21 and the rocket made the slow 3-mile (5 km) journey to the launch pad on October 9. Testing continued all through December until the day before launch, including various levels of readiness testing from 5 December through 11 December. Final testing of modifications to address the problems of pogo oscillation, ruptured fuel lines, and bad igniter lines took place on 18 December, a mere three days before the scheduled launch.
Launch and trans-lunar injection.
Apollo 8 launched at 7:51:00 a.m. Eastern Standard Time on December 21, 1968, using the Saturn V's three stages, S-IC, S-II, and S-IVB, to achieve Earth orbit. The launch phase experienced only three minor problems: The engines of the first stage, S-IC, underperformed by 0.75%, causing the engines to burn for 2.45 seconds longer than planned, and toward the end of the second stage burn, S-II, the rocket underwent pogo oscillations. Frank Borman estimated the oscillations were approximately and (±2.5 m/s²). The apogee was also slightly higher than the planned circular orbit of. In its first manned mission, the Saturn V rocket placed Apollo 8 into a Earth orbit with a period of 88 minutes and 10 seconds.
All three rocket stages fired during launch; the S-IC and S-II detached during launch. The S-IC impacted the Atlantic Ocean at and the S-II second stage at. The third stage of the rocket, S-IVB, assisted in driving the craft into Earth orbit but remained attached to later perform the Trans-Lunar Injection (TLI), the burn that would put the spacecraft on a trajectory to the Moon.
Once in Earth orbit, both the Apollo 8 crew and Mission Control spent the next 2 hours and 38 minutes checking that the spacecraft was in proper working order and ready for TLI. The proper operation of third stage of the rocket, S-IVB was crucial; In the last unmanned test, the S-IVB had failed to re-ignite for TLI.
During the flight, three fellow astronauts served on the ground as capsule communicators (usually referred to as "CAPCOMs") on a rotating schedule. The CAPCOMs were the only people who regularly communicated with the crew. Michael Collins was the first CAPCOM on duty and at 2 hours, 27 minutes and 22 seconds after launch radioed, "Apollo 8. You are Go for TLI". This communication signified that Mission Control had given official permission for Apollo 8 to go to the moon. Over the next twelve minutes before the TLI burn, the Apollo 8 crew continued to monitor the spacecraft and the rocket. The S-IVB third stage rocket ignited on time and burned perfectly for 5 minutes and 17 seconds. The burn increased the velocity of Apollo 8 to and the spacecraft's altitude at the end of the burn was. At this time, the crew also set the record for the highest speed humans had ever traveled. Although the S-IVB was sufficiently powerful to accelerate the CSM to the Earth's escape velocity, the TLI burn did not achieve this; the CSM remained in an elongated elliptical Earth orbit, and would have returned to the Earth if it had not encountered the Moon's gravitational field.
After the S-IVB had performed its required tasks, it was jettisoned. The crew then rotated the spacecraft to take some photographs of the spent stage and then practiced flying in formation with it. As the crew rotated the spacecraft, they had their first views of the Earth as they moved away from it. This marked the first time humans could view the whole Earth at once. Borman became worried that the S-IVB was staying too close to the Command/Service Module and suggested to Mission Control that the crew perform a separation maneuver. Mission Control first suggested pointing the spacecraft towards Earth and using the Reaction Control System (RCS) thrusters on the Service Module to add away from the Earth, but Borman did not want to lose sight of the S-IVB. After discussion, the crew and Mission Control decided to burn in this direction, but at instead. These discussions put the crew an hour behind their flight plan.
Five hours after launch, Mission Control sent a command to the S-IVB booster to vent its remaining fuel through its engine bell to change the booster's trajectory. This S-IVB would then pass the Moon and enter into a solar orbit, posing no further hazard to Apollo 8. The S-IVB subsequently went into a solar orbit with an inclination of 23.47° and a period of 340.80 days.
The Apollo 8 crew were the first humans to pass through the Van Allen radiation belts, which extend up to from Earth. Scientists predicted that passing through the belts quickly at the spacecraft's high speed would cause a radiation dosage of no more than a chest X-ray, or 1 milligray (during the course of a year, the average human receives a dose of 2 to 3 mGy). To record the actual radiation dosages, each crew member wore a Personal Radiation Dosimeter that transmitted data to Earth as well as three passive film dosimeters that showed the cumulative radiation experienced by the crew. By the end of the mission, the crew experienced an average radiation dose of 1.6 mGy.
Lunar trajectory.
Jim Lovell's main job as Command Module Pilot was as navigator. Although Mission Control performed all of the actual navigation calculation, it was necessary to have a crew member serving as navigator so that the crew could successfully return to Earth in case of communication loss with Mission Control. Lovell navigated by star sightings using a sextant built into the spacecraft, measuring the angle between a star and the Earth's (or the Moon's) horizon. This task proved to be difficult, as a large cloud of debris around the spacecraft formed by the venting S-IVB made it hard to distinguish the stars.
By seven hours into the mission, the crew was about one hour and 40 minutes behind flight plan due to the issues of moving away from the S-IVB and Lovell's obscured star sightings. The crew now placed the spacecraft into Passive Thermal Control (PTC), also known as "barbecue" mode. PTC involved the spacecraft rotating about once per hour along its long axis to ensure even heat distribution across the surface of the spacecraft. In direct sunlight, the spacecraft could be heated to over 200 °C while the parts in shadow would be −100 °C. These temperatures could cause the heat shield to crack or propellant lines to burst. As it was impossible to get a perfect roll, the spacecraft actually swept out a cone as it rotated. The crew had to make minor adjustments every half hour as the cone pattern got larger and larger.
The first mid-course correction came 11 hours into the flight. Testing on the ground had shown that the Service Propulsion System (SPS) engine had a small chance of exploding when burned for long periods unless its combustion chamber was "coated" first. Burning the engine for a short period would accomplish coating. This first correction burn was only 2.4 seconds and added about prograde (in the direction of travel). This change was less than the planned due to a bubble of helium in the oxidizer lines causing lower than expected fuel pressure. The crew had to use the small Reaction Control System (RCS) thrusters to make up the shortfall. Two later planned mid-course corrections were canceled as the Apollo 8 trajectory was found to be perfect.
Eleven hours into the flight, the crew had been awake for over 16 hours. Before launch, NASA had decided that at least one crew member should be awake at all times to deal with any issues that might arise. Borman started the first sleep shift, but between the constant radio chatter and mechanical noises, he found sleep difficult.
About an hour after starting his sleep shift, Borman requested clearance to take a Seconal sleeping pill. However, the pill had little effect. Borman eventually fell asleep but then awoke feeling ill. He vomited twice and had a bout of diarrhea that left the spacecraft full of small globules of vomit and feces that the crew cleaned up to the best of their ability. Borman initially decided that he did not want everyone to know about his medical problems, but Lovell and Anders wanted to inform Mission Control. The crew decided to use the Data Storage Equipment (DSE), which could tape voice recordings and telemetry and dump them to Mission Control at high speed. After recording a description of Borman's illness they requested that Mission Control check the recording, stating that they "would like an evaluation of the voice comments".
The Apollo 8 crew and Mission Control medical personnel held a conference using an unoccupied second floor control room (there were two identical control rooms in Houston on the second and third floor, only one of which was used during a mission). The conference participants decided that there was little to worry about and that Borman's illness was either a 24-hour flu, as Borman thought, or a reaction to the sleeping pill. Researchers now believe that he was suffering from space adaptation syndrome, which affects about a third of astronauts during their first day in space as their vestibular system adapts to weightlessness. Space adaptation syndrome had not been an issue on previous spacecraft (Mercury and Gemini), as those astronauts were unable to move freely in the comparatively smaller cabins of those spacecraft. The increased cabin space in the Apollo Command Module afforded astronauts greater freedom of movement, contributing to symptoms of spacesickness for Borman and, later, astronaut Russell Schweickart during Apollo 9.
The cruise phase was a relatively uneventful part of the flight, except for the crew checking that the spacecraft was in working order and that they were on course. During this time, NASA scheduled a television broadcast at 31 hours after launch. The Apollo 8 crew used a 2 kg camera that broadcast in black-and-white only, using a Vidicon tube. The camera had two lenses, a very wide-angle (160°) lens, and a telephoto (9°) lens.
During this first broadcast, the crew gave a tour of the spacecraft and attempted to show how the Earth appeared from space. However, difficulties aiming the narrow-angle lens without the aid of a monitor to show what it was looking at made showing the Earth impossible. Additionally, the Earth image became saturated by any bright source without proper filters. In the end, all the crew could show the people watching back on Earth was a bright blob. After broadcasting for 17 minutes, the rotation of the spacecraft took the high-gain antenna out of view of the receiving stations on Earth and they ended the transmission with Lovell wishing his mother a happy birthday.
By this time, the crew had completely abandoned the planned sleep shifts. Lovell went to sleep 32½ hours into the flight — 3½ hours before he had planned to. A short while later, Anders also went to sleep after taking a sleeping pill.
The crew was unable to see the Moon for much of the outward cruise. Two factors made the Moon almost impossible to see from inside the spacecraft: three of the five windows fogging up due to out-gassed oils from the silicone sealant, and the attitude required for the PTC. It was not until the crew had gone behind the Moon that they would be able to see it for the first time.
The Apollo 8 made a second television broadcast at 55 hours into the flight. This time, the crew rigged up filters meant for the still cameras so they could acquire images of the Earth through the telephoto lens. Although difficult to aim, as they had to maneuver the entire spacecraft, the crew was able to broadcast back to Earth the first television pictures of the Earth. The crew spent the transmission describing the Earth and what was visible and the colors they could see. The transmission lasted 23 minutes.
Lunar sphere of influence.
At about 55 hours and 40 minutes into the flight, the crew of Apollo 8 became the first humans to enter the gravitational sphere of influence of another celestial body. In other words, the effect of the Moon's gravitational force on Apollo 8 became stronger than that of the Earth. At the time it happened, Apollo 8 was from the Moon and had a speed of relative to the Moon. This historic moment was of little interest to the crew since they were still calculating their trajectory with respect to the launch pad at Kennedy Space Center. They would continue to do so until they performed their last mid-course correction, switching to a reference frame based on ideal orientation for the second engine burn they would make in lunar orbit. It was only thirteen hours until they would be in lunar orbit.
The last major event before Lunar Orbit Insertion was a second mid-course correction. It was in retrograde (against direction of travel) and slowed the spacecraft down by, effectively lowering the closest distance that the spacecraft would pass the moon. At exactly 61 hours after launch, about from the Moon, the crew burned the RCS for 11 seconds. They would now pass from the lunar surface.
At 64 hours into the flight, the crew began to prepare for Lunar Orbit Insertion-1 (LOI-1). This maneuver had to be performed perfectly, and due to orbital mechanics had to be on the far side of the Moon, out of contact with the Earth. After Mission Control was polled for a Go/No Go decision, the crew was told at 68 hours, they were Go and "riding the best bird we can find". At 68 hours and 58 minutes, the spacecraft went behind the Moon and out of radio contact with the Earth.
With 10 minutes before the LOI-1, the crew began one last check of the spacecraft systems and made sure that every switch was in the correct place. At that time, they finally got their first glimpses of the Moon. They had been flying over the unlit side, and it was Lovell who saw the first shafts of sunlight obliquely illuminating the lunar surface. The LOI burn was only two minutes away, so the crew had little time to appreciate the view.
Lunar orbit.
The SPS ignited at 69 hours, 8 minutes, and 16 seconds after launch and burned for 4 minutes and 13 seconds, placing the Apollo 8 spacecraft in orbit around the Moon. The crew described the burn as being the longest four minutes of their lives. If the burn had not lasted exactly the correct amount of time, the spacecraft could have ended up in a highly elliptical lunar orbit or even flung off into space. If it lasted too long they could have impacted the Moon. After making sure the spacecraft was working, they finally had a chance to look at the Moon, which they would orbit for the next 20 hours.
On Earth, Mission Control continued to wait. If the crew had not burned the engine or the burn had not lasted the planned length of time, the crew would appear early from behind the Moon. However, this time came and went without Apollo 8 reappearing. Exactly at the calculated moment, the signal was received from the spacecraft, indicating it was in a orbit about the Moon.
Lovell continued to describe the terrain they were passing over. One of the crew's major tasks was reconnaissance of planned future landing sites on the Moon, especially one in Mare Tranquillitatis that would be the Apollo 11 landing site. The launch time of Apollo 8 had been chosen to give the best lighting conditions for examining the site. A film camera had been set up in one of the spacecraft windows to record a frame every second of the Moon below. Bill Anders spent much of the next 20 hours taking as many photographs as possible of targets of interest. By the end of the mission the crew had taken 700 photographs of the Moon and 150 of the Earth.
Throughout the hour that the spacecraft was in contact with Earth, Borman kept asking how the data for the SPS looked. He wanted to make sure that the engine was working and could be used to return early to the Earth if necessary. He also asked that they receive a Go/No Go decision before they passed behind the Moon on each orbit.
As they reappeared for their second pass in front of the Moon, the crew set up the equipment to broadcast a view of the lunar surface. Anders described the craters that they were passing over. At the end of this second orbit they performed the eleven-second LOI-2 burn of the SPS to circularize the orbit to.
Through the next two orbits, the crew continued to keep check of the spacecraft and to observe and photograph the Moon. During the third pass, Borman read a small prayer for his church. He was scheduled to participate in a service at St. Christopher's Episcopal Church near Seabrook, Texas, but due to the Apollo 8 flight was unable. A fellow parishioner and engineer at Mission Control, Rod Rose, suggested that Borman read the prayer which could be recorded and then replayed during the service.
Earthrise.
When the spacecraft came out from behind the Moon for its fourth pass across the front, the crew witnessed Earthrise for the first time in human history. Borman saw the Earth emerging from behind the lunar horizon and called in excitement to the others, taking a black-and-white photo as he did so. In the ensuing scramble Anders took the more famous colour photo, later picked by "Life" magazine as one of its hundred photos of the century. Due to the synchronous rotation of the Moon about the Earth, Earthrise is not generally visible from the Lunar surface. Earthrise is generally only visible when orbiting the Moon, other than at selected places near the Moon's limb, where libration carries the Earth slightly above and below the lunar horizon.
Anders continued to take photographs while Lovell assumed control of the spacecraft so Borman could rest. Despite the difficulty resting in the cramped and noisy spacecraft, Borman was able to sleep for two orbits, awakening periodically to ask questions about their status.
Borman awoke fully, however, when he started to hear his fellow crew members make mistakes. They were beginning to not understand questions and would have to ask for the answers to be repeated. Borman realized that everyone was extremely tired having not had a good night's sleep in over three days. Taking command, he ordered Anders and Lovell to get some sleep and that the rest of the flight plan regarding observing the Moon be scrubbed. At first Anders protested saying that he was fine, but Borman would not be swayed. At last Anders agreed as long as Borman would set up the camera to continue to take automatic shots of the Moon. Borman also remembered that there was a second television broadcast planned, and with so many people expected to be watching he wanted the crew to be alert. For the next two orbits Anders and Lovell slept while Borman sat at the helm. On subsequent Apollo missions, crews would avoid this situation by sleeping on the same schedule.
As they rounded the Moon for the ninth time, the second television transmission began. Borman introduced the crew, followed by each man giving his impression of the lunar surface and what it was like to be orbiting the Moon. Borman described it as being "a vast, lonely, forbidding expanse of nothing." Then, after talking about what they were flying over, Anders said that the crew had a message for all those on Earth. Each man on board read a section from the Biblical creation story (verses 1-10) from the Book of Genesis. Borman finished the broadcast by wishing a Merry Christmas to everyone on Earth. His message appeared to sum up the feelings that all three crewmen had from their vantage point in lunar orbit. Borman said, "And from the crew of Apollo 8, we close with good night, good luck, and a Merry Christmas, God bless all of you, "all of you on the good Earth".
The only task left for the crew at this point was to perform the Trans-Earth Injection (TEI), which was scheduled for 2½ hours after the end of the television transmission. The TEI was the most critical burn of the flight, as any failure of the SPS to ignite would strand the crew in Lunar orbit, with little hope of escape. As with the previous burn, the crew had to perform the maneuver above the far side of the Moon, out of contact with Earth.
The burn occurred exactly on time. The spacecraft telemetry was reacquired as it re-emerged from behind the Moon at 89 hours, 28 minutes, and 39 seconds, the exact time calculated. When voice contact was regained, Lovell announced, "Please be informed, there is a Santa Claus", to which Ken Mattingly, the current CAPCOM, replied, "That's affirmative, you are the best ones to know". The spacecraft began its journey back to Earth on December 25, Christmas Day.
Unplanned manual re-alignment.
Later, Lovell used some otherwise idle time to do some navigational sightings, maneuvering the module to view various stars by using the computer keyboard. However, he accidentally erased some of the computer's memory, which caused the inertial measuring unit (IMU) to think the module was in the same relative position it had been in before lift-off and fire the thrusters to "correct" the module's attitude.
Once the crew realized why the computer had changed the module's attitude, they realized they would have to re-enter data that would tell the computer its real position. It took Lovell ten minutes to figure out the right numbers, using the thrusters to get the stars Rigel and Sirius aligned, and another fifteen minutes to enter the corrected data into the computer.
Sixteen months later, Lovell would once again have to perform a similar manual re-alignment, under more critical conditions, during the Apollo 13 mission, after that module's IMU had to be turned off to conserve energy. In his 1994 book, ', Lovell wrote, "My training [on Apollo 8] came in handy!". In that book he dismissed the incident as a "planned experiment", requested by the ground crew. However, in subsequent interviews Lovell has acknowledged that the incident was an accident, caused by his mistake.
Cruise back to Earth and re-entry.
The cruise back to Earth was mostly a time for the crew to relax and monitor the spacecraft. As long as the trajectory specialists had calculated everything correctly, the spacecraft would re-enter 2½ days after TEI and splashdown in the Pacific.
On Christmas afternoon, the crew made their fifth television broadcast. This time they gave a tour of the spacecraft, showing how an astronaut lived in space. When they had finished broadcasting they found a small present from Deke Slayton in the food locker—real turkey with stuffing and three miniature bottles of brandy (which remained unopened). There were also small presents to the crew from their wives. The next day, at about 124 hours into the mission, the sixth and final TV transmission showed the mission's best video images of the earth, in a short four minute broadcast.
After two uneventful days the crew prepared for re-entry. The computer would control the re-entry and all the crew had to do was put the spacecraft in the correct attitude, blunt end forward. If the computer broke down, Borman would take over.
Once the Command Module was separated from the Service Module, the astronauts were committed to re-entry. Six minutes before they hit the top of the atmosphere, the crew saw the Moon rising above the Earth's horizon, just as had been predicted by the trajectory specialists. As they hit the thin outer atmosphere they noticed it was becoming hazy outside as glowing plasma formed around the spacecraft. The spacecraft started slowing down and the deceleration peaked at 6 g (59 m/s²). With the computer controlling the descent by changing the attitude of the spacecraft, Apollo 8 rose briefly like a skipping stone before descending to the ocean. At the drogue parachute stabilized the spacecraft and was followed at by the three main parachutes. The spacecraft splashdown position was estimated to be.
When it hit the water, the parachutes dragged the spacecraft over and left it upside down, in what was termed Stable 2 position. As they were buffeted by a swell, Borman was sick, waiting for the three flotation balloons to right the spacecraft. It was 43 minutes after splashdown before the first frogman from the USS "Yorktown" arrived, as the spacecraft had landed before sunrise. Forty-five minutes later, the crew was safe on the deck of the aircraft carrier.
Historical importance.
Apollo 8 came at the end of 1968, a year that had seen much upheaval around the world. Yet, "TIME" magazine chose the crew of Apollo 8 as their Men of the Year for 1968, recognizing them as the people who most influenced events in the preceding year. They had been the first people ever to leave the gravitational influence of the Earth and orbit another celestial body. They had survived a mission that even the crew themselves had rated as only having a fifty-fifty chance of fully succeeding. The effect of Apollo 8 can be summed up by a telegram from a stranger, received by Borman after the mission, that simply stated, "Thank you Apollo 8. You saved 1968."
One of the most famous aspects of the flight was the Earthrise picture that was taken as they came around for their fourth orbit of the Moon. This was the first time that humans had taken such a picture whilst actually behind the camera, and it has been credited with a role in inspiring the first Earth Day in 1970. It was selected as the first of "Life" magazine's 'hundred photos that changed the world'. Apollo 8 is regarded by some as the most historically significant of all the Apollo missions.
The mission was the most widely covered by the media since the first American orbital flight, Mercury-Atlas 6 by John Glenn in 1962. There were 1200 journalists covering the mission, with the BBC coverage being broadcast in 54 countries in 15 different languages. The Soviet newspaper "Pravda" featured a quote from Boris Nikolaevich Petrov, Chairman of the Soviet Intercosmos program, who described the flight as an "outstanding achievement of American space sciences and technology". It is estimated that a quarter of the people alive at the time saw — either live or delayed — the Christmas Eve transmission during the ninth orbit of the Moon. The Apollo 8 broadcasts won an Emmy, the highest honor given by the Academy of Television Arts and Sciences.
Atheist Madalyn Murray O'Hair later caused controversy by bringing a lawsuit against NASA over the reading from "Genesis". O'Hair wished the courts to ban US astronauts — who were all Government employees — from public prayer in space. Though the case was rejected by the US Supreme Court for lack of jurisdiction, it caused NASA to be skittish about the issue of religion throughout the rest of the Apollo program. Buzz Aldrin, on Apollo 11, self-communicated Presbyterian Communion on the surface of the moon after landing; he refrained from mentioning this publicly for several years, and only obliquely referred to it at the time.
In 1969, the US Postal Service issued a postage stamp (1371) commemorating the Apollo 8 flight around the moon. The stamp featured a detail of the famous photograph of the Earthrise over the moon taken by Anders on Christmas Eve, and the words, "In the beginning God..."
Mission parameters.
The mission parameters for Apollo 8 differed significantly from those of previous flights, for several reasons. As the first manned spacecraft to orbit multiple celestial bodies, the mission recorded two different sets of orbital parameters. The mission was also the first to execute a translunar injection.
While in parking orbit around the Earth, Apollo 8 maintained altitude between a perigee of and an apogee of. The inclination of this orbit, or its angle in relation to the equator, was 32.51°. Each orbit had a period of 88.17 minutes.
In contrast, the spacecraft orbited the Moon at more varying altitudes. At its lowest altitude above the moon's surface, the spacecraft had a pericynthion of, while the highest altitude, or apocynthion, was. The spacecraft took 128.7 minutes to complete each of its 10 circuits around the Moon, at an inclination of 12°.
The spacecraft began its translunar injection burn on December 21, 1968, at 15:41:38 UTC. The burn represented the second of two burns on the Saturn V rocket's S-IVB third stage. The rocket burned for a total of 318 seconds, propelling the spacecraft from an Earth parking orbit velocity of to a translunar trajectory velocity of.
Spacecraft location.
The command module is now displayed at the Chicago Museum of Science and Industry, along with a collection of personal items from the flight donated by Lovell and the spacesuit worn by Frank Borman. Jim Lovell's Apollo 8 spacesuit is on public display in the Visitor Center at NASA's Glenn Research Center. Bill Anders' spacesuit is on display at the Science Museum in London, England.
In film.
Apollo 8's historic mission has been shown and referred to in several forms, both documentary and fiction. The various television transmissions and 16 mm footage shot by the crew of Apollo 8 was compiled and released by NASA in the 1969 documentary, "Debrief: Apollo 8", which was hosted by Burgess Meredith. In addition, Spacecraft Films released a three-disc DVD set covering the mission in 2003. Portions of the Apollo 8 Mission can be seen in the 1989 documentary "For All Mankind", which won the Grand Jury Prize at the Sundance Film Festival for Outstanding Documentary. The Apollo 8 mission was well covered in the British documentary: 'In the Shadow of the Moon'.
Apollo 8 was mentioned in the film "Apollo 13," though only briefly.
Portions of the Apollo 8 mission are dramatized in the miniseries "From the Earth to the Moon" episode "1968". The S-IVB stage of Apollo 8 was also portrayed as the location of an alien device in the 1970 "UFO" episode "Conflict".
---END.OF.DOCUMENT---
Astronaut.
An astronaut or cosmonaut is a person trained by a human spaceflight program to command, pilot, or serve as a crew member of a spacecraft.
While generally reserved for professional space travelers, the term is sometimes applied to anyone who travels into space, including scientists, politicians, journalists, and tourists.
Until 2003, astronauts were sponsored and trained exclusively by governments, either by the military, or by civilian space agencies. With the sub-orbital flight of the privately-funded SpaceShipOne in 2004, a new category of astronaut was created: the commercial astronaut.
Definition.
The criteria for what constitutes human spaceflight vary. The Fédération Aéronautique Internationale (FAI) Sporting Code for astronautics recognizes only flights that exceed an altitude of. In the United States, professional, military, and commercial astronauts who travel above an altitude of are awarded astronaut wings.
As of September 19, 2009, a total of 505 humans from 38 countries have reached 100 km or more in altitude, of which 502 reached Low Earth orbit or beyond.
Of these, 24 people have traveled beyond Low Earth orbit, to either lunar or trans-lunar orbit or to the surface of the moon; three of the 24 did so twice: Jim Lovell, John Young and Eugene Cernan.
Under the U. S. definition, 496 people qualify as having reached space, above altitude. Of eight X-15 pilots who exceeded 50 miles in altitude, seven reached above but below 100 kilometers (about 62 miles).
Space travelers have spent over 30,400 person-days (or a cumulative total of over 83 years) in space, including over 100 astronaut-days of spacewalks.
As of 2008, the man with the longest time in space is Sergei K. Krikalev, who has spent 803 days, 9 hours and 39 minutes, or 2.2 years, in space.
Peggy A. Whitson holds the record for most time in space by a woman, 377 days.
English-speaking nations.
In the United States, Canada, United Kingdom, and many other English-speaking nations, a professional space traveler is called an "astronaut". The term derives from the Greek words "ástron" (ἄστρον), meaning "star", and "nautes" (ναύτης), meaning "sailor". The first known use of the term "astronaut" in the modern sense was by Neil R. Jones in his short story "The Death's Head Meteor" in 1930. The word itself had been known earlier. For example, in Percy Greg's 1880 book "Across the Zodiac", "astronaut" referred to a spacecraft. In "Les Navigateurs de l'Infini" (1925) of J.-H. Rosny aîné, the word "astronautique" (astronautic) was used. The word may have been inspired by "aeronaut", an older term for an air traveler first applied (in 1784) to balloonists.
NASA applies the term astronaut to any crew member aboard NASA spacecraft bound for Earth orbit or beyond. NASA also uses the term as a title for those selected to join its Astronaut Corps. The European Space Agency similarly uses the term astronaut for members of its Astronaut Corps.
Russian.
By convention, an astronaut employed by the Russian Federal Space Agency (or its Soviet predecessor) is called a cosmonaut in English texts. The word is an anglicisation of the Russian word "kosmonavt" (), which in turn derives from the Greek words "kosmos" (κόσμος), meaning "universe", and "nautes" (ναύτης), meaning "sailor". For the most part, "cosmonaut" and "astronaut" are synonyms in all languages, and the usage of choice is often dictated by political reasons.
Yuri Gagarin, Russian, is the first human cosmonaut. Valentina Tereshkova, Russian, is the first woman cosmonaut. On March 14, 1995, Norman Thagard became the first American to ride to space on board a Russian launch vehicle, arguably becoming the first "American cosmonaut" in the process.
Chinese.
Official English-language texts issued by the government of the People's Republic of China use "astronaut" while texts in Russian use "космонавт" ("kosmonavt"). In China, the terms "yǔhángyuán" (, "sailing personnel in universe") or "hángtiānyuán" (, "sailing personnel in sky") have long been used for astronauts. The phrase "tàikōng rén" (, "spaceman") is often used in Taiwan and Hong Kong.
The term taikonaut is used by some English-language news media organizations for professional space travelers from China. The word has featured in the Longman and Oxford English dictionaries, the latter of which describes it as "a hybrid of the Chinese term "taikong" (space) and the Greek "naut" (sailor)"; the term became more common in 2003 when China sent its first astronaut Yang Liwei into space aboard the "Shenzhou 5" spacecraft. This is the term used by Xinhua in the English version of the Chinese People's Daily since the advent of the Chinese space program. The origin of the term is unclear; as early as May 1998, Chiew Lee Yih () from Malaysia, used it in newsgroups, while Chen Lan (), almost simultaneously, announced it at his "Go Taikonauts!" GeoCities page.
Other terms.
With the rise of space tourism, NASA and the Russian Federal Space Agency agreed to use the term "spaceflight participant" to distinguish those space travelers from astronauts on missions coordinated by those two agencies.
While no nation other than Russia (formerly the Soviet Union), the United States, and China has launched a manned spacecraft, several other nations have sent people into space in cooperation with one of these countries. Inspired partly by these missions, other synonyms for astronaut have entered occasional English usage. For example, the term spationaut (French spelling: "spationaute") is sometimes used to describe French space travelers, from the Latin word "spatium" or space, and the Malay term "angkasawan" was used to describe participants in the Angkasawan program.
Space travel milestones.
The first human in space was Russian Yuri Gagarin, who was launched into space on April 12, 1961 aboard Vostok 1 and orbited around the Earth for 108 minutes. There are allegations that Gagarin ejected from landing module after re-entering the atmosphere and parachuted back, due to safety concerns about the craft's landing systems. The first woman in space was Russian Valentina Tereshkova, launched in June 1963 aboard Vostok 6.
Alan Shepard became the first American and second person in space on May 5, 1961 on a 15-minute sub-orbital flight. The first American woman in space was Sally Ride, during Space Shuttle Challenger's mission STS-7, on June 18, 1983.
The first mission to orbit the moon was "Apollo 8", which included William Anders who was born in Hong Kong, making him the first Asian-born astronaut in 1968. In April 1985, Taylor Wang became the first ethnic Chinese person in space. On 15 October 2003, Yang Liwei became China's first astronaut on the Shenzhou 5 spacecraft.
The Soviet Union, through its Intercosmos program, allowed people from other "socialist" (i.e. Warsaw Pact and other Soviet-allied) countries to fly on its missions. An example is Vladimír Remek, a Czechoslovak, who became the first non-Soviet European in space in 1978 on a Russian Soyuz-U rocket.
On July 23, 1980, Pham Tuan of Vietnam became the first Asian in space when he flew aboard Soyuz 37.
Also in 1980, Cuban Arnaldo Tamayo Méndez became the first person of Hispanic and black African descent to fly in space, Guion Bluford became the first African American to fly into space. The first person born in Africa to fly in space was Patrick Baudry, in 1985. In 1988, Abdul Ahad Mohmand became the first Afghan to reach space, spending nine days aboard the Mir space station.
With the larger number of seats available on the Space Shuttle, the U.S. began taking international astronauts. In 1983, Ulf Merbold of West Germany became the first non-US citizen to fly in a US spacecraft.
In 1985, Rodolfo Neri Vela became the first Mexican-born person in space. In 1991, Helen Sharman became the first Briton to fly in space.
In 2002, Mark Shuttleworth became the first citizen of an African country to fly in space, as a paying spaceflight participant. In 2003, Ilan Ramon became the first Israeli to fly in space, although he died during a re-entry accident.
Age milestones.
The youngest person to fly in space is Gherman Titov, who was 25 years old when he flew Vostok 2. (Titov was also the first person to suffer space sickness).
The oldest person who has flown in space is John Glenn, who was 77 when he flew on STS-95.
Duration and distance milestones.
The longest stay in space was 438 days, by Russian Valeri Polyakov.
As of 2006, the most spaceflights by an individual astronaut is seven, a record held by both Jerry L. Ross and Franklin Chang-Diaz. The farthest distance from Earth an astronaut has traveled was 401,056 km, when Jim Lovell, John Swigert, and Fred Haise went around the Moon during the Apollo 13 emergency.
Civilian and non-government milestones.
The first civilian in space was Neil Armstrong, who had retired from the United States Navy before his first spaceflight on Gemini 8. The first person in space who had never been a member of any country's armed forces was Harrison Schmitt, a geologist who first flew in space on Apollo 17. Both Armstrong and Schmitt were directly employed by NASA.
The first non-governmental space traveler was Byron K. Lichtenberg, a researcher from the Massachusetts Institute of Technology who flew on STS-9 in 1983. In December 1990, Toyohiro Akiyama became the first paying space traveler as a reporter for Tokyo Broadcasting System, a visit to Mir as part of an estimated $12 million (USD) deal with a Japanese TV station, although at the time, the term used to refer to Akiyama was "Research Cosmonaut". Akiyama suffered severe space-sickness during his mission, which affected his productivity.
The first self-funded space tourist was Dennis Tito onboard the Russian spacecraft Soyuz TM-3 on 28 April 2001.
Training.
The first NASA astronauts were selected for training in 1959. Early in the space program, military jet test piloting and engineering training were often cited as prerequisites for selection as an astronaut at NASA, although neither John Glenn nor Scott Carpenter (of the Mercury Seven) had any university degree, in engineering or any other discipline at the time of their selection. Selection was initially limited to military pilots. The earliest astronauts for both America and Russia tended to be jet fighter pilots, and were often test pilots.
Once selected, NASA astronauts go through 20 months of training in a variety of areas, including training for extra-vehicular activity in a facility such as NASA's Neutral Buoyancy Laboratory. Astronauts-in-training may also experience short periods of weightlessness in aircraft called the "vomit comet", the nickname given to a pair of modified KC-135s (retired in 2000 and 2004 respectively, and replaced in 2005 with a C-9) which perform parabolic flights. Astronauts are also required to accumulate a number of flight hours in high-performance jet aircraft. This is mostly done in T-38 jet aircraft out of Ellington Field, due to its proximity to the Johnson Space Center. Ellington Field is also where the Shuttle Training Aircraft is maintained and developed, although most flights of the aircraft are done out of Edwards Air Force Base.
Mission Specialist Educator.
Mission Specialist Educators, or "Educator Astronauts", were first selected in 2004, and as of 2007, there are three NASA Educator astronauts: Joseph M. Acaba, Richard R. Arnold, and Dorothy Metcalf-Lindenburger.
Barbara Morgan, selected as back-up teacher to Christa McAuliffe in 1985, is considered to be the first Educator astronaut by the media, but she trained as a mission specialist.
The Educator Astronaut program is a successor to the Teacher in Space program from the 1980s.
Health risks of space travel.
Astronauts are susceptible to a variety of health risks including decompression sickness, barotrauma, immunodeficiencies, loss of bone and muscle, orthostatic intolerance due to volume loss, sleep disturbances, and radiation injury. A variety of large scale medical studies are being conducted in space via the National Space and Biomedical Research Institute (NSBRI) to address these issues. Prominent among these is the Advanced Diagnostic Ultrasound in Microgravity Study in which astronauts (including former ISS commanders Leroy Chiao and Gennady Padalka) perform ultrasound scans under the guidance of remote experts to diagnose and potentially treat hundreds of medical conditions in space. This study's techniques are now being applied to cover professional and Olympic sports injuries as well as ultrasound performed by non-expert operators in medical and high school students. It is anticipated that remote guided ultrasound will have application on Earth in emergency and rural care situations, where access to a trained physician is often rare. For more information on the health hazards faced by astronauts, go to the article entitled Space medicine.
Insignia.
At NASA, people who complete astronaut candidate training receive a silver lapel pin. Once they have flown in space, they receive a gold pin. U.S. astronauts who also have active-duty military status receive a special qualification badge, known as the Astronaut Badge, after participation on a spaceflight. The United States Air Force also presents an Astronaut Badge to its pilots who exceed 50 miles (80 km) in altitude.
Deaths.
Eighteen astronauts have lost their lives during spaceflight, on four missions. By nationality, they are thirteen Americans, three Russians, one Ukrainian, and one Israeli. Several others have died while training for space missions.
The Space Mirror Memorial, which stands on the grounds of the John F. Kennedy Space Center Visitor Complex, commemorates the lives of the men and women who have died during spaceflight and during training in the space programs of the United States. In addition to twenty NASA career astronauts, the memorial includes the names of a U.S. Air Force X-15 test pilot, a U.S. Air Force officer who died while training for a then-classified military space program, a civilian spaceflight participant who died in the Challenger disaster, and an international astronaut who was killed in the Columbia disaster.
---END.OF.DOCUMENT---
A Modest Proposal.
"A Modest Proposal: For Preventing the Children of Poor People in Ireland from Being a Burden to Their Parents or Country, and for Making Them Beneficial to the Publick", commonly referred to as "A Modest Proposal", is a Juvenalian satirical essay written and published anonymously by Jonathan Swift in 1729. Swift appears to suggest in his essay that the impoverished Irish might ease their economic troubles by selling children as food for rich gentlemen and ladies. By doing this he mocks the authority of the British officials.
Details.
Swift goes to great lengths to support his argument, including a list of possible preparation styles for the children, and calculations showing the financial benefits of his suggestion. He uses common methods of argument throughout his essay, such as appealing to the authority of "a very knowing American of my acquaintance in London" and "the famous Psalmanazar, a native of the island Formosa" (who had already confessed to "not" being from Formosa in 1706). Swift couches his arguments in then-current events, exploiting common prejudice against Catholics (misnomed "Papists") and pointing out their depredations of England. After enumerating the benefits of his proposal, Swift addresses possible objections including the depopulation of Ireland and a litany of other solutions which he dismisses as impractical.
This essay is widely held to be one of the greatest examples of sustained irony in the history of the English language. Much of its shock value derives from the fact that the first portion of the essay describes the plight of starving beggars in Ireland, so that the reader is unprepared for the surprise of Swift's solution when he states, "A young healthy child well nursed, is, at a year old, a most delicious nourishing and wholesome food, whether stewed, roasted, baked, or boiled; and I make no doubt that it will equally serve in a fricassee, or a ragout."
Readers unacquainted with its reputation as a satirical work often do not immediately realize that Swift was not seriously proposing cannibalism and infanticide, nor would readers unfamiliar with the satires of Horace and Juvenal recognize that Swift's essay follows the rules and structure of Latin satires.
The satirical element of the pamphlet is often only understood after the reader notes the allusions made by Swift to the attitudes of landlords, such as the following: "I grant this food may be somewhat dear, and therefore very proper for Landlords, who as they have already devoured most of the Parents, seem to have the best Title to the Children." Swift extends the metaphor to get in a few jibes at England’s mistreatment of Ireland, noting that "For this kind of commodity will not bear exportation, and flesh being of too tender a consistence, to admit a long continuance in salt, although perhaps I could name a country, which would be glad to eat up our whole nation without it."
Population solutions.
It has been argued that Swift’s main target in "A Modest Proposal" was not the conditions in Ireland, but rather the can-do spirit of the times that led people to devise a number of illogical schemes that would purportedly solve social and economic ills. Swift was especially insulted by projects that tried to fix population and labor issues with a simple cure-all solution. A memorable example of these sorts of schemes "involved the idea of running the poor through a joint-stock company". In response, Swift’s "Modest Proposal" was "a burlesque of projects concerning the poor", that were in vogue during the early 18th century.
"A Modest Proposal" also targets the calculating way people perceived the poor in designing their projects. The pamphlet targets reformers who "regard people as commodities". In the piece, Swift adopts the "technique of a political arithmetician" to show the utter ridiculousness of trying to prove any proposal with dispassionate statistics.
Critics differ about Swift’s intentions in using this faux-mathematical philosophy. Edmund Wilson argues that statistically "the logic of the 'Modest proposal' can be compared with defense of crime (arrogated to Marx) in which he argues that crime takes care of the superfluous population". Wittkowsky counters that Swift's satiric use of statistical analysis is an effort to enhance his satire that "springs from a spirit of bitter mockery, not from the delight in calculations for their own sake".
Rhetoric.
Charles K. Smith argues that Swift’s rhetorical style persuades the reader to detest the speaker and pity the Irish. Swift’s specific strategy is twofold, using a "trap" to create sympathy for the Irish and a dislike of the narrator who, in the span of one sentence, "details vividly and with rhetorical emphasis the grinding poverty" but feels emotion solely for members of his own class. Swift’s use of gripping details of poverty and his narrator’s cool approach towards them creates "two opposing points of view" which "alienate the reader, perhaps unconsciously, from a narrator who can view with 'melancholy' detachment a subject that Swift has directed us, rhetorically, to see in a much less detached way".
Swift has his proposer further degrade the Irish by using language ordinarily reserved for animals. Lewis argues that the speaker uses "the vocabulary of animal husbandry" to describe the Irish. Once the children have been commoditized, Swift’s rhetoric can easily turn "people into animals, then meat, and from meat, logically, into tonnage worth a price per pound".
Swift uses the proposer’s serious tone to highlight the absurdity of his proposal. In making his argument, the speaker uses the conventional, text book approved order of argument from Swift’s time. The contrast between the "careful control against the almost inconceivable perversion of his scheme" and "the ridiculousness of the proposal" create a situation in which the reader has "to consider just what perverted values and assumptions would allow such a diligent, thoughtful, and conventional man to propose so perverse a plan".
Tertullian’s "Apology".
Some scholars have argued that "A Modest Proposal" was largely influenced and inspired by Tertullian’s "Apology". While Tertullian’s "Apology" is a satirical attack against early Roman persecution of Christianity, Swift’s "A Modest Proposal" addresses the Anglo-Irish situation in the 1720s. James William Johnson believes that Swift saw major similarities between the two situations. Johnson notes Swift’s obvious affinity for Tertullian and the bold stylistic and structural similarities between the works "A Modest Proposal" and "Apology". In structure, Johnson points out the same central theme; that of cannibalism and the eating of babies; and the same final argument; that "human depravity is such that men will attempt to justify their own cruelty by accusing their victims of being lower than human". Stylistically, Swift and Tertullian share the same command of sarcasm and language. In agreement with Johnson, Donald C. Baker points out the similarity between both authors' tones and use of irony. Baker notes the uncanny way that both authors imply an ironic "justification by ownership" over the subject of sacrificing children—Tertullian while attacking pagan parents, and Swift while attacking the English mistreatment of the Irish poor.
Economic themes.
Robert Phiddian's article "Have you eaten yet? The Reader in A Modest Proposal" focuses on two aspects of "A Modest Proposal": the voice of Swift and the voice of the Proposer. Phiddian stresses that a reader of the pamphlet must learn to distinguish between the satiric voice of Jonathan Swift and the apparent economic projections of the Proposer. He reminds readers that "there is a gap between the narrator’s meaning and the text’s, and that a moral-political argument is being carried out by means of parody".
While Swift’s proposal is obviously not a serious economic proposal, George Wittkowsky, author of "Swift’s Modest Proposal: The Biography of an Early Georgian Pamphlet", argues that it in order to understand the piece fully, it is important to understand the economics of Swift’s time. Wittowsky argues that not enough critics have taken the time to focus directly on the mercantilism and theories of labor in 18th century England. "[I]f one regards the "Modest Proposal" simply as a criticism of condition, about all one can say is that conditions were bad and that Swift's irony brilliantly underscored this fact". At the start of a new industrial age in the 18th century, it was believed that "people are the riches of the nation", and there was a general faith in an economy which paid its workers low wages because high wages would mean workers would work less. Furthermore, "in the mercantilist view no child was too young to go into industry". In those times, the "somewhat more humane attitudes of an earlier day had all but disappeared and the laborer had come to be regarded as a commodity".
People are the riches of a nation.
Louis A. Landa presents Swift’s "A Modest Proposal" as a critique of the popular and unjustified maxim of mercantilism in the eighteenth century that "people are the riches of a nation". Swift presents the dire state of Ireland and shows that mere population itself, in Ireland’s case, did not always mean greater wealth and economy. The uncontrolled maxim fails to take into account that a person that does not produce in an economic or political way makes a country poorer, not richer. Swift also recognizes the implications of such a fact in making mercantilist philosophy a paradox: the wealth of a country is based on the poverty of the majority of its citizens. Swift however, Landa argues, is not merely criticizing economic maxims but also addressing the fact that England was denying Irish citizens their natural rights and dehumanizing them by viewing them as a mere commodity.
Modern usage.
"A Modest Proposal" is included in many literature programs as an example of early modern western satire. It also serves as an exceptional introduction to the concept and use of argumentative language, lending itself well to secondary and post-secondary essay courses. Outside of the realm of English studies, "A Modest Proposal" is a relevant piece included in many comparative and global literature and history courses, as well as those of numerous other disciplines in the arts, humanities, and even the social sciences.
It has been emulated many times as well. In his book "A Modest Proposal" (1984), evangelical author Frank Schaeffer emulated Swift's work in social conservative polemic against abortion and euthanasia in a future dystopia that advocated recycling of aborted embryos and fetuses, as well as some disabled infants with compound intellectual, physical and physiological difficulties. (Such Baby Doe Rules cases were then a major concern of the pro-life movement of the early 1980s, which viewed selective treatment of those infants as disability discrimination.)
In Hunter S. Thompson's, which contains hundreds of private letters written by Thompson over the years, contains a letter in which he uses "A Modest Proposals satire technique against the Vietnam War. Thompson writes a letter to a local Aspen newspaper informing them that, on Christmas Eve, he was going to use napalm to burn a number of dogs and hopefully any humans they find. This letter protests the burning of Vietnamese people occurring overseas.
In popular culture.
The game "Orphan Feast" on Cartoon Network's Adult Swim website is loosely based on "A Modest Proposal".
The show "Sealab 2021" references "A Modest Proposal" by the character of Jodene Sparks. It was suggested as recommended reading when Debbie wanted a child.
"A Modest Proposal" is the name of The University of Texas at Dallas', the monthly opinion paper of the University; and was the name of a regular column in of Harvard University, a satire publication which also takes its name from Johnathan Swift.
"A Modest Proposal" is mentioned in the 1996 film "The Birdcage".
Controversial American political activist and disbarred attorney Jack Thompson's A Modest Video Game Proposal draws its title from "A Modest Proposal".
One of the radio presenters in the game Saint's Row claims he has "A modest proposal" which is to apply shock collars to all immigrants in America.
---END.OF.DOCUMENT---
Alphabet.
The word "alphabet" came into Middle English from the Late Latin word Alphabetum, which in turn originated in the Ancient Greek "Αλφάβητος" Alphabetos, from "alpha" and "beta," the first two letters of the Greek alphabet. "Alpha" and "beta" in turn came from the first two letters of the Phoenician alphabet, and meant "ox" and "house" respectively. There are dozens of alphabets in use today, the most common being Latin, deriving from the first true alphabet, Greek.
Most of them are composed of lines (linear writing); notable exceptions are Braille, fingerspelling (Sign language), and Morse code.
Linguistic definition and context.
The term alphabet prototypically refers to a writing system that has characters (graphemes) which represent both consonant and vowel sounds, even though there may not be a complete one-to-one correspondence between symbol and sound.
A grapheme is an abstract entity which may be physically represented by different styles of glyphs. There are many written entities which do not form part of the alphabet, including numerals, mathematical symbols, and punctuation. Some human languages are commonly written using a combination of logograms (which represent morphemes or words) and syllabaries (which represent syllables) instead of an alphabet. Egyptian hieroglyphs and Chinese characters are two of the best-known writing systems with predominantly non-alphabetic representations.
Non-written languages may also be represented alphabetically. For example, linguists researching a non-written language (such as some of the indigenous Amerindian languages) will use the International Phonetic Alphabet to enable them to write down the sounds they hear.
Most, if not all, linguistic writing systems have some means for phonetic approximation of foreign words, usually using the native character set.
The English alphabet has 26 letters in it.
Middle Eastern Scripts.
The history of the alphabet started in ancient Egypt. By 2700 BC Egyptian writing had a set of some 24 hieroglyphs which are called uniliterals, to represent syllables that begin with a single consonant of their language, plus a vowel (or no vowel) to be supplied by the native speaker. These glyphs were used as pronunciation guides for logograms, to write grammatical inflections, and, later, to transcribe loan words and foreign names.
However, although seemingly alphabetic in nature, the original Egyptian uniliterals were not a system and were never used by themselves to encode Egyptian speech. In the Middle Bronze Age an apparently "alphabetic" system known as the Proto-Sinaitic script is thought by some to have been developed in the Sinai peninsula during the 19th century BC, by Canaanite workers in the Egyptian turquoise mines. Others suggest the alphabet was developed in central Egypt during the 15th century BC for or by Semitic workers, but only one of these early writings has been deciphered and their exact nature remains open to interpretation. Based on letter appearances and names, it is believed to be based on Egyptian hieroglyphs. This script had no characters representing vowels. An alphabetic cuneiform script with 30 signs including 3 which indicate the following vowel was invented in Ugarit before the 15th century BC. This script was not used after the destruction of Ugarit.
The Proto-Sinatic or Proto-Canaanite script eventually developed into the Proto-Canaanite alphabet, which in turn was refined into the Phoenician alphabet. The oldest text in Phoenician script is an inscription on the sarcophagus of King Ahiram.This script is the parent script of all western alphabets.At the tenth century two other forms can be distinguished namely Canaanite and Aramaic.The Aramaic gave rise to Hebrew. The South Arabian alphabet, a sister script to the Phoenician alphabet, is the script from which the Ge'ez alphabet (an abugida) is descended. Note that the scripts mentioned above are not considered proper alphabets, as they all lack characters representing vowels. These vowelless alphabets are called abjads, currently exemplified in scripts including Arabic, Hebrew, and Syriac.The omission of vowels was not a satisfactory solution and some "weak" consonants were used to indicate the vowel quality of a syllable.(matres lectionis).These had dual function since they were also used as pure consonants.
The Proto-Sinatic or Proto Canaanite script and the Ugaritic script were the first scripts with limited number of signs, in contrast to the other widely used writing systems at the time, Cuneiform, Egyptian hieroglyphs, and Linear B. The Phoenecian script was probably the first phonemic script and it contained only about two dozen distinct letters, making it a script simple enough for common traders to learn. Another advantage of Phoenician was that it could be used to write down many different languages, since it recorded words phonemically.
The script was spread by the Phoenicians, across the Mediterranean. In Greece, the script was modified to add the vowels, giving rise to the ancestor of all alphabets in the West. The indication of the vowels is the same way as the indication of the consonants, therefore it was the first true alphabet. The Greeks took letters which did not represent sounds that existed in Greek, and changed them to represent the vowels. The vowels are significant in the Greek language, and the syllabical Linear B script which was used by the Mycenean Greeks from the 16th century BC had 87 symbols including 5 vowels. In its early years, there were many variants of the Greek alphabet, a situation which caused many different alphabets to evolve from it.
European alphabets.
The Cumae form of the Greek alphabet was carried over by Greek colonists from Euboea to the Italian peninsula, where it gave rise to a variety of alphabets used to inscribe the Italic languages. One of these became the Latin alphabet, which was spread across Europe as the Romans expanded their empire. Even after the fall of the Roman state, the alphabet survived in intellectual and religious works. It eventually became used for the descendant languages of Latin (the Romance languages) and then for most of the other languages of Europe.
Another notable script is Elder Futhark, which is believed to have evolved out of one of the Old Italic alphabets. Elder Futhark gave rise to a variety of alphabets known collectively as the Runic alphabets. The Runic alphabets were used for Germanic languages from AD 100 to the late Middle Ages. Its usage was mostly restricted to engravings on stone and jewelry, although inscriptions have also been found on bone and wood. These alphabets have since been replaced with the Latin alphabet, except for decorative usage for which the runes remained in use until the 20th century.
The Glagolitic alphabet was the initial script of the liturgical language Old Church Slavonic and became, together with the Greek uncial script, the basis of the Cyrillic alphabet. The Cyrillic alphabet is one of the most widely used modern alphabets, and is notable for its use in Slavic languages and also for other languages within the former Soviet Union. Variants include the Serbian, Macedonian, Bulgarian, and Russian alphabets. The Glagolitic alphabet is believed to have been created by Saints Cyril and Methodius, while the Cyrillic alphabet was invented by the Bulgarian scholar Clement of Ohrid, who was their disciple. They feature many letters that appear to have been borrowed from or influenced by the Greek alphabet and the Hebrew alphabet.
Asian alphabets.
Beyond the logographic Chinese writing, many phonetic scripts are in existence in Asia. The Arabic alphabet, Hebrew alphabet, Syriac alphabet, and other abjads of the Middle East are developments of the Aramaic alphabet, but because these writing systems are largely consonant-based they are often not considered true alphabets.
Most alphabetic scripts of India and Eastern Asia are descended from the Brahmi script, which is often believed to be a descendent of Aramaic.
In Korea, the Hangul alphabet was created by Sejong the Great in 1443. Understanding of the phonetic alphabet of Mongolian Phagspa script aided the creation of a phonetic script suited to the spoken Korean language. Mongolian Phagspa script was in turn derived from the Brahmi script. Hangul is a unique alphabet in a variety of ways: it is a featural alphabet, where many of the letters are designed from a sound's place of articulation (P to look like widened mouth, L sound to look like tongue pulled in, etc.); its design was planned by the government of the time; and it places individual letters in syllable clusters with equal dimensions, in the same way as Chinese characters, to allow for mixed script writing (one syllable always takes up one type-space no matter how many letters get stacked into building that one sound-block).
Zhuyin (sometimes called "Bopomofo") is a semi-syllabary used to phonetically transcribe Mandarin Chinese in the Republic of China. After the later establishment of the People's Republic of China and its adoption of Hanyu Pinyin, the use of Zhuyin today is limited, but it's still widely used in Taiwan where the Republic of China still governs. Zhuyin developed out of a form of Chinese shorthand based on Chinese characters in the early 1900s and has elements of both an alphabet and a syllabary. Like an alphabet the phonemes of syllable initials are represented by individual symbols, but like a syllabary the phonemes of the syllable finals are not; rather, each possible final (excluding the medial glide) is represented by its own symbol. For example, "luan" is represented as ㄌㄨㄢ ("l-u-an"), where the last symbol ㄢ represents the entire final "-an". While Zhuyin is not used as a mainstream writing system, it is still often used in ways similar to a romanization system that is, for aiding in pronunciation and as an input method for Chinese characters on computers and cell phones.
European alphabets, especially Latin and Cyrillic, have been adapted for many languages of Asia. Arabic is also widely used, sometimes as an abjad (as with Urdu and Persian) and sometimes as a complete alphabet (as with Kurdish and Uyghur)
Types.
The term "alphabet" is used by linguists and paleographers in both a wide and a narrow sense. In the wider sense, an alphabet is a script that is "segmental" at the phoneme level that is, it has separate glyphs for individual sounds and not for larger units such as syllables or words. In the narrower sense, some scholars distinguish "true" alphabets from two other types of segmental script, abjads and abugidas. These three differ from each other in the way they treat vowels: abjads have letters for consonants and leave most vowels unexpressed; abugidas are also consonant-based, but indicate vowels with diacritics to or a systematic graphic modification of the consonants. In alphabets in the narrow sense, on the other hand, consonants and vowels are written as independent letters. The earliest known alphabet in the wider sense is the Wadi el-Hol script, believed to be an abjad, which through its successor Phoenician is the ancestor of modern alphabets, including Arabic, Greek, Latin (via the Old Italic alphabet), Cyrillic (via the Greek alphabet) and Hebrew (via Aramaic).
Examples of present-day abjads are the Arabic and Hebrew scripts; true alphabets include Latin, Cyrillic, and Korean hangul; and abugidas are used to write Tigrinya Amharic, Hindi, and Thai. The Canadian Aboriginal syllabics are also an abugida rather than a syllabary as their name would imply, since each glyph stands for a consonant which is modified by rotation to represent the following vowel. (In a true syllabary, each consonant-vowel combination would be represented by a separate glyph.)
The boundaries between the three types of segmental scripts are not always clear-cut. For example, Sorani Kurdish is written in the Arabic script, which is normally an abjad. However, in Kurdish, writing the vowels is mandatory, and full letters are used, so the script is a true alphabet. Other languages may use a Semitic abjad with mandatory vowel diacritics, effectively making them abugidas. On the other hand, the Phagspa script of the Mongol Empire was based closely on the Tibetan abugida, but all vowel marks were written after the preceding consonant rather than as diacritic marks. Although short "a" was not written, as in the Indic abugidas, one could argue that the linear arrangement made this a true alphabet. Conversely, the vowel marks of the Tigrinya abugida and the Amharic abugida (ironically, the original source of the term "abugida") have been so completely assimilated into their consonants that the modifications are no longer systematic and have to be learned as a syllabary rather than as a segmental script. Even more extreme, the Pahlavi abjad eventually became logographic. (See below.)
Thus the primary classification of alphabets reflects how they treat vowels. For tonal languages, further classification can be based on their treatment of tone, though names do not yet exist to distinguish the various types. Some alphabets disregard tone entirely, especially when it does not carry a heavy functional load, as in Somali and many other languages of Africa and the Americas. Such scripts are to tone what abjads are to vowels. Most commonly, tones are indicated with diacritics, the way vowels are treated in abugidas. This is the case for Vietnamese (a true alphabet) and Thai (an abugida). In Thai, tone is determined primarily by the choice of consonant, with diacritics for disambiguation. In the Pollard script, an abugida, vowels are indicated by diacritics, but the placement of the diacritic relative to the consonant is modified to indicate the tone. More rarely, a script may have separate letters for tones, as is the case for Hmong and Zhuang. For most of these scripts, regardless of whether letters or diacritics are used, the most common tone is not marked, just as the most common vowel is not marked in Indic abugidas; in Zhuyin not only is one of the tones unmarked, but there is a diacritic to indicate lack of tone, like the virama of Indic.
The number of letters in an alphabet can be quite small. The Book Pahlavi script, an abjad, had only twelve letters at one point, and may have had even fewer later on. Today the Rotokas alphabet has only twelve letters. (The Hawaiian alphabet is sometimes claimed to be as small, but it actually consists of 18 letters, including the ʻokina and five long vowels.) While Rotokas has a small alphabet because it has few phonemes to represent (just eleven), Book Pahlavi was small because many letters had been "conflated" that is, the graphic distinctions had been lost over time, and diacritics were not developed to compensate for this as they were in Arabic, another script that lost many of its distinct letter shapes. For example, a comma-shaped letter represented "g, d, y, k," or "j". However, such apparent simplifications can perversely make a script more complicated. In later Pahlavi papyri, up to half of the remaining graphic distinctions of these twelve letters were lost, and the script could no longer be read as a sequence of letters at all, but instead each word had to be learned as a whole that is, they had become logograms as in Egyptian Demotic.
The largest segmental script is probably an abugida, Devanagari. When written in Devanagari, Vedic Sanskrit has an alphabet of 53 letters, including the "visarga" mark for final aspiration and special letters for "kš" and "jñ," though one of the letters is theoretical and not actually used. The Hindi alphabet must represent both Sanskrit and modern vocabulary, and so has been expanded to 58 with the "khutma" letters (letters with a dot added) to represent sounds from Persian and English.
The largest known abjad is Sindhi, with 51 letters. The largest alphabets in the narrow sense include Kabardian and Abkhaz (for Cyrillic), with 58 and 56 letters, respectively, and Slovak (for the Latin alphabet), with 46. However, these scripts either count di- and tri-graphs as separate letters, as Spanish did with "ch" and "ll" until recently, or uses diacritics like Slovak "č". The largest true alphabet where each letter is graphically independent is probably Georgian, with 41 letters.
Syllabaries typically contain 50 to 400 glyphs (though the Múra-Pirahã language of Brazil would require only 24 if it did not denote tone, and Rotokas would require only 30), and the glyphs of logographic systems typically number from the many hundreds into the thousands. Thus a simple count of the number of distinct symbols is an important clue to the nature of an unknown script.
Alphabetic order.
It is not always clear what constitutes a distinct alphabet. French uses the same basic alphabet as English, but many of the letters can carry additional marks, such as é, à, and ô. In French, these combinations are not considered to be additional letters. However, in Icelandic, the accented letters such as á, í, and ö are considered to be distinct letters of the alphabet. In Spanish, ñ is considered a separate letter, but accented vowels such as á and é are not. The ll and ch were also considered single letters, distinct from a single l followed by an l and c followed by an h, respectively, but in 1994 the Real Academia Española changed them so that ll is between lk and lm in the dictionary and ch is between cg and ci.
In German, words starting with "sch-" (constituting the German phoneme /ʃ/) would be intercalated between words with initial "sca-" and "sci-" (all incidentally loanwords) instead of this graphic cluster appearing after the letter s, as though it were a single letter – a lexicographical policy which would be de rigueur in a dictionary of Albanian, i.e. "dh-", "gj-", "ll-", "rr-", "th-", "xh-" and "zh-" (all representing phonemes and considered separate single letters) would follow the letters d, g, l, n, r, t, x and z respectively. Nor is, in a dictionary of English, the lexical section with initial "th-" reserved a place after the letter t, but is inserted between "te-" and "ti-". German words with umlaut would further be alphabetized as if there were no umlaut at all – contrary to Turkish which allegedly adopted the Swedish graphemes ö and ü, and where a word like tüfek, "gun", would come after tuz, "salt", in the dictionary.
The Danish and Norwegian alphabets end with æ – ø – å, whereas the Swedish and the Finnish ones conventionally put å – ä – ö at the end.
Some adaptations of the Latin alphabet are augmented with ligatures, such as æ in Old English and Icelandic and Ȣ in Algonquian; by borrowings from other alphabets, such as the thorn þ in Old English and Icelandic, which came from the Futhark runes; and by modifying existing letters, such as the eth ð of Old English and Icelandic, which is a modified "d". Other alphabets only use a subset of the Latin alphabet, such as Hawaiian, and Italian, which uses the letters "j, k, x, y" and "w" only in foreign words.
It is unknown whether the earliest alphabets had a defined sequence. Some alphabets today, such as the Hanuno'o script, are learned one letter at a time, in no particular order, and are not used for collation where a definite order is required. However, a dozen Ugaritic tablets from the fourteenth century BC preserve the alphabet in two sequences. One, the "ABCDE" order later used in Phoenician, has continued with minor changes in Hebrew, Greek, Armenian, Gothic, Cyrillic, and Latin; the other, "HMĦLQ," was used in southern Arabia and is preserved today in Ethiopic. Both orders have therefore been stable for at least 3000 years.
The historical order was abandoned in Runic and Arabic, although Arabic retains the traditional "abjadi order" for numbering.
The Brahmic family of alphabets used in India use a unique order based on phonology: The letters are arranged according to how and where they are produced in the mouth. This organization is used in Southeast Asia, Tibet, Korean hangul, and even Japanese kana, which is not an alphabet.
The Phoenician letter names, in which each letter is associated with a word that begins with that sound, continue to be used in Samaritan, Aramaic, Syriac, Hebrew, and Greek. However, they were abandoned in Arabic, Cyrillic and Latin.
Orthography and spelling.
Each language may establish rules that govern the association between letters and phonemes, but, depending on the language, these rules may or may not be consistently followed. In a perfectly phonological alphabet, the phonemes and letters would correspond perfectly in two directions: a writer could predict the spelling of a word given its pronunciation, and a speaker could predict the pronunciation of a word given its spelling. However, languages often evolve independently of their writing systems, and writing systems have been borrowed for languages they were not designed for, so the degree to which letters of an alphabet correspond to phonemes of a language varies greatly from one language to another and even within a single language.
National languages generally elect to address the problem of dialects by simply associating the alphabet with the national standard. However, with an international language with wide variations in its dialects, such as English, it would be impossible to represent the language in all its variations with a single phonetic alphabet.
Some national languages like Finnish, Turkish and Bulgarian have a very regular spelling system with a nearly one-to-one correspondence between letters and phonemes. Strictly speaking, there is no word in the Finnish, Turkish and Bulgarian languages corresponding to the verb "to spell" (meaning to split a word into its letters), the closest match being a verb meaning to split a word into its syllables. Similarly, the Italian verb corresponding to 'spell', "compitare", is unknown to many Italians because the act of spelling itself is almost never needed: each phoneme of Standard Italian is represented in only one way. However, pronunciation cannot always be predicted from spelling in cases of irregular syllabic stress. In standard Spanish, it is possible to tell the pronunciation of a word from its spelling, but not vice versa; this is because certain phonemes can be represented in more than one way, but a given letter is consistently pronounced. French, with its silent letters and its heavy use of nasal vowels and elision, may seem to lack much correspondence between spelling and pronunciation, but its rules on pronunciation are actually consistent and predictable with a fair degree of accuracy.
At the other extreme, are languages such as English, where the spelling of many words simply has to be memorized as they do not correspond to sounds in a consistent way. For English, this is partly because the Great Vowel Shift occurred after the orthography was established, and because English has acquired a large number of loanwords at different times, retaining their original spelling at varying levels. Even English has general, albeit complex, rules that predict pronunciation from spelling, and these rules are successful most of the time; rules to predict spelling from the pronunciation have a higher failure rate.
Sometimes, countries have the written language undergo a spelling reform to realign the writing with the contemporary spoken language. These can range from simple spelling changes and word forms to switching the entire writing system itself, as when Turkey switched from the Arabic alphabet to the Roman alphabet.
The sounds of speech of all languages of the world can be written by a rather small universal phonetic alphabet. A standard for this is the International Phonetic Alphabet.
---END.OF.DOCUMENT---
Atomic number.
In chemistry and physics, the atomic number (also known as the proton number) is the number of protons found in the nucleus of an atom and therefore identical to the charge number of the nucleus. It is conventionally represented by the symbol "Z". The atomic number uniquely identifies a chemical element. In an atom of neutral charge, the atomic number is also equal to the number of electrons.
The atomic number, "Z", should not be confused with the mass number, "A", which is the total number of protons and neutrons in the nucleus of an atom. The number of neutrons, "N", is known as the neutron number of the atom; thus, "A" = "Z" + "N". Since protons and neutrons have approximately the same mass (and the mass of the electrons is negligible for many purposes), the atomic mass of an atom is roughly equal to "A".
Atoms having the same atomic number Z but different neutron number "N", and hence different atomic mass, are known as isotopes. Most naturally occurring elements exist as a mixture of isotopes, and the average atomic mass of this mixture determines the element's atomic weight. The current standard for the atomic mass unit (amu), also termed the dalton (Da) is defined to be exactly of the mass of a free (unbound) neutral atom in its ground (lowest-energy) state.
History.
Loosely speaking, the existence of a periodic table creates an ordering for the elements. Such an ordering is not necessarily a numbering, but can be used to construct a numbering by fiat.
Dmitri Mendeleev claimed he arranged his tables in order of atomic weight ("Atomgewicht") However, in deference to the observed chemical properties, he violated his own rule and placed tellurium (atomic weight 127.6) ahead of iodine (atomic weight 126.9). This placement is consistent with the modern practice of ordering the elements by proton number, "Z", but this number was not known or suspected at the time.
A simple numbering based on periodic table position was never entirely satisfactory. Besides iodine and tellurium, several other pairs of elements (such as cobalt and nickel) were known to have nearly identical or reversed atomic weights, leaving their placement in the periodic table by chemical properties to be in violation of known physical properties. Another problem was that the gradual identification of more and more chemically similar and indistinguishable lanthanides, which were of an uncertain number, led to inconsistency and uncertainty in the numbering of all elements at least from lutetium (element 71) onwards (hafnium was not known at this time).
In 1911 Ernest Rutherford gave a model of the atom in which a central core held most of the atom's mass and a positive charge which, in units of the electron's charge, was to be approximately equal to half of the atom's atomic weight, expressed in numbers of hydrogen atoms. This central charge would thus be approximately half the atomic weight (though it was almost 25% off the figure for the atomic number in gold (Z=79, A=197), the single element from which Rutherford made his guess). Nevertheless, in spite of Rutherford's estimation that gold had a central charge of about 100 (but was element Z=79 on the periodic table), a month after Rutherford's paper appeared, Antonius van den Broek first formally suggested that the central charge and number of electrons in an atom was "exactly" equal to its place in the periodic table (also known as element number, atomic number, and symbolized Z). This proved eventually to be the case.
The experimental situation improved dramatically after research by Henry Moseley in 1913. Moseley, after discussions with Bohr who was at the same lab (and who had used Van den Broek's hypothesis in his Bohr model of the atom), decided to test Van den Broek and Bohr's hypothesis directly, by seeing if spectral lines emitted from excited atoms fit the Bohr theory's demand that the frequency of the spectral lines be proportional to a measure of the square of Z.
To do this, Moseley measured the wavelengths of the innermost photon transitions (K and L lines) produced by the elements from aluminum (Z=13) to gold (Z= 79) used as a series of movable anodic targets inside an x-ray tube. The square root of the frequency of these photons (x-rays) increased from one target to the next in a linear fashion. This led to the conclusion (Moseley's law) that the atomic number does closely correspond (with an offset of one unit for K-lines, in Moseley's work) to the calculated electric charge of the nucleus, i.e. the proton number "Z". Among other things, Moseley demonstrated that the lanthanide series (from lanthanum to lutetium inclusive) must have 15 members — no fewer and no more — which was far from obvious from the chemistry at that time.
The conventional symbol Z presumably comes from the German word "Atomz'"ahl" (atomic number).
Chemical properties.
Each element has a specific set of chemical properties as a consequence of the number of electrons present in the neutral atom, which is "Z". The configuration of these electrons follows from the principles of quantum mechanics. The number of electrons in each element's electron shells, particularly the outermost valence shell, is the primary factor in determining its chemical bonding behavior. Hence it is the atomic number alone that determines the chemical properties of an element; and it is for this reason that an element can be defined as consisting of "any" mixture of atoms with a given atomic number.
New elements.
The quest for new elements is usually described using atomic numbers. As of early 2007, elements with atomic numbers 1 to 116 and 118 have been observed. Synthesis of new elements is accomplished by bombarding target atoms of heavy elements with ions, such that the sum of the atomic numbers of the target and ion elements equals the atomic number of the element being created. In general, the half-life becomes shorter as atomic number increases, though an "island of stability" may exist for undiscovered isotopes with certain numbers of protons and neutrons.
---END.OF.DOCUMENT---
Anatomy.
Anatomy (from the Greek " anatomia", from " ana: separate, apart from, and temnein", to cut up, cut open. Also from the Greek word "anatome"--ana: apart, tome: to cut-->To cut apart.) is a branch of biology and medicine that is the consideration of the structure of living things. It is a general term that includes human anatomy, animal anatomy (zootomy) and plant anatomy (phytotomy). In some of its facets anatomy is closely related to embryology, comparative anatomy and comparative embryology, through common roots in evolution.
Anatomy is subdivided into gross anatomy (or macroscopic anatomy) and microscopic anatomy. Gross anatomy (also called topographical anatomy, regional anatomy, or anthropotomy) is the study of anatomical structures that can be seen by unaided vision with the naked eye. Microscopic anatomy is the study of minute anatomical structures assisted with microscopes, which includes histology (the study of the organization of tissues), and cytology (the study of cells).
The history of anatomy has been characterized, over time, by a continually developing understanding of the functions of organs and structures in the body. Methods have also improved dramatically, advancing from examination of animals through dissection of cadavers (dead human bodies) to technologically complex techniques developed in the 20th century including X-ray, ultrasound, and MRI imaging.
Anatomy should not be confused with anatomical pathology (also called morbid anatomy or histopathology), which is the study of the gross and microscopic appearances of diseased organs.
Superficial anatomy.
Superficial anatomy or surface anatomy is important in anatomy being the study of anatomical landmarks that can be readily seen from the contours or the surface of the body. With knowledge of superficial anatomy, physicians or veterinary surgeons gauge the position and anatomy of the associated deeper structures.
Human anatomy.
Human anatomy, including gross human anatomy and histology, is primarily the scientific study of the morphology of the adult human body.
Generally, students of certain biological sciences, paramedics, physiotherapists, occupational therapy, nurses, and medical students learn gross anatomy and microscopic anatomy from anatomical models, skeletons, textbooks, diagrams, photographs, lectures and tutorials. The study of microscopic anatomy (or histology) can be aided by practical experience examining histological preparations (or slides) under a microscope; and in addition, medical students generally also learn gross anatomy with practical experience of dissection and inspection of cadavers (dead human bodies).
Human anatomy, physiology and biochemistry are complementary basic medical sciences, which are generally taught to medical students in their first year at medical school. Human anatomy can be taught regionally or systemically; that is, respectively, studying anatomy by bodily regions such as the head and chest, or studying by specific systems, such as the nervous or respiratory systems. The major anatomy textbook, Gray's Anatomy, has recently been reorganized from a systems format to a regional format, in line with modern teaching methods. A thorough working knowledge of anatomy is required by all medical doctors, especially surgeons, and doctors working in some diagnostic specialities, such as histopathology and radiology.
Academic human anatomists are usually employed by universities, medical schools or teaching hospitals. They are often involved in teaching anatomy, and research into certain systems, organs, tissues or cells.
---END.OF.DOCUMENT---
Affirming the consequent.
An argument of this form is invalid, i.e., the conclusion can be false even when statements 1 and 2 are true. Since "P" was never asserted as the "only" sufficient condition for "Q", other factors could account for "Q" (while "P" was false).
The name "affirming the consequent" derives from the premise "Q", which affirms the "then" clause of the conditional premise.
Owning Fort Knox is not the "only" way to be rich. There are any number of other ways to be rich.
But having the flu is not the "only" cause of a sore throat since many illnesses cause sore throat, such as the common cold or strep throat.
The following is a more subtle version of the fallacy embedded into conversation.
B attempts to falsify A's conditional statement ("if Republican then pro-life") by providing evidence he believes would contradict its implication. However, B's example of his uncle does not contradict A's statement, which says nothing about non-Republicans. What would be needed to disprove A's assertion are examples of Republicans who are not pro-life.
Tautologies.
If claims "P" and "Q" express the same proposition, then the argument would be trivially valid, as it would beg the question.
This is also the case for definitions. For example.
In everyday discourse, however, such cases are rare. The validity of such definitions is due to the fact that definitions can be expressed as an if and only if (see below).
Clearly if the definition of "bachelor" is "an unmarried male", then the propositional statement: "A is a bachelor" if and only if "A is an unmarried male", must be true.
In normal speech it is awkward to use the phrase "if and only if", so we substitute the valid but less complete "if", giving the conventional form which is similar to the form of the formal fallacy.
If and only if.
The above argument may be valid, but only if the claim "if he's outside, then he's not inside" follows from the first premise. More to the point, the validity of the argument stems not from affirming the consequent, but affirming the antecedent.
Such if and only if statements often make their way into detective mysteries.
Use of the fallacy in science.
However, such reasoning is still affirming the consequent and logically invalid (e.g., Let "P" = geocentrism and "Q" = sunrise and sunset.) The strength of such reasoning as an inductive inference depends on the likelihood of alternative hypotheses, which shows that such reasoning is based on additional premises, not merely on affirming the consequent.
In addition, testing scientific theories involves repeated rounds of affirming the consequent as new data come in. The repetitive use eliminates competing theories (those that are inconsistent with the newest data: more technically, it is the law of contraposition that plays the role in elimination), leaving behind only theories that have proved to be consistent with all tests performed to date.
---END.OF.DOCUMENT---
Andrei Tarkovsky.
Andrei Arsenyevich Tarkovsky () (April 4, 1932–December 29, 1986) was a Soviet and Russian filmmaker, writer, film editor, film theorist and opera director.
Tarkovsky's films include "Andrei Rublev", "Solaris", "The Mirror", and "Stalker". He directed the first five of his seven feature films in the Soviet Union; his last two films were produced in Italy and Sweden. They are characterized by spirituality and metaphysical themes, extremely long takes, lack of conventional dramatic structure and plot, and memorable cinematography.
Ingmar Bergman said of him: "Tarkovsky for me is the greatest [director], the one who invented a new language, true to the nature of film, as it captures life as a reflection, life as a dream".
Childhood and early life.
Tarkovsky was born in the village of Zavrazhye in Ivanovo Oblast, the son of poet and translator Arseny Alexandrovich Tarkovsky, native of Kirovohrad, Ukraine, and Maria Ivanova Vishnyakova, a graduate of the Maxim Gorky Literature Institute.
Tarkovsky spent his childhood in Yuryevets. He was described by childhood friends as active and popular, having many friends and being typically in the center of action. In 1937, his father left the family, subsequently volunteering for the army in 1941. Tarkovsky stayed with his mother, moving with her and his sister Marina to Moscow, where she worked as a proofreader at a printing press. In 1939, Tarkovsky enrolled at the Moscow School № 554. During the war, the three evacuated to Yuryevets, living with his maternal grandmother. In 1943, the family returned to Moscow. Tarkovsky continued his studies at his old school, where the poet Andrey Voznesensky was one of his classmates. He learned the piano at a music school and attended classes at an art school. The family lived on Shshipok Street in the Zamoskvorechye District in Moscow. From November 1947 to spring 1948, he was in a hospital with tuberculosis. Many themes of his childhood - the evacuation, his mother and her two children, the withdrawn father, the time in the hospital - feature prominently in his film "The Mirror".
Following high school graduation, from 1951 to 1952, Tarkovsky studied Arabic at the Oriental Institute in Moscow, a branch of the Academy of Sciences of the USSR. Although he already spoke some Arabic and was a successful student in his first semesters, he did not finish his studies and dropped out to work as a prospector for the Academy of Science Institute for Non-Ferrous Metals and Gold. He participated in a year-long research expedition to the river Kureikye near Turukhansk in the Krasnoyarsk Province. During this time in the Taiga Tarkovsky decided to study film.
Film school student.
Upon return from the research expedition in 1954, Tarkovsky applied at the State Institute of Cinematography (VGIK) and was admitted to the film-directing-program. He was in the same class as Irma Raush, whom he married in April 1957.
The early Khrushchev era offered unique opportunities for young film directors. Before 1953, annual film production was low and most films were directed by veteran directors. After 1953, more films were produced, many of them by young directors. The Khrushchev Thaw opened Soviet society and allowed, to some degree, Western literature, films and music. This allowed Tarkovsky to see films of the Italian neorealists, French New Wave, and of directors such as Kurosawa, Buñuel, Bergman, Bresson and Mizoguchi. Tarkovsky absorbed the idea of the auteur as a necessary condition for creativity.
Tarkovsky’s teacher and mentor was Mikhail Romm, who taught many film students who would later become influential film directors. In 1956, Tarkovsky directed his first student short film, "The Killers", from a short story of Ernest Hemingway. The short film "There Will Be No Leave Today" and the screenplay "Concentrate" followed in 1958 and 1959.
An important influence on Tarkovsky was the film director Grigori Chukhrai, who was teaching at the VGIK. Impressed by the talent of his student, Chukhrai offered Tarkovsky a position as assistant director for his film "Clear Skies". Tarkovsky initially showed interest, but then decided to concentrate on his studies and his own projects.
During his third year at the VGIK, Tarkovsky met Andrei Konchalovsky. They found much in common as they liked the same film directors and shared ideas on cinema and films. In 1959, they wrote the script "Antarctica - Distant Country", which was later published in the "Moskovskij Komsomolets". Tarkovsky submitted the script to Lenfilm, which was rejected. They were more successful with the script "The Steamroller and the Violin," which they sold to Mosfilm. This film became Tarkovsky’s diploma film, earning him his diploma in 1960 and winning first prize at the New York Student Film Festival in 1961.
Film career in the Soviet Union.
Tarkovsky's first feature film was "Ivan's Childhood" in 1962. He had inherited the film from director Eduard Abalov, who had to abort the project. The film earned Tarkovsky international acclaim and won the Golden Lion award at the Venice Film Festival in 1962. In the same year, on September 30, his first son Arseny (called Senka in Tarkovsky's diaries) Tarkovsky was born.
In 1965, he directed the film "Andrei Rublev" about the life of Andrei Rublev, the 15th century Russian icon painter. "Andrei Rublev" was not immediately released after completion due to problems with Soviet authorities. Tarkovsky had to cut the film several times, resulting in several different versions of varying lengths. A version of the film was presented at the Cannes Film Festival in 1969 and won the FIPRESCI prize. The film was officially released in the Soviet Union in a cut version in 1971.
He divorced his wife, Irma Raush, in June 1970. In the same year, he married Larissa Kizilova (née Egorkina), who had been a production assistant for the film "Andrei Rublev" (they had been living together since 1965). Their son, Andrei Tarkovsky Jr., was born in the same year on August 7.
In 1972, he completed "Solaris", an adaptation of the novel "Solaris" by Stanisław Lem. He had worked on this together with screenwriter Fridrikh Gorenshtein, as early as 1968. The film was presented at the Cannes Film Festival and won the Grand Prix Spécial du Jury and the FIPRESCI prize and was nominated for the Palme d'Or. From 1973 to 1974, he shot the film "The Mirror", a highly autobiographical film drawing on his childhood and incorporating some of his father's poems. Tarkovsky had worked on the screenplay for this film since 1967, under the consecutive titles "Confession", "White day" and "A white, white day". From the beginning the film was not well received by Soviet authorities due to its content and its perceived elitist nature. Russian authorities placed the film in the "third category" which meant severe limitations on its distribution, allowing it to be shown only in third class cinemas and workers' clubs. Few prints were made and the filmmakers received no returns. Third category films also placed the filmmakers in danger of being accused of wasting public funds, which could have serious effects on their future productivity. These difficulties are presumed to have made Tarkovsky play with the idea of going abroad and producing a film outside the Soviet film industry.
During 1975, Tarkovsky also worked on the screenplay "Hoffmanniana", about the German writer and poet E. T. A. Hoffmann. In December 1976, he directed "Hamlet", his only stage play, at the Lenkom Theatre in Moscow. The main role was played by Anatoly Solonitsyn, who also acted in several of Tarkovsky's films. At the end of 1978, he also wrote the screenplay "Sardor" together with the writer Aleksandr Misharin.
The last film Tarkovsky completed in the Soviet Union was "Stalker", inspired by the novel "Roadside Picnic" by the brothers Arkady and Boris Strugatsky. Tarkovsky had met the brothers first in 1971 and was in contact with them until his death in 1986. Initially he wanted to shoot a film based on their novel "Dead Mountaineer's Hotel" and he developed a raw script. Influenced by a discussion with Arkady Strugatsky he changed his plan and began to work on the script based on "Roadside Picnic". Work on this film began in 1976. The production was mired in troubles; improper development of the negatives had ruined all the exterior shots. Tarkovsky's relationship with cinematographer Georgy Rerberg deteriorated to the point where Tarkovsky hired Alexander Knyazhinsky as a new first cinematographer. Furthermore, Tarkovsky suffered a heart attack in April 1978, resulting in further delay. The film was completed in 1979 and won the Prize of the Ecumenical Jury at the Cannes Film Festival.
In the same year Tarkovsky also began the production of the film "The First Day" (Russian: Pervyy Dyen), based on a script by his friend and longterm collaborator Andrei Konchalovsky. The film was set in 18th century Russia during the reign of Peter the Great and starred Natalya Bondarchuk and Anatoli Papanov in the main role. To get the project approved by Goskino, Tarkovsky submitted a script that was different from the original script, leaving out several scenes that were critical of the official atheism in the Soviet Union. After finishing shooting of roughly one half of the film, the project was stopped by Goskino, after it became apparent that the film differed from the script submitted to the censors. Tarkovsky was reportedly infuriated by this interruption and destroyed most of the film.
Film career outside the Soviet Union.
During the summer of 1979, Tarkovsky traveled to Italy, where he shot the documentary "Voyage in Time", together with his longtime friend Tonino Guerra. Tarkovsky returned to Italy in 1980 for an extended trip during which he and Tonino Guerra completed the script for the film "Nostalghia". During 1981 he traveled to the United Kingdom and Sweden. During his trip to Sweden he had considered defecting from the Soviet Union, but ultimately decided to return because of his wife and his son.
Tarkovsky returned to Italy in 1982 to start shooting "Nostalghia". He did not return to his home country. As Mosfilm withdrew from the project, he had to complete the film with financial support provided by the Italian RAI. Tarkovsky completed the film in 1983. "Nostalghia" was presented at the Cannes Film Festival and won the Grand Prix Spécial du Jury, the FIPRESCI prize and the Prize of the Ecumenical Jury. Soviet authorities prevented the film from winning the Palme d'Or, a fact that hardened Tarkovsky's resolve to never work in the Soviet Union again. In the same year, he also arranged the opera "Boris Godunov" at the Royal Opera House in London under the musical direction of Claudio Abbado.
He spent most of 1984 preparing the film "The Sacrifice". At a press conference in Milan on July 10, 1984, he announced that he would never return to the Soviet Union and would remain in the West. At that time, his son Andrei Jr. was still in the Soviet Union and not allowed to leave the country.
During 1985, he shot the film "The Sacrifice" in Sweden. At the end of the year he was diagnosed with terminal lung cancer. In January 1986, he began treatment in Paris, and was joined there by his wife and his son, who were finally allowed to leave the Soviet Union. "The Sacrifice" was presented at the Cannes Film Festival and received the Grand Prix Spécial du Jury, the FIPRESCI prize and the Prize of the Ecumenical Jury. As Tarkovsky was unable to attend due to his illness, the prizes were collected by his son, Andrei Jr.
In Tarkovsky's last diary entry (December 15, 1986), he wrote: "But now I have no strength left - that is the problem". The diaries are sometimes also known as "Martyrolog" and were published posthumously in 1989 and in English in 1991.
Tarkovsky died in Paris on December 29, 1986. He was buried on January 3, 1987 in the Russian Cemetery in Sainte-Geneviève-des-Bois in France. The inscription on his grave stone, which was created by the Russian sculptor Ernst Neizvestny, reads: "To the man who saw the Angel".
A controversy emerged in Russia in the early 1990s when it was alleged that Tarkovsky did not die of natural causes, but was assassinated by the KGB. Evidence for this hypothesis includes several testimonies by former KGB agents, who claim that Viktor Chebrikov gave the order to irradiate Tarkovsky to prevent what the Soviet government and the KGB saw as anti-Soviet propaganda by Tarkovsky. Other evidence includes several memos that surfaced after the 1991 coup and the claim by one of Tarkovsky's doctors that his cancer could not have developed from a natural cause.
As Tarkovsky, his wife Larisa Tarkovskaya and actor Anatoli Solonitsyn all died from the very same type of lung cancer, Vladimir Sharun, sound designer in "Stalker", is convinced that they were all poisoned when shooting the film near a chemical plant.
Filmography.
Tarkovsky is mainly known as a director of films. During his career he directed only seven feature films, and three short films during his time at the film school. He also wrote several screenplays, directed the play "Hamlet" for the stage in Moscow, the opera "Boris Godunov" in London, and directed a radio production of the short story "Turnabout" by William Faulkner. He also wrote "Sculpting In Time", a book on film theory.
Tarkovsky's first feature film was "Ivan's Childhood" in 1962. He then directed in the Soviet Union "Andrei Rublev" in 1966, "Solaris" in 1972, "The Mirror" in 1975 and "Stalker" in 1979. The documentary "Voyage in Time" was produced in Italy in 1982, as was "Nostalghia" in 1983. His last film "The Sacrifice" was produced in Sweden in 1986. Tarkovsky was personally involved in writing the screenplays for all his films, sometimes with a co-writer. To Tarkovsky a director who realizes somebody else's screenplay without being involved in it becomes a mere illustrator, resulting in dead and monotonous films.
Awards.
Numerous awards were bestowed on Tarkovsky throughout his lifetime. At the Venice Film Festival he was awarded the "Golden Lion". At the Cannes Film Festival he won several times the "FIPRESCI prize", the "Prize of the Ecumenical Jury" and the "Grand Prix Spécial du Jury". He was also nominated for the "Palme d'Or" two times. In 1987, the British Academy of Film and Television Arts awarded the BAFTA Award for Best Foreign Language Film to "The Sacrifice".
Under the influence of Glasnost and Perestroika, Tarkovsky was finally recognized in the Soviet Union in the fall of 1986, shortly before his death, by a retrospective of his films in Moscow. After his death, an entire issue of the film magazine "Iskusstvo Kino" was devoted to Tarkovsky. In their obituaries, the film committee of the Council of Ministers of the USSR and the Union of Soviet Film Makers expressed their sorrow that Tarkovsky had to spend the last years of his life in exile.
Posthumously, he was awarded the Lenin Prize in 1990, one of the highest state honors in the Soviet Union. In 1989 the "Andrei Tarkovsky Memorial Prize" was established, with its first recipient being the Russian animator Yuriy Norshteyn. Since 1993, the Moscow International Film Festival awards the annual "Andrei Tarkovsky Award". In 1996 the Andrei Tarkovsky Museum opened in Yuryevets, his childhood town. A minor planet, 3345 Tarkovskij, discovered by Soviet astronomer Lyudmila Georgievna Karachkina in 1982, has also been named after him.
Tarkovsky has been the subject of several documentaries. Most notable is the 1988 documentary "Moscow Elegy", by Russian film director Alexander Sokurov. Sokurov's own work has been heavily influenced by Tarkovsky. The film consists mostly of narration over stock footage from Tarkovsky's films. "Directed by Andrei Tarkovsky" is 1988 documentary film by Michal Leszczylowski, an editor of the film "The Sacrifice". Film director Chris Marker produced the television documentary "One Day in the Life of Andrei Arsenevich" as an homage to Andrei Tarkovsky in 2000.
Tarkovsky is widely considered to be one of the greatest film makers of all time. Ingmar Bergman was quoted as saying: "Tarkovsky for me is the greatest [of us all], the one who invented a new language, true to the nature of film, as it captures life as a reflection, life as a dream". Film historian Steven Dillon claims that much of subsequent film was deeply influenced by the films of Tarkovsky.
Influences.
Tarkovsky became a film director during the mid and late 1950s, a period during which Soviet society opened to foreign films, literature and music. This allowed Tarkovsky to see films of European, American and Japanese directors, an experience which influenced his own film making. His teacher and mentor at the film school, Mikhail Romm, allowed his students considerable freedom and emphasized the independence of the film director.
Tarkovsky was, according to Shavka Abdusalmov, a fellow student at the film school, fascinated by Japanese films. He was amazed by how every character on the screen is exceptional and how everyday events such as a Samurai cutting bread with his sword are elevated to something special and put into the limelight. Tarkovsky has also expressed interest in the art of Haiku and its ability to create “images in such a way that they mean nothing beyond themselves.”
In 1972, Tarkovsky told film historian Leonid Kozlov his ten favorite films. The list includes: "Diary of a Country Priest" and "Mouchette", by Robert Bresson; "Winter Light", "Wild Strawberries" and "Persona", by Ingmar Bergman; "Nazarin", by Luis Buñuel; "City Lights", by Charlie Chaplin; "Ugetsu", by Kenji Mizoguchi; "Seven Samurai", by Akira Kurosawa, and "Woman in the Dunes", by Hiroshi Teshigahara. Among his favorite directors were Luis Buñuel, Kenji Mizoguchi, Ingmar Bergman, Robert Bresson, Akira Kurosawa, Michelangelo Antonioni, Jean Vigo and Carl Theodor Dreyer.
With the exception of "City Lights", the list does not contain any films of the early silent era. The reason is that Tarkovsky saw film as an art as only a relatively recent phenomenon, with the early film-making forming only a prelude. The list has also no films or directors from Tarkovsky's native Russia, although he rated Soviet directors such as Boris Barnet, Sergei Paradjanov and Alexander Dovzhenko highly.
Although strongly opposed to commercial cinema, in a famous exception Tarkovsky praised the blockbuster film "The Terminator", saying its "vision of the future and the relation between man and its destiny is pushing the frontier of cinema as an art". He was critical of the "brutality and low acting skills", but nevertheless impressed by this film.
Cinematic style.
Tarkovsky's films are characterised by Christian and metaphysical themes, extremely long takes, and memorable images of exceptional beauty. Recurring motifs are dreams, memory, childhood, running water accompanied by fire, rain indoors, reflections, levitation, and characters re-appearing in the foreground of long panning movements of the camera.
Tarkovsky included levitation scenes into several of his films, most notably "Solaris". To him these scenes possess great power and are used for their photogenic value and magical inexplicability.
Water, clouds, and reflections were used by him for its surreal beauty and photogenic value, as well as its symbolism, such as waves or the form of brooks or running water.
Bells and candles are also frequent symbols. These are symbols of film, sight and sound, and Tarkovsky's film frequently has themes of self reflection.
Tarkovsky developed a theory of cinema that he called "sculpting in time". By this he meant that the unique characteristic of cinema as a medium was to take our experience of time and alter it. Unedited movie footage transcribes time in real time. By using long takes and few cuts in his films, he aimed to give the viewers a sense of time passing, time lost, and the relationship of one moment in time to another.
Up to, and including, his film "The Mirror", Tarkovsky focused his cinematic works on exploring this theory. After "The Mirror", he announced that he would focus his work on exploring the dramatic unities proposed by Aristotle: a concentrated action, happening in one place, within the span of a single day.
Several of Tarkovsky's films have color or black and white sequences, including for example "Andrei Rublev" which features an epilogue in color of religious icon paintings, as well as "Solaris", "The Mirror", and "Stalker", which feature monochrome and sepia sequences while otherwise being in color. In 1966, in an interview conducted shortly after finishing "Andrei Rublev", Tarkovsky dismissed color film as a "commercial gimmick" and cast doubt on the idea that contemporary films meaningfully use color. He claimed that in everyday life one does not consciously notice colors most of the time. Hence in film color should be used mainly to emphasize certain moments, but not all the time as this distracts the viewer. To him, films in color are like moving paintings or photographs, which are too beautiful to be a realistic depiction of life.
The natural elements play a large role in Tarkovsky's films. The soundtracks often contain the sounds of water dripping while the earth seems to be perpetually damp. Fire and water are usually represented together, the burning barn from "The Mirror" and candle in "Nostalghia" being two examples. "The Mirror", "Stalker", and "Nostalghia" all contain scenes in which one or several characters lay on the earth in contemplation. Wind is also used often in "The Mirror". This emphasis of moments in nature, as well as the theory of "sculpting in time" has been cited by the remodernist film movement as a major influence on their own ideas on filmmaking.
---END.OF.DOCUMENT---
Ambiguity.
Ambiguity is the property of being ambiguous, where a word, term, notation, sign, symbol, phrase, sentence, or any other form used for communication, is called ambiguous if it can be interpreted in more than one way. Ambiguity is different from vagueness, which arises when the boundaries of meaning are indistinct. Ambiguity is context-dependent: the same linguistic item (be it a word, phrase, or sentence) may be ambiguous in one context and unambiguous in another context. For a word, ambiguity typically refers to an unclear choice between different definitions as may be found in a dictionary. A sentence may be ambiguous due to different ways of parsing the same sequence of words.
Linguistic forms.
The lexical ambiguity of a word or phrase consists in its having more than one meaning in the language to which the word belongs. "Meaning" hereby refers to whatever should be captured by a good dictionary. For instance, the word “bank” has several distinct lexical definitions, including “financial institution” and “edge of a river”. Another example is as in apothecary. You could say "I bought herbs from the apothecary." This could mean you actually spoke to the apothecary (pharmacist) or went to the apothecary (drug store).
The context in which an ambiguous word is used often makes it evident which of the meanings is intended. If, for instance, someone says “I deposited $100 in the bank,” most people would not think you used a shovel to dig in the mud.
However, some linguistic contexts do not provide sufficient information to disambiguate a used word. For example, "Biweekly" can mean "fortnightly" (once every two weeks - 26 times a year), OR "twice a week" (104 times a year). If "biweekly" is used in a conversation about a meeting schedule, it may be difficult to infer which meaning was intended.
Many people believe that such lexically ambiguous, miscommunication-prone words should be avoided wherever possible, since the user generally has to waste time, effort, and attention span to define what is meant when they are used.
The use of multi-defined words requires the author or speaker to clarify their context, and sometimes elaborate on their specific intended meaning (in which case, a less ambiguous term should have been used). The goal of clear concise communication is that the receiver(s) have no misunderstanding about what was meant to be conveyed. An exception to this could include a politician whose "wiggle words" and obfuscation are necessary to gain support from multiple constituents with mutually exclusive conflicting desires from their candidate of choice. Ambiguity is a powerful tool of political science.
More problematic are words whose senses express closely related concepts. “Good,” for example, can mean “useful” or “functional” ("That’s a good hammer"), “exemplary” ("She’s a good student"), “pleasing” ("This is good soup"), “moral” ("a good person" versus "the lesson to be learned from a story"), "righteous", etc. “I have a good daughter” is not clear about which sense is intended. The various ways to apply prefixes and suffixes can also create ambiguity (“unlockable” can mean “capable of being unlocked” or “impossible to lock”).
Syntactic ambiguity arises when a complex phrase or a sentence can be parsed in more than one way. “He ate the cookies on the couch,” for example, could mean that he ate those cookies which were on the couch (as opposed to those that were on the table), or it could mean that he was sitting on the couch when he ate the cookies.
Spoken language can contain many more types of ambiguities, where there is more than one way to compose a set of sounds into words, for example “ice cream” and “I scream.” Such ambiguity is generally resolved according to the context. A mishearing of such, based on incorrectly resolved ambiguity, is called a mondegreen.
Semantic ambiguity arises when a word or concept has an inherently diffuse meaning based on widespread or informal usage. This is often the case, for example, with idiomatic expressions whose definitions are rarely or never well-defined, and are presented in the context of a larger argument that invites a conclusion.
For example, “You could do with a new automobile. How about a test drive?” The clause “You could do with” presents a statement with such wide possible interpretation as to be essentially meaningless. Lexical ambiguity is contrasted with semantic ambiguity. The former represents a choice between a finite number of known and meaningful context-dependent interpretations. The latter represents a choice between any number of possible interpretations, none of which may have a standard agreed-upon meaning. This form of ambiguity is closely related to vagueness.
Linguistic ambiguity can be a problem in law (see Ambiguity (law)), because the interpretation of written documents and oral agreements is often of paramount importance.
Intentional application.
Philosophers (and other users of logic) spend a lot of time and effort searching for and removing (or intentionally adding) ambiguity in arguments, because it can lead to incorrect conclusions and can be used to deliberately conceal bad arguments. For example, a politician might say “I oppose taxes that hinder economic growth.” Some will think he opposes taxes in general, because they hinder economic growth. Others may think he opposes only those taxes that he believes will hinder economic growth. In writing, the correct insertion or omission of a comma after “taxes” and the use of "which" can help reduce ambiguity here (for the first meaning, “, which” is properly used in place of “that”), or the sentence can be restructured to completely eliminate possible misinterpretation. The devious politician hopes that each constituent (politics) will interpret the above statement in the most desirable way, and think the politician supports everyone's opinion. However, the opposite can also be true - An opponent can turn a positive statement into a bad one, if the speaker uses ambiguity (intentionally or not). The logical fallacies of amphiboly and equivocation rely heavily on the use of ambiguous words and phrases.
In literature and rhetoric, on the other hand, ambiguity can be a useful tool. Groucho Marx’s classic joke depends on a grammatical ambiguity for its humor, for example: “Last night I shot an elephant in my pajamas. What he was doing in my pajamas I’ll never know.” Ambiguity can also be used as a comic device through a genuine intention to confuse, as does Magic: The Gathering's Unhinged © Ambiguity, which makes puns with homophones, mispunctuation, and run-ons: “Whenever a player plays a spell that counters a spell that has been played[,] or a player plays a spell that comes into play with counters, that player may counter the next spell played[,] or put an additional counter on a permanent that has already been played, but not countered.” Songs and poetry often rely on ambiguous words for artistic effect, as in the song title “Don’t It Make My Brown Eyes Blue” (where “blue” can refer to the color, or to sadness).
In narrative, ambiguity can be introduced in several ways: motive, plot, character. F. Scott Fitzgerald uses the latter type of ambiguity with notable effect in his novel "The Great Gatsby".
All religions debate the orthodoxy or heterodoxy of ambiguity. Christianity and Judaism employ the concept of paradox synonymously with 'ambiguity'. Ambiguity within Christianity (and other religions) is resisted by the conservatives and fundamentalists, who regard the concept as equating with 'contradiction'. Non-fundamentalist Christians and Jews endorse Rudolf Otto's description of the sacred as 'mysterium tremendum et fascinans', the awe-inspiring mystery which fascinates humans.
Metonymy involves the use of the name of a subcomponent part as an abbreviation, or jargon, for the name of the whole object (for example "wheels" to refer to a car, or "flowers" to refer to beautiful offspring, an entire plant, or a collection of blooming plants). In modern vocabulary critical semiotics, metonymy encompasses any potentially ambiguous word substitution that is based on contextual contiguity (located close together), or a function or process that an object performs, such as "sweet ride" to refer to a nice car. Metonym miscommunication is considered a primary mechanism of linguistic humour.
Psychology and management.
In sociology and social psychology, the term "ambiguity" is used to indicate situations that involve uncertainty. An increasing amount of research is concentrating on how people react and respond to ambiguous situations. Much of this focuses on ambiguity tolerance. A number of correlations have been found between an individual’s reaction and tolerance to ambiguity and a range of factors.
Apter and Desselles (2001) for example, found a strong correlation with such attributes and factors like a greater preference for safe as opposed to risk-based sports, a preference for endurance-type activities as opposed to explosive activities, a more organized and less casual lifestyle, greater care and precision in descriptions, a lower sensitivity to emotional and unpleasant words, a less acute sense of humor, engaging a smaller variety of sexual practices than their more risk-comfortable colleagues, a lower likelihood of the use of drugs, pornography and drink, a greater likelihood of displaying obsessional behavior.
In the field of leadership David Wilkinson (2006) found strong correlations between an individual leader's reaction to ambiguous situations and the Modes of Leadership they use, the type of creativity (Kirton (2003) and how they relate to others.
Music.
In music, pieces or sections which confound expectations and may be or are interpreted simultaneously in different ways are ambiguous, such as some polytonality, polymeter, other ambiguous meters or rhythms, and ambiguous phrasing, or (Stein 2005, p. 79) any aspect of music. The music of Africa is often purposely ambiguous. To quote Sir Donald Francis Tovey (1935, p. 195), “Theorists are apt to vex themselves with vain efforts to remove uncertainty just where it has a high aesthetic value.”
Visual art.
In visual art, certain images are visually ambiguous, such as the Necker cube, which can be interpreted in two ways. Perceptions of such objects remain stable for a time, then may flip, a phenomenon called multistable perception.
The opposite of such ambiguous images are impossible objects.
Pictures or photographs may also be ambiguous at the semantic level: the visual image is unambiguous, but the meaning and narrative may be ambiguous: is a certain facial expression one of excitement or fear, for instance?
Constructed language.
Some languages have been created with the intention of avoiding ambiguity, especially lexical ambiguity. Lojban and Loglan are two related languages which have been created with this in mind. The languages can be both spoken and written. These languages are intended to provide a greater technical precision over big natural languages, although historically, such attempts at language improvement have been criticized. Languages composed from many diverse sources contain much ambiguity and inconsistency. The many exceptions to syntax and semantic rules are time-consuming and difficult to learn.
Mathematical notation.
Mathematical notation, widely used in physics and other sciences, avoids many ambiguities compared to expression in natural language. However, for various reasons, several lexical, syntactic and semantic ambiguities remain.
Expressions.
Ambiguous expressions often appear in physical and mathematical texts.
It is common practice to omit multiplication signs in mathematical expressions. Also, it is common, to give the same name to a variable and a function, for example, formula_1. Then, if one sees formula_2, there is no way to distinguish, does it mean formula_1 multiplied by formula_4, or function formula_5 evaluated at argument equal to formula_4. In each case of use of such notations, the reader is supposed to be able to perform the deduction and reveal the true meaning.
Creators of algorithmic languages try to avoid ambiguities. Many algorithmic languages (C++, MATLAB, Fortran) require the character * as symbol of multiplication. The language Mathematica allows the user to omit the multiplication symbol, but requires square brackets to indicate the argument of a function; square brackets are not allowed for grouping of expressions. Fortran, in addition, does not allow use of the same name (identifier) for different objects, for example, function and variable; in particular, the expression f=f(x) is qualified as an error.
The order of operations may depend on the context. In most programming languages, the operations of division and multiplication have equal priority and are executed from left to right. Until the last century, many editorials assumed that multiplication is performed first, for example, formula_7 is interpreted as formula_8; in this case, the insertion of parentheses is required when translating the formulas to an algorithmic language. In addition, it is common to write an argument of a function without parenthesis, which also may lead to ambiguity.
Sometimes, one uses "italics" letters to denote elementary functions.
In the scientific journal style, the expression
formula_9
formula_10,
formula_11,
formula_12 and
formula_13, although in a slideshow, it may mean formula_14.
Comma in subscripts and superscripts sometimes is omitted; it is also ambiguous notation.
If it is written formula_15, the reader should guess from the context, does it mean a single-index object, evaluated while the subscript is equal to product of variables
formula_16, formula_12 and formula_18, or it is indication to a three-valent tensor.
The writing of formula_15 instead of formula_20 may mean that the writer either is stretched in space (for example, to reduce the publication fees, or aims to increase number of publications without considering readers. The same may apply to any other use of ambiguous notations.
Subscripts are also used to denote the argument to a function, as in formula_21.
Examples of potentially confusing ambiguous mathematical expressions.
formula_22, which could be understood to mean either formula_23 or formula_24. In addition, formula_25 may mean formula_26, as formula_27 means formula_28 (see tetration).
formula_29, which by convention means formula_30, though it might be thought to mean formula_31 since formula_32 means formula_33.
formula_34, which arguably should mean formula_35 but would commonly be understood to mean formula_36
Notations in quantum optics and quantum mechanics.
It is common to define the coherent states in quantum optics with formula_37 and states with fixed number of photons with formula_38. Then, there is an "unwritten rule": the state is coherent if there are more Greek characters than Latin characters in the argument, and formula_12photon state if the Latin characters dominate. The ambiguity becomes even worse, if formula_40 is used for the states with certain value of the coordinate, and formula_41 means the state with certain value of the momentum, which may be used in books on quantum mechanics. Such ambiguities easy lead to confusions, especially if some normalized adimensional, dimensionless variables are used. Expression formula_42 may mean a state with single photon, or the coherent state with mean amplitude equal to 1, or state with momentum equal to unity, and so on. The reader is supposed to guess from the context.
Ambiguous terms in physics and mathematics.
Some physical quantities do not yet have established notations; their value (and sometimes even dimension, as in the case of the Einstein coefficients) depends on the system of notations. Many terms are ambiguous. Each use of an ambiguous term should be preceded by the definition, suitable for a specific case.
A highly confusing term is "gain". For example, the sentence "the gain of a system should be doubled", without context, means close to nothing.
It may mean that the ratio of the output voltage of an electric circuit to the input voltage should be doubled.
It may mean that the ratio of the output power of an electric or optical circuit to the input power should be doubled.
It may mean that the gain of the laser medium should be doubled, for example, doubling the population of the upper laser level in a quasi-two level system (assuming negligible absorption of the ground-state).
The term "intensity" is ambiguous when applied to light. The term can refer to any of irradiance, luminous intensity, radiant intensity, or radiance, depending on the background of the person using the term.
Also, confusions may be related with the use of atomic percent as measure of concentration of a dopant, or resolution of an imaging system, as measure of the size of the smallest detail which still can be resolved at the background of statistical noise. See also Accuracy and precision and its talk.
The Berry paradox arises as a result of systematic ambiguity in the meaning of terms such as "definable" or "nameable". Terms of this kind give rise to vicious circle fallacies. Other terms with this type of ambiguity are: satisfiable, true, false, function, property, class, relation, cardinal, and ordinal.
Mathematical interpretation of ambiguity.
In mathematics and logic, ambiguity can be considered to be an "underdetermined system" (of equations or logic) – for example, formula_43 leaves open what the value of "X" is – while its opposite is a self-contradiction, also called inconsistency, paradoxicalness, or oxymoron, in an overdetermined system – such as formula_44, which has no solution – see also underdetermination.
Logical ambiguity and self-contradiction is analogous to visual ambiguity and impossible objects, such as the Necker cube and impossible cube, or many of the drawings of M. C. Escher.
Pedagogic use of ambiguous expressions.
Ambiguity can be used as a pedagogical trick, to force students to reproduce the deduction by themselves. Some textbooks
Rigorously speaking, such an expression requires that formula_46;
even if function formula_47 is a self-Fourier function, the expression should be written as
formula_48; however, it is assumed that
the shape of the function (and even its norm
formula_49) depend on the character used to denote its argument.
If the Greek letter is used, it is assumed to be a Fourier transform of another function,
The first function is assumed, if the expression in the argument contains more characters formula_50 or formula_51, than characters formula_52, and the second function is assumed in the opposite case. Expressions like formula_53 or formula_54 contain symbols formula_50 and formula_52 in equal amounts; they are ambiguous and should be avoided in serious deduction.
---END.OF.DOCUMENT---
Animal (disambiguation).
An animal is a taxonomic member of the Kingdom Animalia.
---END.OF.DOCUMENT---
Aardvark.
The Aardvark ("Orycteropus afer") (afer: from Africa) is a medium-sized, burrowing, nocturnal mammal native to Africa. It is the only living species of all Tubulidentata, but there are known other prehistoric species and genera of Tubulidentata.
It is sometimes called "antbear", "anteater", "Cape anteater" (after the Cape of Good Hope), "earth hog" or "earth pig". The word "aardvark" is famous for being one of the first entries to appear in many encyclopaedias and even abridged dictionaries. The name comes from the Afrikaans/Dutch for "earth pig" or "ground pig" ("aarde" earth/ground, "varken" pig), because early settlers from Europe thought it resembled a domesticated pig. However, the aardvark is not closely related to the pig; rather, it is the sole recent representative of the obscure mammalian order Tubulidentata, in which it is usually considered to form a single variable species of the genus "Orycteropus", coextensive with the family Orycteropodidae. The aardvark is not closely related to the South American anteater, despite sharing some characteristics and a superficial resemblance. The closest living relatives of the aardvark are the elephant shrews, along with the sirenians, hyraxes, tenrecs, and elephants. Together, these animals form the superorder Afrotheria.
Description.
Genetically speaking, the aardvark is a living fossil, as its chromosomes are highly conserved, reflecting much of the early eutherian arrangement before the divergence of the major modern taxa.
The aardvark is vaguely pig-like in appearance. Its body is stout with an arched back and is sparsely covered with coarse hairs. The limbs are of moderate length. The front feet have lost the pollex (or 'thumb') — resulting in four toes — but the rear feet have all five toes. Each toe bears a large, robust nail which is somewhat flattened and shovel-like, and appears to be intermediate between a claw and a hoof. The ears are disproportionately long, and the tail is very thick at the base and gradually tapers. The greatly elongated head is set on a short, thick neck, and the end of the snout bears a disc, which houses the nostrils. The mouth is small and tubular, typical of species that feed on termites. The aardvark has a long, thin, snakelike, protruding tongue and elaborate structures supporting a keen sense of smell.
An aardvark's weight is typically between 40 and 65 kg. An aardvark's length is usually between 1 and 1.3 metres, and can reach lengths of 2.2 metres when its tail (which can be up to 70 centimetres) is taken into account. The aardvark is pale yellowish gray in color and often stained reddish-brown by soil. The aardvark's coat is thin and the animal's primary protection is its tough skin. The aardvark has been known to sleep in a recently excavated ant nest, which also serves as protection from its predators.
Behavior.
The aardvark is nocturnal and is a solitary creature that feeds almost exclusively on ants and termites (formicivore); the only fruit eaten by aardvarks is the aardvark cucumber. An aardvark emerges from its burrow in the late afternoon or shortly after sunset, and forages over a considerable home range encompassing 10 to 30 kilometers, swinging its long nose from side to side to pick up the scent of food. When a concentration of ants or termites is detected, the aardvark digs into it with its powerful front legs, keeping its long ears upright to listen for predators, and takes up an astonishing number of insects with its long, sticky tongue—as many as 50,000 in one night have been recorded. It is an exceptionally fast digger, but otherwise moves fairly slowly. Its claws enable it to dig through the extremely hard crust of a termite or ant mound quickly, avoiding the dust by sealing the nostrils. When successful, the aardvark's long (as long as 30 centimeters) tongue licks up the insects; the termites' biting, or the ants' stinging attacks are rendered futile by the tough skin. Its keen hearing warns it of predators: lions, leopards, hyenas, and pythons.
Aside from digging out ants and termites, the aardvark also excavates burrows in which to live: temporary sites are scattered around the home range as refuges, and a main burrow is used for breeding. Main burrows can be deep and extensive, have several entrances and can be as long as 13 meters. The aardvark changes the layout of its home burrow regularly, and from time to time moves on and makes a new one; the old burrows are then inhabited by smaller animals like the African Wild Dog. Only mothers and young share burrows. If attacked in the tunnel, it will seal the tunnel off behind itself or turn around and attack with its claws.
Aardvarks only pair during the breeding season; after a gestation period of 7 months, a single cub weighing around 2 kg is born, and is able to leave the burrow to accompany its mother after only two weeks, and is eating termites at 14 weeks and is weaned by 16 weeks. At six months of age it is able to dig its own burrows, but it will often remain with the mother until the next mating season, and is sexually capable by the season after that.
Aardvarks can live to be over 24 years old in captivity.
The aardvark's main predators are lions, leopards, hunting dogs and pythons. Aardvarks can dig fast or run in zigzag fashion to elude enemies, but if all else fails, they will strike with their claws, tail and shoulders, sometimes flipping onto their backs to lash with all fours. Their thick skin also protects them to some extent.
Habitat.
Aardvarks live in subsaharan Africa, where there is suitable habitat for them to live, such as savannas, grasslands, woodlands and bushland, and available food (i.e., ants and termites).
Mythology and popular culture.
In African folklore the aardvark is much admired because of its diligent quest for food and its fearless response to soldier ants. Hausa magicians make a charm from the heart, skin, forehead, and nails of the aardvark, which they then proceed to pound together with the root of a certain tree. Wrapped in a piece of skin and worn on the chest the charm is said to give the owner the ability to pass through walls or roofs at night. The charm is said to be used by burglars and those seeking to visit young girls without their parents' permission.
The main character of Arthur, a popular animated television series for children produced by WGBH-TV and shown in more than 100 countries, is an aardvark.
One of the main characters of The Ant and the Aardvark, is a blue aardvark, voiced by John Byner, doing an impersonation of Jackie Mason. It depicts the Aardvark attempting, and failing, to catch and eat his antagonist, the Ant.
Cerebus the Aardvark was the title character of a comic-book series by Dave Sim and Gerhard that ran from 1977 to 2004, and is still sold in collected volumes of reprints.
During character development for what would eventually be Spiderman, Stan Lee and Steve Ditko originally wanted a mammalian themed superhero to add to the Marvel Universe. Preliminary ideas led to the creation of "Aardvarkman," a superhero with the ability to control hordes of soldier ants. However, in the words of Ditko "the idea of a long gross tongue seemed downright evil in nature; a tongue that long with a mouth that small seems ridiculous." The soldier ant theme eventually led to the creation of Spider-Man, and the supervillain Toad was eventually created from the failed artwork for Aardvarkman
---END.OF.DOCUMENT---
Adventure.
An adventure is an activity that is perceived to involve risky, dangerous or exciting experiences.
The term is often used to refer to activities with some potential for physical danger, such as skydiving, mountain climbing, and extreme sports. However, the term also broadly refers to any enterprise that is potentially fraught with physical, financial or psychological risk, such as a business venture, a love affair, or other major life undertakings.
Adventurous experiences create psychological and physiological arousal, which can be interpreted as negative (e.g. fear) or positive (e.g. flow), and which can be detrimental as stated by the Yerkes-Dodson law. For some people, adventure becomes a major pursuit in and of itself. According to adventurer André Malraux, in his "La Condition Humaine" (1933), "If a man is not ready to risk his life, where is his dignity?". Similarly, Helen Keller famously stated that "Life is either a daring adventure or nothing."
About.
Outdoor adventurous activities are typically undertaken for the purposes of recreation or excitement: examples are adventure racing and adventure tourism. Adventurous activities can also lead to gains in knowledge, such as those undertaken by explorers and pioneers. Adventure education intentionally uses challenging experiences for learning.
Adventure in mythology.
The oldest and most widespread stories in the world are adventure stories.
Joseph Campbell discussed his notion of the monomyth in his book, "The Hero with a Thousand Faces". Campbell proposed that the heroic mythological stories from culture to culture comprised of a similar underlying pattern, starting with the "call to adventure", followed by a hazardous journey and eventual triumph. The adventure novel exhibits these "protagonist on adventurous journey" characteristics as do many popular feature films, such as Star Wars.
Adventurer.
In fiction, the adventurer figure or Picaro may be regarded as a descendant of the knight-errant of Medieval romance. Like the knight, the adventurer roams through episodic encounters, usually involving wealth, romance, or fighting. Unlike the knight, the adventurer was a realistic figure, often lower class or otherwise impoverished, who is forced to make his way to fortune, often by deceit. Also, an adventurer is a roguish hero of low social class who lives by his or her wits in a corrupt society. The picaresque novel originated in Spain in the middle of the fifteenth century. Novels such as Lazarillo de Tormes were influential across Europe. Throughout the eighteenth century, a great number of novels featured bold, amoral, adventuring protagonists, who made their way into wealth and happiness, sometimes with and sometimes without the moral conversion that generally accompanies the Spanish model.
Under Victorian morality the term, used without qualifiers, came to imply a person of low moral character, often someone trying to marry for money.
In comic book handbooks such as "Official Handbook of the Marvel Universe" and ', the term "adventurer" is used as a synonym for "super-hero" when listing a character's occupation.
In role-playing games, the player characters are often professional adventurers, who earn wealth and fame by adventure, such as undertaking hazardous missions, exploring ruins, and slaying monsters. This stereotype is strong enough that "the adventurers" can often be used as a synonym for "the player characters". However non-player character groups of adventurers can also exist, and can be an interesting encounter for the players.
---END.OF.DOCUMENT---
Atlantic Ocean.
The Atlantic Ocean is the second-largest of the world's oceanic divisions. With a total area of about 106.4 million square kilometres (41.1 million square miles), it covers approximately twenty percent of the Earth's surface and about twenty-six percent of its water surface area. The first part of its name refers to the Atlas of Greek mythology, making the Atlantic the "Sea of Atlas".
The oldest known mention of this name is contained in "The Histories" of Herodotus around 450 BC (I 202); see also: "Atlas Mountains". Another name historically used was the ancient term Ethiopic Ocean, derived from Ethiopia, whose name was sometimes used as a synonym for all of Africa and thus for the ocean. Before Europeans discovered other oceans, the term "ocean" itself was to them synonymous with the waters beyond Western Europe that we now know as the Atlantic and which the Greeks had believed to be a gigantic river encircling the world; see Oceanus.
The Atlantic Ocean occupies an elongated, S-shaped basin extending longitudinally between the Americas to the west, and Eurasia and Africa to the east. As one component of the interconnected global ocean, it is connected in the north to the Arctic Ocean (which is sometimes considered a sea of the Atlantic), to the Pacific Ocean in the southwest, the Indian Ocean in the southeast, and the Southern Ocean in the south. (Other definitions describe the Atlantic as extending southward to Antarctica.) The equator subdivides it into the North Atlantic Ocean and South Atlantic Ocean.
Geography.
The Atlantic Ocean is bounded on the west by North and South America. It connects to the Arctic Ocean through the Denmark Strait, Greenland Sea, Norwegian Sea and Barents Sea. To the east, the boundaries of the ocean proper are Europe, the Strait of Gibraltar (where it connects with the Mediterranean Sea, one of its marginal seas and, in turn, the Black Sea) and Africa.
In the southeast, the Atlantic merges into the Indian Ocean. The 20° East meridian, running south from Cape Agulhas to Antarctica defines its border. Some authorities show it extending south to Antarctica, while others show it bounded at the 60° parallel by the Southern Ocean.
In the southwest, the Drake Passage connects it to the Pacific Ocean. The man-made Panama Canal links the Atlantic and Pacific. Besides those mentioned, other large bodies of water adjacent to the Atlantic are the Caribbean Sea, the Gulf of Mexico, Hudson Bay, the Arctic Ocean, the Mediterranean Sea, the North Sea, the Baltic Sea, and the Celtic Sea.
Covering approximately 22% of Earth's surface, the Atlantic is second in size to the Pacific. With its adjacent seas it occupies an area of about; without them, it has an area of. The land that drains into the Atlantic covers four times that of either the Pacific or Indian oceans. The volume of the Atlantic with its adjacent seas is 354,700,000 cubic kilometers (85,100,000 cu mi) and without them 323,600,000 cubic kilometres (77,640,000 cu mi).
The average depth of the Atlantic, with its adjacent seas, is; without them it is. The greatest depth, is in the Puerto Rico Trench. The Atlantic's width varies from between Brazil and Sierra Leone to over in the south.
Extent.
"On the West." The Eastern limits of the Caribbean Sea, the Southeastern limits of the Gulf of Mexico from the North coast of Cuba to Key West, the Southwestern limit of the Bay of Fundy and the Southeastern and Northeastern limits of the Gulf of St. Lawrence.
"On the North." The Southern limit of Davis Strait from the coast of Labrador to Greenland and the Southwestern limit of the Greenland Sea and Norwegian Sea from Greenland to the Shetland Islands.
"On the East." The Northwestern limit of the North Sea, the Northern and Western limits of the Scottish Seas, the Southern limit of the Irish Sea, the Western limits of the Bristol and English Channels, of the Bay of Biscay and of the Mediterranean Sea.
"On the South." The equator, from the coast of Brazil to the Southwestern limit of the Gulf of Guinea.
"On the Southwest." The meridian of Cape Horn, Chile (67°16'W) from Tierra del Fuego to the Antarctic Continent; a line from Cape Virgins () to Cape Espiritu Santo, Tierra del Fuego, the Eastern entrance to Magellan Strait, Chile
"On the West." The limit of the Rio de La Plata.
"On the North." The Southern limit of the North Atlantic Ocean.
"On the Northeast." The limit of the Gulf of Guinea.
"On the Southeast." From Cape Agulhas along the meridian of 20° East to the Antarctic continent.
"On the South." The Antarctic Continent.
Note that these definitions exclude any marginal waterbodies that are separately defined by the IHO (such as the Bay of Biscay and Gulf of Guinea), though these are usually considered to be part of the Atlantic Ocean.
In 2000 the IHO redefined the Atlantic Ocean, moving its southern limit to 60°S, with the waters south of that line identified as the Southern Ocean. This new definition has not yet been ratified (a reservation has been lodged by Australia) though it is in use by the IHO and others. If and when adopted, the 2000 definition will be published in the 4th edition of "Limits of Oceans and Seas", restoring the Southern Ocean as originally outlined in the 2nd edition and subsequently omitted from the 3rd edition.
Cultural significance.
Transatlantic travel played a major role in the expansion of Western civilization into the Americas. Today, it can be referred to in a humorously diminutive way as the Pond in idioms, in reference to the geographical and cultural divide between North America and Europe. Some British people refer to the USA as "across the pond".
Ocean bottom.
The principal feature of the bathymetry (bottom topography) is a submarine mountain range called the Mid-Atlantic Ridge. It extends from Iceland in the north to approximately 58° South latitude, reaching a maximum width of about. A great rift valley also extends along the ridge over most of its length. The depth of water at the apex of the ridge is less than in most places, the bottom of the ridge is three times as deep and of course several peaks rise above the water and form islands. The South Atlantic Ocean has an additional submarine ridge, the Walvis Ridge.
The Mid-Atlantic Ridge separates the Atlantic Ocean into two large troughs with depths from. Transverse ridges running between the continents and the Mid-Atlantic Ridge divide the ocean floor into numerous basins. Some of the larger basins are the Blake, Guiana, North American, Cape Verde, and Canaries basins in the North Atlantic. The largest South Atlantic basins are the Angola, Cape, Argentina, and Brazil basins.
The deep ocean floor is thought to be fairly flat with occasional deeps, trenches, seamounts and some guyots. Various shelves along the margins of the continents constitute about 11% of the bottom topography with few deep channels cut across the continental rise.
Water characteristics.
On average, the Atlantic is the saltiest major ocean; surface water salinity in the open ocean ranges from 33 to 37 parts per thousand (3.3 - 3.7%) by mass and varies with latitude and season. Evaporation, precipitation, river inflow and sea ice melting influence surface salinity values. Although the salinity values are just north of the equator (because of heavy tropical rainfall), in general the lowest values are in the high latitudes and along coasts where large rivers enter. Maximum salinity values occur at about 25° north and south, in subtropical regions with low rainfall and high evaporation.
Surface water temperatures, which vary with latitude, current systems, and season and reflect the latitudinal distribution of solar energy, range from below. Maximum temperatures occur north of the equator, and minimum values are found in the polar regions. In the middle latitudes, the area of maximum temperature variations, values may vary by 7-8 °C (12-15 °F).
The Atlantic Ocean consists of four major water masses. The North and South Atlantic central waters make up the surface. The sub-Antarctic intermediate water extends to depths of. The North Atlantic Deep Water reaches depths of as much as. The Antarctic Bottom Water occupies ocean basins at depths greater than 4,000 meters.
Within the North Atlantic, ocean currents isolate the Sargasso Sea, a large elongated body of water, with above average salinity. The Sargasso Sea contains large amounts of seaweed and is also the spawning ground for both the European eel and the American eel.
The Coriolis effect circulates North Atlantic water in a clockwise direction, whereas South Atlantic water circulates counter-clockwise. The south tides in the Atlantic Ocean are semi-diurnal; that is, two high tides occur during each 24 lunar hours. In latitudes above 40° North some east-west oscillation occurs.
Climate.
Climate is influenced by the temperatures of the surface waters and water currents as well as winds. Because of the ocean's great heat retention capacity, maritime climates are more moderate and have less extreme seasonal variations than inland climates. Precipitation can be approximated from coastal weather data and air temperature from water temperatures.
The oceans are the major source of the atmospheric moisture that is obtained through evaporation. Climatic zones vary with latitude; the warmest zones stretch across the Atlantic north of the equator. The coldest zones are in high latitudes, with the coldest regions corresponding to the areas covered by sea ice. Ocean currents influence climate by transporting warm and cold waters to other regions. The winds that are cooled or warmed when blowing over these currents influence adjacent land areas.
The Gulf Stream and its northern extension towards Europe, the North Atlantic Drift, for example, warms the atmosphere of the British Isles and north-western Europe, and the cold water currents contribute to heavy fog off the coast of eastern Canada (the Grand Banks of Newfoundland area) and Africa's north-western coast. In general, winds transport moisture and air over land areas. Hurricanes develop in the southern part of the North Atlantic Ocean.
History.
The Atlantic Ocean appears to be the second youngest of the five oceans. Apparently it did not exist prior to 130 million years ago, when the continents that formed from the breakup of the ancestral super continent, Pangaea, were drifting apart from seafloor spreading. The Atlantic has been extensively explored since the earliest settlements along its shores.
The Vikings, the Portuguese, and Christopher Columbus were the most famous among early explorers. After Columbus, European exploration rapidly accelerated, and many new trade routes were established.
As a result, the Atlantic became and remains the major artery between Europe and the Americas (known as transatlantic trade). Scientific explorations include the Challenger expedition, the German Meteor expedition, Columbia University's Lamont-Doherty Earth Observatory and the United States Navy Hydrographic Office.
Ethiopic Ocean.
The Ethiopic Ocean or Ethiopian Ocean (Okeanos Aithiopos) is an old name for what is now called the South Atlantic Ocean, which is separated from the North Atlantic Ocean by a narrow region between Natal, Brazil and Monrovia, Liberia. Use of this term illustrates a past trend towards referring to the whole continent of Africa by the name "Aethiopia". The modern nation of Ethiopia, in northeast Africa, is nowhere near the Ethiopic Ocean, which would be said to lie off the west coast of Africa. The term "Ethiopian Ocean" sometimes appeared until the mid-19th century.
Economy.
The Atlantic has contributed significantly to the development and economy of surrounding countries. Besides major transatlantic transportation and communication routes, the Atlantic offers abundant petroleum deposits in the sedimentary rocks of the continental shelves. The Atlantic hosts the world's richest fishing resources, especially in the waters covering the shelves. The major fish are cod, haddock, hake, herring, and mackerel.
The most productive areas include Newfoundland's Grand Banks, the Nova Scotia shelf, Georges Bank off Cape Cod, the Bahama Banks, the waters around Iceland, the Irish Sea, the Dogger Bank of the North Sea, and the Falkland Banks. Eel, lobster, and whales appear in great quantities. Because environmental threats from oil spills, marine debris, and the incineration of toxic wastes at sea, various international treaties attempt to reduce pollution.
Terrain.
From October to June the surface is usually covered with sea ice in the Labrador Sea, Denmark Strait, and Baltic Sea. A clockwise warm-water gyre occupies the northern Atlantic, and a counter-clockwise warm-water gyre appears in the southern Atlantic. The Mid-Atlantic Ridge, a rugged north-south centerline for the entire Atlantic basin, first discovered by the Challenger Expedition dominates the ocean floor. This was formed by the vulcanism that also formed the ocean floor and the islands rising from it.
The Atlantic has irregular coasts indented by numerous bays, gulfs, and seas. These include the Norwegian Sea, Baltic Sea, North Sea, Labrador Sea, Black Sea, Gulf of Saint Lawrence, Bay of Fundy, Gulf of Maine, Mediterranean Sea, Gulf of Mexico, and Caribbean Sea.
Islands include Greenland, Iceland, Faroe Islands, Great Britain (including numerous surrounding islands), Ireland, Rockall, Newfoundland, Sable Island, Azores, Madeira, Bermuda, Canary Islands, Caribbean, Cape Verde, São Tomé and Príncipe, Annobón Province, St. Peter Island, Fernando de Noronha, Rocas Atoll, Ascension Island, Saint Helena, The Islands of Trindad, Tristan da Cunha, Gough Island (Also known as Diego Alvarez), Falkland Islands, Tierra del Fuego, South Georgia Island, South Sandwich Islands, and Bouvet Island.
Natural resources.
The Atlantic harbors petroleum and gas fields, fish, marine mammals (seals and whales), sand and gravel aggregates, placer deposits, polymetallic nodules, and precious stones.
Natural hazards.
Icebergs are common from February to August in the Davis Strait, Denmark Strait, and the northwestern Atlantic and have been spotted as far south as Bermuda and Madeira. Ships are subject to superstructure icing in the extreme north from October to May. Persistent fog can be a maritime hazard from May to September, as can hurricanes north of the equator (May to December).
The United States' southeast coast has a long history of shipwrecks due to its many shoals and reefs. The Virginia and North Carolina coasts were particularly dangerous.
The Bermuda Triangle is popularly believed to be the site of numerous aviation and shipping incidents because of unexplained and supposedly mysterious causes, but Coast Guard records do not support this belief.
Current environmental issues.
Endangered marine species include the manatee, seals, sea lions, turtles, and whales. Drift net fishing can kill dolphins, albatrosses and other seabirds (petrels, auks), hastening the fish stock decline and contributing to international disputes. Municipal pollution comes from the eastern United States, southern Brazil, and eastern Argentina; oil pollution in the Caribbean Sea, Gulf of Mexico, Lake Maracaibo, Mediterranean Sea, and North Sea; and industrial waste and municipal sewage pollution in the Baltic Sea, North Sea, and Mediterranean Sea.
In 2005, there was some concern that warm northern European currents were slowing down, but no scientific consensus formed from that evidence.
On June 7, 2006, Florida's wildlife commission voted to take the manatee off the state's endangered species list. Some environmentalists worry that this could erode safeguards for the popular sea creature.
Marine pollution.
Marine pollution is a generic term for the entry into the ocean of potentially hazardous chemicals or particles. The biggest culprits are rivers and with them many agriculture fertilizer chemicals as well as livestock and human waste. The excess of oxygen-depleting chemicals leads to hypoxia and the creation of a dead zone.
Marine debris, also known as marine litter, describes human-created waste floating in a body of water. Oceanic debris tends to accumulate at the center of gyres and coastlines, frequently washing aground where it is known as beach litter.
References.
Much of this article comes from the public domain site http://oceanographer.navy.mil/atlantic.html (dead link). It is now accessible from the Internet Archive at http://web.archive.org/web/20020221215514/http%3a//oceanographer.navy.mil/atlantic.html.
---END.OF.DOCUMENT---
Arthur Schopenhauer.
Arthur Schopenhauer (22 February 1788 – 21 September 1860) was a German philosopher known for his atheistic pessimism and philosophical clarity. At age 25, he published his doctoral dissertation, "On the Fourfold Root of the Principle of Sufficient Reason", which examined the fundamental question of whether reason alone can unlock answers about the world.
Schopenhauer's most influential work, "The World as Will and Representation", emphasized the role of man's basic motivation, which Schopenhauer called will. His analysis of will led him to the conclusion that emotional, physical, and sexual desires can never be fulfilled. Consequently, he favored a lifestyle of negating human desires, similar to the teachings of ancient Greek Stoic philosophers, Buddhism, and Vedanta.
Schopenhauer's metaphysical analysis of will, his views on human motivation and desire, and his aphoristic writing style influenced many well-known thinkers including Friedrich Nietzsche, Richard Wagner, Ludwig Wittgenstein, Erwin Schrödinger, Albert Einstein, Sigmund Freud, Otto Rank, Carl Gustav Jung, and Jorge Luis Borges.
Life.
Arthur Schopenhauer was born in the city of Danzig (Gdańsk) as the son of Heinrich Floris Schopenhauer and Johanna Schopenhauer, both descendants of wealthy German Patrician families. When the Kingdom of Prussia acquired the Polish-Lithuanian Commonwealth city of Danzig in 1793, Schopenhauer's family moved to Hamburg. In 1805, Schopenhauer's father committed suicide. Schopenhauer's mother Johanna shortly after moved to Weimar, then the centre of German literature, to pursue her writing career. After one year, Schopenhauer left the family business in Hamburg to join her.
Schopenhauer became a student at the University of Göttingen in 1809. There he studied metaphysics and psychology under Gottlob Ernst Schulze, the author of "Aenesidemus", who advised him to concentrate on Plato and Kant. In Berlin, from 1811 to 1812, he had attended lectures by the prominent post-Kantian philosopher J. G. Fichte and the theologian Schleiermacher.
In 1814, Schopenhauer began his seminal work "The World as Will and Representation" ("Die Welt als Wille und Vorstellung"). He would finish it in 1818 and publish it the following year. In Dresden in 1819, Schopenhauer fathered an illegitimate child who was born and died the same year. In 1820, Schopenhauer became a lecturer at the University of Berlin. He scheduled his lectures to coincide with those of the famous philosopher G. W. F. Hegel, whom Schopenhauer described as a "clumsy charlatan". However, only five students turned up to Schopenhauer's lectures, and he dropped out of academia. A late essay, "On University Philosophy", expressed his resentment towards university philosophy.
While in Berlin, Schopenhauer was named as a defendant in an action at law initiated by a woman named Caroline Marquet.
She asked for damages, alleging that Schopenhauer had pushed her. According to Schopenhauer's court testimony, she deliberately annoyed him by raising her voice while standing right outside his door. Marquet alleged that the philosopher had assaulted and battered her after she refused to leave his doorway. Her companion testified that she saw Marquet prostrate outside his apartment. Because Marquet won the lawsuit, he made payments to her for the next twenty years. When she died, he wrote on a copy of her death certificate, "Obit anus, abit onus" ("The old woman dies, the burden flies").
In 1821, he fell in love with nineteen-year old opera singer, Caroline Richter (called Medon), and had a relationship with her for several years. He discarded marriage plans, however, writing, "Marrying means to halve one's rights and double one's duties", and "Marrying means, to grasp blindfolded into a sack hoping to find out an eel out of an assembly of snakes." When he was forty-three years old, seventeen-year old Flora Weiss recorded rejecting him in her diary.
Schopenhauer had a notably strained relationship with his mother Johanna Schopenhauer. After his father's death, Arthur Schopenhauer endured two long years of drudgery as a merchant, in honor of his dead father. Afterwards, his mother retired to Weimar, and Arthur dedicated himself wholly to studies in the gymnasium of Gotha. After he left it in disgust after seeing one of the masters lampooned, he went to live with his mother. But by that time she had already opened her infamous salon, and Arthur was not compatible with the vain, ceremonious ways of the salon. He was also disgusted by the ease with which Johanna had forgotten his father's memory. Therefore, he gave university life a shot. There, he wrote his first book, "On the Fourfold Root of the Principle of Sufficient Reason". She informed him that the book was incomprehensible and it was unlikely that anyone would ever buy a copy. In a fit of temper Arthur told her that his work would be read long after the rubbish she wrote would have been totally forgotten.
In 1831, a cholera epidemic broke out in Berlin and Schopenhauer left the city. Schopenhauer settled permanently in Frankfurt in 1833, where he remained for the next twenty-seven years, living alone except for a succession of pet poodles named Atma and Butz. Schopenhauer had a robust constitution, but in 1860 his health began to deteriorate. He died of heart failure on 21 September 1860, while sitting in his armchair at home. He was 72.
Philosophy of the "will".
A key focus of Schopenhauer was his investigation of individual motivation. Before Schopenhauer, Hegel had popularized the concept of "Zeitgeist", the idea that society consisted of a collective consciousness which moved in a distinct direction, dictating the actions of its members. Schopenhauer, a reader of both Kant and Hegel, criticized their logical optimism and the belief that individual morality could be determined by society and reason. Schopenhauer believed that humans were motivated only by their own basic desires, or "Wille zum Leben" (Will to Live), which directed all of mankind. For Schopenhauer, human desire was futile, illogical, directionless, and, by extension, so was all human action in the world. To Schopenhauer, the Will is a metaphysical existence which controls not only the actions of individual, intelligent agents, but ultimately all observable phenomena. Will, for Schopenhauer, is what Kant called the "thing-in-itself".
Art and aesthetics.
For Schopenhauer, human desiring, "willing," and craving cause suffering or pain. A temporary way to escape this pain is through aesthetic contemplation (a method comparable to Zapffe's "Sublimation"). This is the next best way, short of not willing at all, which is the best way. Total absorption in the world as representation prevents a person from suffering the world as will. Art diverts the spectator's attention from the grave everyday world and lifts him or her into a world that consists of mere play of images. With music, the auditor becomes engrossed with a playful form of the will, which is normally deadly serious. Music was also given a special status in Schopenhauer's aesthetics as it did not rely upon the medium of phenomenal representation. Music artistically presents the will itself, not the way that the will appears to an individual observer. According to Daniel Albright, "Schopenhauer thought that music was the only art that did not merely copy ideas, but actually embodied the will itself."
Ethics.
Schopenhauer's moral theory proposed that of three primary moral incentives, compassion, malice and egoism, compassion is the major motivator to moral expression. Malice and egoism are corrupt alternatives.
Psychology.
Schopenhauer was perhaps even more influential in his treatment of man's psychology than he was in the realm of philosophy.
...one ought rather to be surprised that a thing [sex] which plays throughout so important a part in human life has hitherto practically been disregarded by philosophers altogether, and lies before us as raw and untreated material.
He gave a name to a force within man which he felt had invariably precedence over reason: the Will to Live or Will to Life ("Wille zum Leben"), defined as an inherent drive within human beings, and indeed all creatures, to stay alive and to reproduce.
The ultimate aim of all love affairs... is more important than all other aims in man's life; and therefore it is quite worthy of the profound seriousness with which everyone pursues it.
What is decided by it is nothing less than the composition of the next generation...
These ideas foreshadowed Darwin's discovery of evolution and Freud's concepts of the libido and the unconscious mind.
Politics.
Schopenhauer's politics were, for the most part, an echo of his system of ethics (the latter being expressed in "Die beiden Grundprobleme der Ethik", available in English as two separate books, "On the Basis of Morality" and "On the Freedom of the Will"). Ethics also occupies about one quarter of his central work, "The World as Will and Representation".
In occasional political comments in his "Parerga and Paralipomena" and "Manuscript Remains", Schopenhauer described himself as a proponent of limited government. What was essential, he thought, was that the state should "leave each man free to work out his own salvation", and so long as government was thus limited, he would "prefer to be ruled by a lion than one of [his] fellow rats" — i.e., by a monarch, rather than a democrat. Schopenhauer did, however, share the view of Thomas Hobbes on the necessity of the state, and of state violence, to check the destructive tendencies innate to our species.
Schopenhauer, by his own admission, did not give much thought to politics, and several times he writes proudly of how little attention he had paid "to political affairs of [his] day". In a life that spanned several revolutions in French and German government, and a few continent-shaking wars, he did indeed maintain his aloof position of "minding not the times but the eternities". He wrote many disparaging remarks about Germany and the Germans. A typical example is, "For a German it is even good to have somewhat lengthy words in his mouth, for he thinks slowly, and they give him time to reflect."
The highest civilization and culture, apart from the ancient Hindus and Egyptians, are found exclusively among the white races; and even with many dark peoples, the ruling caste or race is fairer in colour than the rest and has, therefore, evidently immigrated, for example, the Brahmans, the Incas, and the rulers of the South Sea Islands. All this is due to the fact that necessity is the mother of invention because those tribes that emigrated early to the north, and there gradually became white, had to develop all their intellectual powers and invent and perfect all the arts in their struggle with need, want and misery, which in their many forms were brought about by the climate. This they had to do in order to make up for the parsimony of nature and out of it all came their high civilization.
Despite this, he was adamantly against differing treatment of races, was fervently anti-slavery, and supported the abolitionist movement in the United States. He describes the treatment of "[our] innocent black brothers whom force and injustice have delivered into [the slave-master's] devilish clutches" as "belonging to the blackest pages of mankind's criminal record".
While all other religions endeavor to explain to the people by symbols the metaphysical significance of life, the religion of the Jews is entirely immanent and furnishes nothing but a mere war-cry in the struggle with other nations.
Je me croyais loin de la religion pourtant. Je ne songeais pas que, de Schopenhauer que j'admirais plus que de raison, à l'"Ecclésiaste", et au "Livre de Job", il n'y avait qu'un pas. Les prémisses sur le Pessimisme sont les mêmes, seulement lorsqu'il s'agit de conclure, le philosophe se dérobe. [...] L'Eglise, elle, explique les origines et les causes, signale les fins, présente les remèdes; elle ne se contente pas de vous donner une consultation d'âme, elle vous traite et elle vous guérit alors que le médicastre allemand, après vous avoir bien démontré que l'affection dont vous souffrez est incurable, vous tourne, en ricanant, le dos.
Views on women.
In Schopenhauer's 1851 essay "Of Women" ("Über die Weiber", full text), he expressed his opposition to what he called "Teutonico-Christian stupidity" on female affairs. He claimed that "woman is by nature meant to obey", and opposed Schiller's poem in honor of women, "Würde der Frauen" ("Dignity of Women"). The essay does give two compliments, however: that "women are decidedly more sober in their judgment than [men] are" and are more sympathetic to the suffering of others. However, the latter was discounted as weakness rather than humanitarian virtue.
Schopenhauer's controversial writings have influenced many, from Friedrich Nietzsche to nineteenth-century feminists. Schopenhauer's biological analysis of the difference between the sexes, and their separate roles in the struggle for survival and reproduction, anticipates some of the claims that were later ventured by sociobiologists and evolutionary psychologists in the twentieth century.
After the elderly Schopenhauer sat for a sculpture portrait by Elisabet Ney, he told Richard Wagner's friend Malwida von Meysenbug, "I have not yet spoken my last word about women. I believe that if a woman succeeds in withdrawing from the mass, or rather raising herself above the mass, she grows ceaselessly and more than a man."
Heredity and eugenics.
With our knowledge of the complete unalterability both of character and of mental faculties, we are led to the view that a real and thorough improvement of the human race might be reached not so much from outside as from within, not so much by theory and instruction as rather by the path of generation. Plato had something of the kind in mind when, in the fifth book of his "Republic", he explained his plan for increasing and improving his warrior caste. If we could castrate all scoundrels and stick all stupid geese in a convent, and give men of noble character a whole harem, and procure men, and indeed thorough men, for all girls of intellect and understanding, then a generation would soon arise which would produce a better age than that of Pericles.
In another context, Schopenhauer reiterated his antidemocratic-eugenic thesis: "If you want Utopian plans, I would say: the only solution to the problem is the despotism of the wise and noble members of a genuine aristocracy, a genuine nobility, achieved by mating the most magnanimous men with the cleverest and most gifted women. This proposal constitutes my Utopia and my Platonic Republic". Analysts (e.g., Keith Ansell-Pearson) have suggested that Schopenhauer's advocacy of anti-egalitarianism and eugenics influenced the neo-aristocratic philosophy of Friedrich Nietzsche, who initially considered Schopenhauer his mentor.
Views on homosexuality & pederasty.
Schopenhauer was also one of the first philosophers since the days of Greek philosophy to address the subject of male homosexuality. In the third, expanded edition of "The World as Will and Representation" (1856), Schopenhauer added an appendix to his chapter on the "Metaphysics of Sexual Love". He also wrote that homosexuality did have the benefit of preventing ill-begotten children. Concerning this, he stated, "... the vice we are considering appears to work directly against the aims and ends of nature, and that in a matter that is all important and of the greatest concern to her, it must in fact serve these very aims, although only indirectly, as a means for preventing greater evils." Shrewdly anticipating the interpretive distortion on the part of the popular mind of his attempted scientific "explanation" of pederasty as a personal "advocacy" of a phenomenon Schopenhauer otherwise describes, in terms of spiritual ethics, as an "objectionable aberration", Schopenhauer sarcastically concludes the appendix with the statement that "by expounding these paradoxical ideas, I wanted to grant to the professors of philosophy a small favour, for they are very disconcerted by the ever-increasing publicization of my philosophy which they so carefully concealed. I have done so by giving them the opportunity of slandering me by saying that I defend and commend pederasty."
Influences.
Schopenhauer said he was influenced by the Upanishads, Immanuel Kant, and Plato. References to Eastern philosophy and religion appear frequently in Schopenhauer's writing. As noted above, he appreciated the teachings of the Buddha and even called himself a "Buddhist". He said that his philosophy could not have been conceived before these teachings were available.
If the reader has also received the benefit of the Vedas, the access to which by means of the Upanishads is in my eyes the greatest privilege which this still young century (1818) may claim before all previous centuries, if then the reader, I say, has received his initiation in primeval Indian wisdom, and received it with an open heart, he will be prepared in the very best way for hearing what I have to tell him. It will not sound to him strange, as to many others, much less disagreeable; for I might, if it did not sound conceited, contend that every one of the detached statements which constitute the Upanishads, may be deduced as a necessary result from the fundamental thoughts which I have to enunciate, though those deductions themselves are by no means to be found there.
He summarised the influence of the Upanishads thus: “It has been the solace of my life, it will be the solace of my death!”
Other influences were: Shakespeare, Jean Jacques Rousseau, John Locke, Baruch Spinoza, Matthias Claudius, George Berkeley, David Hume, René Descartes.
Criticism of Kant.
Schopenhauer accepted Kant's double-aspect of the universe—the phenomenal (world of experience) and the noumenal (world independent of experience). Some commentators suggest that Schopenhauer claimed that the noumenon, or thing-in-itself, was the basis for Schopenhauer's concept of the will. Other commentators suggest that Schopenhauer considered will to be only a subset of the "thing-in-itself" class, namely that which we can most directly experience.
Schopenhauer's identification of the Kantian "noumenon" (i.e., the actually existing entity) with what he termed "will" deserves some explanation. The noumenon was what Kant called the "Ding an Sich", the "Thing in Itself", the reality that is the foundation of our sensory and mental representations of an external world. In Kantian terms, those sensory and mental representations are mere phenomena. Schopenhauer departed from Kant in his description of the relationship between the phenomenon and the noumenon. According to Kant, things-in-themselves ground the phenomenal representations in our minds; Schopenhauer, on the other hand, believed phenomena and noumena to be two different sides of the same coin. Noumena do not "cause" phenomena, but rather phenomena are simply the way by which our minds perceive the noumena, according to the Principle of Sufficient Reason. This is explained more fully in Schopenhauer's doctoral thesis, "On the Fourfold Root of the Principle of Sufficient Reason".
Schopenhauer's second major departure from Kant's epistemology concerns the body. Kant's philosophy was formulated as a response to the radical philosophical skepticism of David Hume, who claimed that causality could not be observed empirically. Schopenhauer begins by arguing that Kant's demarcation between external objects, knowable only as phenomena, and the Thing in Itself of noumenon, contains a significant omission. There is, in fact, one physical object we know more intimately than we know any object of sense perception: our own body.
We know our human bodies have boundaries and occupy space, the same way other objects known only through our named senses do. Though we seldom think of our body as a physical object, we know even before reflection that it shares some of an object's properties. We understand that a watermelon cannot successfully occupy the same space as an oncoming truck; we know that if we tried to repeat the experiment with our own body, we would obtain similar results – we know this even if we do not understand the physics involved.
We know that our consciousness inhabits a physical body, similar to other physical objects only known as phenomena. Yet our consciousness is not commensurate with our body. Most of us possess the power of voluntary motion. We usually are not aware of the breathing of our lungs or the beating of our heart unless somehow our attention is called to them. Our ability to control either is limited. Our kidneys command our attention on their schedule rather than one we choose. Few of us have any idea what our liver is doing right now, though this organ is as needful as lungs, heart, or kidneys. The conscious mind is the servant, not the master, of these and other organs; these organs have an agenda which the conscious mind did not choose, and over which it has limited power.
When Schopenhauer identifies the "noumenon" with the desires, needs, and impulses in us that we name "will," what he is saying is that we participate in the reality of an otherwise unachievable world outside the mind through will. We cannot "prove" that our mental picture of an outside world corresponds with a reality by reasoning; through will, we know – without thinking – that the world can stimulate us. We suffer fear, or desire: these states arise involuntarily; they arise prior to reflection; they arise even when the conscious mind would prefer to hold them at bay. The rational mind is, for Schopenhauer, a leaf borne along in a stream of pre-reflective and largely unconscious emotion. That stream is will, and through will, if not through logic, we can participate in the underlying reality beyond mere phenomena. It is for this reason that Schopenhauer identifies the "noumenon" with what we call our will.
In his criticism of Kant, Schopenhauer claimed that sensation and understanding are separate and distinct abilities. Yet, for Kant, an object is known through each of them. Kant wrote: "… [T]here are two stems of human knowledge... namely, sensibility and understanding, objects being given by the former [sensibility] and thought by the latter [understanding]." Schopenhauer disagreed. He asserted that mere sense impressions, not objects, are given by sensibility. According to Schopenhauer, objects are intuitively perceived by understanding and are discursively thought by reason (Kant had claimed that (1) the understanding thinks objects through concepts and that (2) reason seeks the unconditioned or ultimate answer to "why?"). Schopenhauer said that Kant's mistake regarding perception resulted in all of the obscurity and difficult confusion that is exhibited in the Transcendental Analytic section of his critique.
Influence.
Schopenhauer has had a massive influence upon later thinkers, though more so in the arts (especially literature and music) and psychology than in philosophy. His popularity peaked in the early twentieth century, especially during the Modernist era, and waned somewhat thereafter. Nevertheless, a number of recent publications have reinterpreted and modernised the study of Schopenhauer. His theory is also being explored by some modern philosophers as a precursor to evolutionary theory and modern evolutionary psychology.
Schopenhauer versus Hegel.
If I were to say that the so-called philosophy of this fellow Hegel is a colossal piece of mystification which will yet provide posterity with an inexhaustible theme for laughter at our times, that it is a pseudo-philosophy paralyzing all mental powers, stifling all real thinking, and, by the most outrageous misuse of language, putting in its place the hollowest, most senseless, thoughtless, and, as is confirmed by its success, most stupefying verbiage, I should be quite right.
Further, if I were to say that this summus philosophus [...] scribbled nonsense quite unlike any mortal before him, so that whoever could read his most eulogized work, the so-called "Phenomenology of the Mind", without feeling as if he were in a madhouse, would qualify as an inmate for Bedlam, I should be no less right.
In his Foreword to the first edition of his work "Die beiden Grundprobleme der Ethik", Schopenhauer suggested that he had shown Hegel to have fallen prey to the "Post hoc ergo propter hoc" fallacy.
Schopenhauer thought that Hegel used deliberately impressive but ultimately vacuous verbiage. He suggested his works were filled with "castles of abstraction" that sounded impressive but ultimately had no content. He also thought that his glorification of church and state were designed for personal advantage and had little to do with the search for philosophical truth. For instance, the Right Hegelians interpreted Hegel as viewing the Prussian state of his day as perfect and the goal of all history up until then.
Indology.
It is the most satisfying and elevating reading (with the exception of the original text) which is possible in the world; it has been the solace of my life and will be the solace of my death.
It is well known that the book "Oupnekhat" (Upanishad) always lay open on his table, and he invariably studied it before sleeping at night. He called the opening up of Sanskrit literature "the greatest gift of our century", and predicted that the philosophy and knowledge of the Upanishads would become the cherished faith of the West.
Animal rights.
As a consequence of his philosophy, Schopenhauer was very concerned about the rights of animals. For him, all animals, including humans, are phenomenal manifestations of Will. The word "will" designated, for him, force, power, impulse, energy, and desire; it is the closest word we have that can signify both the real essence of all external things and also our own direct, inner experience. Since everything is basically Will, then humans and animals are fundamentally the same and can recognize themselves in each other. For this reason, he claimed that a good person would have sympathy for animals, who are our fellow sufferers.
Compassion for animals is intimately associated with goodness of character, and it may be confidently asserted that he, who is cruel to living creatures, cannot be a good man.
Nothing leads more definitely to a recognition of the identity of the essential nature in animal and human phenomena than a study of zoology and anatomy.
“The assumption that animals are without rights and the illusion that our treatment of them has no moral significance is a positively outrageous example of Western crudity and barbarity. Universal compassion is the only guarantee of morality."
In 1841, he praised the establishment, in London, of the Society for the Prevention of Cruelty to Animals, and also the Animals' Friends Society in Philadelphia. Schopenhauer even went so far as to protest against the use of the pronoun "it" in reference to animals because it led to the treatment of them as though they were inanimate things. To reinforce his points, Schopenhauer referred to anecdotal reports of the look in the eyes of a monkey who had been shot and also the grief of a baby elephant whose mother had been killed by a hunter. He was very attached to his succession of pet poodles. Schopenhauer criticized Spinoza's belief that animals are to be used as a mere means for the satisfaction of humans.
Schopenhauer and Buddhism.
Many Europeans, in the 1830s and 1840s, including Schopenhauer himself, found a correspondence between Schopenhauerian thought and the Four Noble Truths of Buddhism. Similarities centered on the principles that life involves suffering, that suffering is caused by desire, and that the extinction of desire leads to salvation. Thus three of the four "truths of the Buddha" correspond to Schopenhauer's doctrine of the will. In Buddhism, however, while greed and lust are always unskillful, desire is ethically variable - it can be skillful, unskillful, or neutral. In the Buddhist perspective, the enemy to be defeated is craving rather than desire in general.
For Schopenhauer, Will had ontological primacy over the intellect; in other words, desire is understood to be prior to thought. Schopenhauer felt this was similar to notions of purushartha or goals of life in Vedanta Hinduism.
If I wished to take the results of my philosophy as the standard of truth, I should have to concede to Buddhism pre-eminence over the others. In any case, it must be a pleasure to me to see my doctrine in such close agreement with a religion that the majority of men on earth hold as their own, for this numbers far more followers than any other. And this agreement must be yet the more pleasing to me, inasmuch as "in my philosophizing I have certainly not been under its influence" [emphasis added]. For up till 1818, when my work appeared, there was to be found in Europe only a very few accounts of Buddhism.
Buddhist philosopher Nishitani Keiji, however, sought to distance Buddhism from Schopenhauer.
Philosophy... is a science, and as such has no articles of faith; accordingly, in it nothing can be assumed as existing except what is either positively given empirically, or demonstrated through indubitable conclusions.
This actual world of what is knowable, in which we are and which is in us, remains both the material and the limit of our consideration.
---END.OF.DOCUMENT---
Angola.
Angola, officially the Republic of Angola (,;), is a country in south-central Africa bordered by Namibia on the south, Democratic Republic of the Congo on the north, and Zambia on the east; its west coast is on the Atlantic Ocean. The exclave province of Cabinda has a border with the Republic of the Congo and the Democratic Republic of the Congo.
Angola was a Portuguese overseas territory from the 16th century to 1975. After independence, Angola was the scene of an intense civil war from 1975 to 2002. The country is the second-largest petroleum and diamond producer in sub-Saharan Africa; however, its life expectancy and infant mortality rates are both among the worst ranked in the world. In August 2006, a peace treaty was signed with a faction of the FLEC, a separatist guerrilla group from the Cabinda exclave in the North, which is still active. About 65% of Angola's oil comes from that region.
Early migrations.
Khoisan hunter-gatherers are some of the earliest known modern human inhabitants of the area. They were largely replaced by Bantu tribes during the Bantu migrations, though small numbers of Khoisans remain in parts of southern Angola to the present day. The Bantu came from the north, probably from somewhere near the present-day Republic of Cameroon. When they reached what is now Angola, they encountered the Khoisans, Bushmen and other groups considerably less technologically advanced than themselves, whom they easily dominated with their superior knowledge of metal-working, ceramics and agriculture. The establishment of the Bantus took many centuries and gave rise to various groups who took on different ethnic characteristics.
The BaKongo kingdoms of Angola established trade routes with other trading cities and civilizations up and down the coast of southwestern and West Africa but engaged in little or no transoceanic trade. This contrasts with the Great Zimbabwe Mutapa civilization which traded with India, the Persian Gulf civilizations and China. The BaKongo engaged in limited trading with Great Zimbabwe, exchanging copper and iron for salt, food and raffia textiles across the Kongo River.
Portuguese rule.
The geographical areas now designated as Angola, first became subject to incursions by the Portuguese in the late 15th century. In 1483, when Portugal established relations with the Kongo State, Ndongo and Lunda existed. The Kongo State stretched from modern Gabon in the north to the Kwanza River in the south. Angola became a link in European trade with India and Southeast Asia. The Portuguese explorer Paulo Dias de Novais founded Luanda in 1575 as "São Paulo de Loanda", with a hundred families of settlers and four hundred soldiers.
Benguela, a Portuguese fort from 1587 which became a town in 1617, was another important early settlement they founded and ruled. The Portuguese would establish several settlements, forts and trading posts along the coastal strip of current-day Angola, which relied on slave trade, commerce in raw materials, and exchange of goods for survival. The African slave trade provided a large number of black slaves to Europeans and their African agents. For example, in what is now Angola, the Imbangala economy was heavily focused on the slave trade.
European traders would export manufactured goods to the coast of Africa where they would be exchanged for slaves. Within the Portuguese Empire, most black African slaves were traded to Portuguese merchants who bought them to sell as cheap labour for use on Brazilian agricultural plantations. This trade would last until the first half of the 1800s.
The Portuguese gradually took control of the coastal strip during the sixteenth century by a series of treaties and wars forming the Portuguese colony of Angola. Taking advantage of the Portuguese Restoration War, the Dutch occupied Luanda from 1641 to 1648, where they allied with local peoples, consolidating their colonial rule against the remaining Portuguese resistance.
In 1648, a fleet under the command of Salvador de Sá retook Luanda for Portugal and initiated a conquest of the lost territories, which restored Portugal to its former possessions by 1650. Treaties regulated relations with Congo in 1649 and Njinga's Kingdom of Matamba and Ndongo in 1656. The conquest of Pungo Andongo in 1671 was the last great Portuguese expansion, as attempts to invade Congo in 1670 and Matamba in 1681 failed. Portugal expanded its territory behind the colony of Benguela in the eighteenth century, and began the attempt to occupy other regions in the mid-nineteenth century.
The process resulted in few gains until the 1880s. Development of the hinterland began after the Berlin Conference in 1885 fixed the colony's borders, and British and Portuguese investment fostered mining, railways, and agriculture. Full Portuguese administrative control of the hinterland did not occur until the beginning of the twentieth century. In 1951, the colony was designated as an overseas province, called Overseas Province of Angola. Portugal had a presence in Angola for nearly five hundred years, and the population's initial reaction to calls for independence was mixed. More overtly political organisations first appeared in the 1950s, and began to make organised demands for their rights, especially in international forums such as the Non-Aligned Movement.
The Portuguese regime, meanwhile, refused to accede to the nationalists' demands of separatism, provoking an armed conflict that started in 1961 when black guerrillas attacked both white and black civilians in cross-border operations in northeastern Angola. The war came to be known as the Colonial War. In this struggle, the principal protagonists were the MPLA (Popular Movement for the Liberation of Angola), founded in 1956, the FNLA (National Front for the Liberation of Angola), which appeared in 1961, and UNITA (National Union for the Total Independence of Angola), founded in 1966. After many years of conflict, Angola gained its independence on 11 November 1975, after the 1974 coup d'état in the metropole's capital city of Lisbon which overthrew the Portuguese regime headed by Marcelo Caetano.
Portugal's new revolutionary leaders began a process of democratic change at home and acceptance of its former colonies' independence abroad. These events prompted a mass exodus of Portuguese citizens from Portugal's African territories (mostly from Portuguese Angola and Mozambique), creating over a million destitute Portuguese refugees — the "retornados".
Independence and civil war.
After independence in November 1975, Angola faced a devastating civil war which lasted several decades and claimed millions of lives and refugees. Following negotiations held in Portugal, itself under severe social and political turmoil and uncertainty due to the April 1974 revolution, Angola's three main guerrilla groups agreed to establish a transitional government in January 1975.
Within two months, however, the FNLA, MPLA and UNITA were fighting each other and the country was well on its way to being divided into zones controlled by rival armed political groups. The superpowers were quickly drawn into the conflict, which became a flash point for the Cold War. The United States, Portugal, Brazil and South Africa supported the FNLA and UNITA. The Soviet Union and Cuba supported the MPLA.
Ceasefire with UNITA.
On February 22, 2002, Jonas Savimbi, the leader of UNITA, was killed in combat with government troops, and a cease-fire was reached by the two factions. UNITA gave up its armed wing and assumed the role of major opposition party. Although the political situation of the country began to stabilize, President Dos Santos has so far refused to institute regular democratic processes. Among Angola's major problems are a serious humanitarian crisis (a result of the prolonged war), the abundance of minefields, and the actions of guerrilla movements fighting for the independence of the northern exclave of Cabinda (Frente para a Libertação do Enclave de Cabinda). While most of the internally displaced have now returned home, the general situation for most Angolans remains desperate, and the development facing the government challenging as a consequence.
Politics.
Angola's motto is "Virtus Unita Fortior", a Latin phrase meaning "Virtue is stronger when united." The executive branch of the government is composed of the President, the Prime Minister (currently Paulo Kassoma) and the Council of Ministers. For decades, political power has been concentrated in the Presidency. The Council of Ministers, composed of all government ministers and vice ministers, meets regularly to discuss policy issues.
Governors of the 18 provinces are appointed by and serve at the pleasure of the president. The Constitutional Law of 1992 establishes the broad outlines of government structure and delineates the rights and duties of citizens. The legal system is based on Portuguese and customary law but is weak and fragmented, and courts operate in only twelve of more than 140 municipalities. A Supreme Court serves as the appellate tribunal; a Constitutional Court with powers of judicial review has never been constituted despite statutory authorization.
Parliamentary elections held on 5 September 2008, announced MPLA as the winning party with 81% of votes. The closest opposition party was UNITA with 10%. These elections were the first since 1992 and were described as only partly free but certainly not as fair. A White Book on the elections in 2008 lists up all irregularities surrounding the Parliamentary elections of 2008.
Angola scored poorly on the 2008 Ibrahim Index of African Governance. It was ranked 44 from 48 sub-Saharan African countries, scoring particularly badly in the areas of Participation and Human Rights, Sustainable Economic Opportunity and Human Development. The Ibrahim Index uses a number of different variables to compile its list which reflects the state of governance in Africa.
Exclave of Cabinda.
With an area of approximately, the Northern Angolan province of Cabinda is unique in being separated from the rest of the country by a strip, some wide, of the Democratic Republic of Congo (DRC) along the lower Congo river. Cabinda borders the Congo Republic to the north and north-northeast and the DRC to the east and south. The town of Cabinda is the chief population center.
According to a 1995 census, Cabinda had an estimated population of 600,000, approximately 400,000 of whom live in neighboring countries. Population estimates are, however, highly unreliable. Consisting largely of tropical forest, Cabinda produces hardwoods, coffee, cocoa, crude rubber and palm oil. The product for which it is best known, however, is its oil, which has given it the nickname, "the Kuwait of Africa". Cabinda's petroleum production from its considerable offshore reserves now accounts for more than half of Angola's output. Most of the oil along its coast was discovered under Portuguese rule by the Cabinda Gulf Oil Company (CABGOC) from 1968 onwards.
Since Portugal handed over sovereignty of its former overseas province of Angola to the local independentist groups (MPLA, UNITA, and FNLA), the territory of Cabinda has been a focus of separatist guerrilla actions opposing the Government of Angola (which has employed its military forces, the FAA – Forças Armadas Angolanas) and Cabindan separatists. The Cabindan separatists, FLEC-FAC, announced a virtual Federal Republic of Cabinda under the Presidency of N'Zita Henriques Tiago. One of the characteristics of the Cabindan independence movement is its constant fragmentation, into smaller and smaller factions, in a process which although not totally fomented by the Angolan government, is undoubtedly encouraged and duly exploited by it.
Military.
The Angolan Armed Forces (AAF) is headed by a Chief of Staff who reports to the Minister of Defense. There are three divisions—the Army (Exército), Navy (Marinha de Guerra, MGA), and National Air Force (Força Aérea Nacional, FAN). Total manpower is about 110,000. The army is by far the largest of the services with about 100,000 men and women. The Navy numbers about 3,000 and operates several small patrol craft and barges.
Air force personnel total about 7,000; its equipment includes Russian-manufactured fighters, bombers, and transport planes. There are also Brazilian-made EMB-312 Tucano for Training role, Czech-made L-39 for training and bombing role, Czech Zlin for training role and a variety of western made aircraft such as C-212\Aviocar, Sud Aviation Alouette III, etc. A small number of FAA personnel are stationed in the Democratic Republic of the Congo (Kinshasa) and the Republic of the Congo (Brazzaville).
Police.
The National Police departments are: Public Order, Criminal Investigation, Traffic and Transport, Investigation and Inspection of Economic Activities, Taxation and Frontier Supervision, Riot Police and the Rapid Intervention Police. The National Police are in the process of standing up an air wing, which will provide helicopter support for police operations. The National Police are also developing their criminal investigation and forensic capabilities. The National Police has an estimated 6,000 patrol officers, 2,500 Taxation and Frontier Supervision officers, 182 criminal investigators and 100 financial crimes detectives and around 90 Economic Activity Inspectors.
The National Police have implemented a modernization and development plan to increase the capabilities and efficiency of the total force. In addition to administrative reorganization; modernization projects include procurement of new vehicles, aircraft and equipment, construction of new police stations and forensic laboratories, restructured training programs and the replacement of AKM rifles with 9 mm UZIs for police officers in urban areas.
Geography.
At, Angola is the world's twenty-third largest country (after Niger). It is comparable in size to Mali and is nearly twice the size of the US state of Texas, or five times the area of the United Kingdom.
Angola is bordered by Namibia to the south, Zambia to the east, the Democratic Republic of the Congo to the north-east, and the South Atlantic Ocean to the west. The exclave of Cabinda also borders the Republic of the Congo to the north. Angola's capital, Luanda, lies on the Atlantic coast in the north-west of the country. Angola's average temperature on the coast is in the winter and in the summer.
Economy.
Angola's economy has undergone a period of transformation in recent years, moving from the disarray caused by a quarter century of civil war to being the fastest growing economy in Africa and one of the fastest in the world. In 2004, China's Eximbank approved a $2 billion line of credit to Angola. The loan is being used to rebuild Angola's infrastructure, and has also limited the influence of the International Monetary Fund in the country.
Growth is almost entirely driven by rising oil production which surpassed in late-2005 and was expected to grow to by 2007. Control of the oil industry is consolidated in Sonangol Group, a conglomerate which is owned by the Angolan government. In December 2006, Angola was admitted as a member of OPEC. The economy grew 18% in 2005, 26% in 2006 and 17.6% in 2007 and it's expected to stay above 10% for the rest of the decade. The security brought about by the 2002 peace settlement has led to the resettlement of 4 million displaced persons, thus resulting in large-scale increases in agriculture production.
The country's economy has grown since achieving political stability in 2002. However, it faces huge social and economic problems as a result of the almost continual state of conflict from 1961 onwards, although the highest level of destruction and socio-economic damage took place after the 1975 independence, during the long years of civil war. The oil sector, with its fast-rising earnings has been the main driving force behind improvements in overall economic activity – nevertheless, poverty remains widespread. Anti-corruption watchdog Transparency International rated Angola one of the 10 most corrupt countries in the world in 2005. The capital city is the most developed and the only large economic centre worth mentioning in the country, however, slums called "musseques", stretch for miles beyond Luanda's former city limits.
According to the Heritage Foundation, a conservative American think tank, oil production from Angola has increased so significantly that Angola now is China's biggest supplier of oil.
Before independence in 1975, Angola was a breadbasket of southern Africa and a major exporter of bananas, coffee and sisal, but three decades of civil war (1975–2002) destroyed the fertile countryside, leaving it littered with landmines and driving millions into the cities. The country now depends on expensive food imports, mainly from South Africa and Portugal, while more than 90 percent of farming is done at family and subsistence level. Thousands of Angolan small-scale farmers are trapped in poverty.
Demographics.
Angola is composed of Ovimbundu 37%, Mbundu 25%, Bakongo 13%, "mestiços" (mixed European and native African) 2%, European 1%, and 22% 'other' ethnic groups. The two Mbundu and Ovimbundu nations combined form a majority of the population, at 62%.
It is estimated that Angola was host to 12,100 refugees and 2,900 asylum seekers by the end of 2007. 11,400 of those refugees were originally from the Democratic Republic of Congo (Congo-Kinshasa) who arrived in the 1970s. As of 2008 there were an estimated 400,000 DRC migrant workers, at least 30,000 Portuguese, and 100,000+ Chinese living in Angola. Prior to independence in 1975, Angola had a community of approximately 500,000 Portuguese.
Languages.
Portuguese is spoken as a first language by 80% of the population, and as a second language by another 20%. The dominance of Portuguese over the native Kimbundu and other African languages is due to a strong influence from Portugal, as opposed to in Mozambique, which being more remote from the Lusosphere, retained a majority of Bantu language speakers.
Religion.
Christianity is the major religion in Angola. The World Christian Database states that the Angolan population is 93.5% Christian, 4.7% ethnoreligionist (indigenous), 0.6% Muslim, 0.9% Agnostic and 0.2% non-religious. However, other sources put the percent of Christians at 53% with the remaining population adhering to indigenous beliefs. According to these sources, of Christians in Angola, 72% are Roman Catholic, and 28% are Baptist, Presbyterian, Reformed Evangelical, Pentecostal, Methodists and a few small Christian sects.
In a study assessing nations' levels of religious regulation and persecution with scores ranging from 0–10 where 0 represented low levels of regulation or persecution, Angola was scored 0.8 on Government Regulation of Religion, 4.0 on Social Regulation of Religion, 0 on Government Favoritism of Religion and 0 on Religious Persecution.
The largest Protestant denominations include the Methodists, Baptists, Congregationalists (United Church of Christ), and Assemblies of God. The largest syncretic religious group is the Kimbanguist Church, whose followers believe that a mid-20th century Congolese pastor named Joseph Kimbangu was a prophet. A small portion of the country's rural population practices animism or traditional indigenous religions. There is a small Islamic community based around migrants from West Africa.
In colonial times, the country's coastal populations primarily were Catholic while the Protestant mission groups were active inland. With the massive social displacement caused by 26 years of civil war, this rough division is no longer valid.
Foreign missionaries were very active prior to independence in 1975, although the Portuguese colonial authorities expelled many Protestant missionaries and closed mission stations based on the belief that the missionaries were inciting pro-independence sentiments. Missionaries have been able to return to the country since the early 1990s, although security conditions due to the civil war have prevented them from restoring many of their former inland mission stations.
The Roman Catholic denomination mostly keeps to itself in contrast to the major Protestant denominations which are much more active in trying to win new members. The major Protestant denominations provide help for the poor in the form of crop seeds, farm animals, medical care and education in the English language, math, history and religion.
Health.
A 2007 survey concluded that low and deficient niacin status was common in Angola. Epidemics of cholera, malaria, rabies and African hemorrhagic fevers like Marburg hemorrhagic fever, are common diseases in several parts of the country. Many regions in this country have high incidence rates of tuberculosis and high HIV prevalence rates. Dengue, filariasis, leishmaniasis, and onchocerciasis (river blindness) are other diseases carried by insects that also occur in the region. Angola has one of the highest infant mortality rates in the world and the world's 2nd lowest life expectancies.
Education.
Although by law, education in Angola is compulsory and free for 8 years, the government reports that a certain percentage of students are not attending school due to a lack of school buildings and teachers. Students are often responsible for paying additional school-related expenses, including fees for books and supplies.
In 1999, the gross primary enrollment rate was 74 percent and in 1998, the most recent year for which data are available, the net primary enrollment rate was 61 percent. Gross and net enrollment ratios are based on the number of students formally registered in primary school and therefore do not necessarily reflect actual school attendance. There continue to be significant disparities in enrollment between rural and urban areas. In 1995, 71.2 percent of children ages 7 to 14 years were attending school. It is reported that higher percentages of boys attend school than girls. During the Angolan Civil War (1975–2002), nearly half of all schools were reportedly looted and destroyed, leading to current problems with overcrowding.
The Ministry of Education hired 20,000 new teachers in 2005, and continued to implement teacher trainings. Teachers tend to be underpaid, inadequately trained, and overworked (sometimes teaching two or three shifts a day). Teachers also reportedly demand payment or bribes directly from their students. Other factors, such as the presence of landmines, lack of resources and identity papers, and poor health also prevent children from regularly attending school. Although budgetary allocations for education were increased in 2004, the education system in Angola continues to be extremely under-funded.
Literacy is quite low, with 67.4% of the population over the age of 15 able to read and write in Portuguese. 82.9% of males and 54.2% of women are literate as of 2001. Since independence from Portugal in 1975, a number of Angolan students continued to be admitted every year at high schools, polytechnical institutes, and universities Portuguese, Brazilian and Cuban through bilateral agreements; in general these students belong to the Angolan elites.
Culture.
Portugal ruled over Angola for 400 years and both countries share cultural aspects: language (Portuguese) and main religion (Roman Catholic Christianity). The Angolan culture is mostly native Bantu which was mixed with Portuguese culture.
---END.OF.DOCUMENT---
Politics of Angola.
Politics of Angola takes place in a framework of a presidential republic, whereby the President of Angola is both head of state and head of government, and of a multi-party system. Executive power is exercised by the government. Legislative power is vested in both the government and parliament. Angola changed from a one-party Marxist-Leninist system ruled by the MPLA to a formal multiparty democracy following the 1992 elections. President dos Santos won the first round election with more than 49% of the vote to Jonas Savimbi's 40%. A runoff never has taken place. The subsequent renewal of civil war and collapse of the Lusaka Protocol have left much of this process stillborn, but democratic forms exist, notably the National Assembly.
Currently, political power is concentrated in the Presidency. The executive branch of the government is composed of the President, the Prime Minister (currently Paulo Kassoma) and Council of Ministers. The Council of Ministers, composed of all government ministers and vice ministers, meets regularly to discuss policy issues. Governors of the 18 provinces are appointed by and serve at the pleasure of the president. The Constitutional Law of 1992 establishes the broad outlines of government structure and the rights and duties of citizens. The legal system is based on Portuguese and customary law but is weak and fragmented. Courts operate in only 12 of more than 140 municipalities. A Supreme Court serves as the appellate tribunal; a Constitutional Court with powers of judicial review has never been constituted despite statutory authorization.
The 26-year long civil war has ravaged the country's political and social institutions. The UN estimates of 1.8 million internally displaced persons (IDPs), while generally the accepted figure for war-affected people is 4 million. Daily conditions of life throughout the country and specifically Luanda (population approximately 4 million) mirror the collapse of administrative infrastructure as well as many social institutions. The ongoing grave economic situation largely prevents any government support for social institutions. Hospitals are without medicines or basic equipment, schools are without books, and public employees often lack the basic supplies for their day-to-day work.
Currently, a constitutional commission is putting together a new constitutions. According to the commission, which is composed of 45 permanent members from the main political parties, a new constitution will be ready by the end of the first quarter of 2010.
Legislative branch.
The National Assembly ("Assembleia Nacional") has 223 members, elected for a four year term, 130 members by proportional representation, 90 members in provincial districts, and 3 members to represent Angolans abroad. The next general elections, due for 1997, have been rescheduled for 5 September 2008. The ruling party MPLA won 82% (191 seats in the National Assembly) and the main opposition party won only 10% (16 seats). The elections however have been described as only partly free but certainly not fair. A White Book on the elections in 2008 lists up all irregularities surrounding the Parliamentary elections of 2008.
Political parties and elections.
Parliamentary elections were held in September 2008. These elections were the first since 1992. Presidential elections are planned for 2009.
Judicial branch.
Supreme Court or Tribunal da Relacao, judges of the Supreme Court are appointed by the president
Administrative divisions.
Angola has eighteen provinces (provincias, singular - provincia); Bengo, Benguela, Bie, Cabinda, Cuando Cubango, Cuanza Norte, Cuanza Sul, Cunene, Huambo, Huila, Luanda, Lunda Norte, Lunda Sul, Malanje, Moxico, Namibe, Uige, Zaire
Political pressure groups and leaders.
Front for the Liberation of the Enclave of Cabinda or FLEC [N'zita Henriques TIAGO; Antonio Bento BEMBE]
International organization participation.
ACP, AfDB, CEEAC, ECA, FAO, G-77, IAEA, IBRD, ICAO, ICCt (signatory), ICFTU, ICRM, IDA, IFAD, IFC, IFRCS, ILO, IMF, IMO, Interpol, IOC, IOM, ISO (correspondent), ITU, Non-Aligned dfrfgbfghgCouncil (temporary), UNCTAD, UNESCO, UNIDO, UPU, WCO, WFTU, WHO, WIPO, WMO, WToO, WTrO
---END.OF.DOCUMENT---
Foreign relations of Angola.
The foreign relations of Angola are based on Angola's strong support of U.S. foreign policy as the Angolan economy is dependent on U.S. foreign aid.
From 1975 to 1989, Angola was aligned with the Eastern bloc, in particular the Soviet Union, Libya, and Cuba. Since then, it has focused on improving relationships with Western countries, cultivating links with other Portuguese-speaking countries, and asserting its own national interests in Central Africa through military and diplomatic intervention. In 1993, it established formal diplomatic relations with the United States. It has entered the Southern African Development Community as a vehicle for improving ties with its largely Anglophone neighbors to the south. Zimbabwe and Namibia joined Angola in its military intervention in the Democratic Republic of the Congo, where Angolan troops remain in support of the Joseph Kabila government. It also has intervened in the Republic of the Congo (Brazzaville) to support the existing government in that country.
Since 1998, Angola has successfully worked with the UN Security Council to impose and carry out sanctions on UNITA. More recently, it has extended those efforts to controls on conflict diamonds, the primary source of revenue for UNITA. At the same time, Angola has promoted the revival of the Community of Portuguese-Speaking Countries (CPLP) as a forum for cultural exchange and expanding ties with Portugal (its former ruler) and Brazil (which shares many cultural affinities with Angola) in particular.
Cape Verde.
Cape Verde signed a friendship accord with Angola in December 1975, shortly after Angola gained its independence. Cape Verde and Guinea-Bissau served as stop-over points for Cuban troops on their way to Angola to fight UNITA rebels and South African troops. Prime Minister Pedro Pires sent FARP soldiers to Angola where they served as the personal bodyguards of Angolan President José Eduardo dos Santos.
Democratic Republic of the Congo.
Many thousands of Angolans fled the country after the civil war. More than 20,000 people were forced to leave the Democratic Republic of the Congo in 2009, an action the DR Congo said was in retaliation for regular expulsion of Congolese diamond miners who were in Angola illegally. Angola sent a delegation to DR Congo's capital Kinshasa and succeeded in stopping government-forced expulsions which had become a "tit-for-tat" immigration dispute. "Congo and Angola have agreed to suspend expulsions from both sides of the border," said Lambert Mende, DR Congo information minister, in October 2009. "We never challenged the expulsions themselves; we challenged the way they were being conducted — all the beating of people and looting their goods, even sometimes their clothes," Mende said.
Namibia.
Namibia borders Angola to the south. In 1999 Namibia signed a mutual defense pact with its northern neighbor Angola.
This affected the Angolan Civil War that had been ongoing since Angola's independence in 1975. Namibia's ruling party SWAPO sought to support the ruling party MPLA in Angola against the rebel movement UNITA, whose stronghold is in southern Angola, bordering to Namibia. The defence pact allowed Angolan troops to use Namibian territory when attacking Jonas Savimbi's UNITA.
Nigeria.
Angolan-Nigerian relations are primarily based on their roles as oil exporting nations. Both are members of the Organization of the Petroleum Exporting Countries, the African Union and other multilateral organizations.
South Africa.
Angola-South Africa relations are quite strong as the ruling parties in both nations, the African National Congress in South Africa and the MPLA in Angola, fought together during the Angolan Civil War and South African Border War. They fought against UNITA rebels, based in Angola, and the apartheid-era government in South Africa who supported them. Nelson Mandela mediated between the MPLA and UNITA factions during the last years of Angola's civil war.
Zimbabwe.
Angola-Zimbabwe relations have remained cordial since the birth of both states, Angola in 1975 and Zimbabwe in 1979, during the Cold War. While Angola's foreign policy shifted to a pro-U.S. stance based on substantial economic ties, under the rule of President Robert Mugabe Zimbabwe's ties with the West soured in the late 1990s.
France.
Relations between the two countries have not always been cordial due to the former French government's policy of supporting militant separatists in Angola's Cabinda province and the international Angolagate scandal embarrassed both governments by exposing corruption and illicit arms deals. Following French President Nicolas Sarkozy's visit in 2008, relations have improved.
Portugal.
Angola-Portugal relations have significantly improved since the Angolan government abandoned communism and nominally embraced democracy in 1991, embracing a pro-U.S. and to a lesser degree pro-Europe foreign policy. Portugal ruled Angola for 400 years, colonizing the territory from 1483 until independence in 1975. Angola's war for independence did not end in a military victory for either side, but was suspended as a result of a coup in Portugal that replaced the Caetano regime.
Russia.
Russia has an embassy in Luanda. Angola has an embassy in Moscow and an honorary consulate in Saint Petersburg. Angola and the precursor to Russia, the Soviet Union, established relations upon Angola's independence.
Brazil.
Commercial and economic ties dominate the relations of each country. Parts of both countries were part of the Portuguese Empire from the early 16th century until Brazil's independence in 1822. As of November 2007, "trade between the two countries is booming as never before"
Cuba.
During Angola's civil war Cuban forces fought to install a Marxist-Leninist MPLA-PT government, against Western-backed UNITA and FLNA guerrillas and the South-African army.
United States.
From the mid-1980s through at least 1992, the United States was the primary source of military and other support for the UNITA rebel movement, which was led from its creation through 2002 by Jonas Savimbi. The U.S. refused to recognize Angola diplomatically during this period.
Relations between the United States of America and the Republic of Angola (formerly the People's Republic of Angola) have warmed since Angola's ideological renunciation of Marxism before the 1992 elections.
Israel.
Angola-Israel relations, primarily based on trade and pro-United States foreign policies, are excellent. In March 2006, the trade volume between the two countries amounted to $400 million. The Israeli ambassador to Angola is Avraham Benjamin.[1] In 2005, President José Eduardo dos Santos visited Israel.
Japan.
As of 2007, economic relations played "a fundamental role in the bilateral relations between the two governments". Japan has donated towards demining following the civil war.
People's Republic of China.
Chinese Prime Minister Wen Jiabao visited Angola in June 2006, offering a US$9 billion loan for infrastructure improvements in return for petroleum. The PRC has invested heavily in Angola since the end of the civil war in 2002. João Manuel Bernardo, the current ambassador of Angola to China, visited the PRC in November 2007.
In February 2006, Angola surpassed Saudi Arabia to become the number one supplier of oil to China.
Vietnam.
Angola-Vietnam relations were established in August 1971, four years before Angola gained its independence, when future President of Angola Agostinho Neto visited Vietnam. Angola and Vietnam have steadfast partners as both transitioned from Cold War-era foreign policies of international communism to pro-Western pragmatism following the fall of the Soviet Union.
---END.OF.DOCUMENT---
Albert Sidney Johnston.
Albert Sidney Johnston (February 2, 1803 – April 6, 1862) was a career United States Army officer, a Texas Army general, and a Confederate States general. He saw extensive combat during his military career, fighting actions in the Texas War of Independence, the Mexican-American War, the Utah War, as well as the American Civil War.
Considered by Confederate President Jefferson Davis to be the finest general officer in the Confederacy before the emergence of Robert E. Lee, he was killed early in the Civil War at the Battle of Shiloh and was the highest ranking officer, Union or Confederate, killed during the entire war. Davis believed the loss of Johnston "was the turning point of our fate"
Early life.
Johnston was born in Washington, Kentucky, the youngest son of Dr. John and Abigail Harris Johnston. His father was a native of Salisbury, Connecticut. Although Albert Johnston was born in Kentucky, he lived much of his life in Texas, which he considered his home. He was first educated at Transylvania University in Lexington, where he met fellow student Jefferson Davis. Both were appointed to the United States Military Academy, Davis two years behind Johnston. In 1826 Johnston graduated eighth of 41 cadets in his class from West Point with a commission as a brevet second lieutenant in the 2nd U.S. Infantry.
Johnston was assigned to posts in New York and Missouri and served in the Black Hawk War in 1832 as chief of staff to Bvt. Brig. Gen. Henry Atkinson. In 1829 he married Henrietta Preston, sister of Kentucky politician and future civil war general William Preston. He resigned his commission in 1834 to return to Kentucky to care for his dying wife, who succumbed two years later to tuberculosis. They had one son, Col. William Preston Johnston, who would also serve in the Confederate Army.
Texas Army.
In April 1834, Johnston took up farming in Texas, but enlisted as a private in the Texas Army during the Texas War of Independence against the Republic of Mexico in 1836. One month later, Johnston was promoted to major and the position of aide-de-camp to General Sam Houston. He was named Adjutant General as a colonel in the Republic of Texas Army on August 5, 1836. On January 31, 1837, he became senior brigadier general in command of the Texas Army.
On February 7, 1837, he fought in a duel with Texas Brig. Gen. Felix Huston, challenging each other for the command of the Texas Army; Johnston refused to fire on Huston and lost the position after he was wounded in the pelvis. The second president of the Republic of Texas, Mirabeau B. Lamar, appointed him Secretary of War on December 22, 1838. Johnston was to provide the defense of the Texas border against Mexican invasion, and in 1839 conducted a campaign against Indians in northern Texas. In February 1840, he resigned and returned to Kentucky, where he married Eliza Griffin in 1843. They settled on a large plantation he named China Grove in Brazoria County, Texas.
U.S. Army.
Johnston returned to the Texas Army during the Mexican-American War under General Zachary Taylor as a colonel of the 1st Texas Rifle Volunteers. The enlistments of his volunteers ran out just before the Battle of Monterrey. Johnston managed to convince a few volunteers to stay and fight as he himself served as the inspector general of volunteers and fought at the battles of Monterrey and Buena Vista. Johnston remained on his plantation after the war until he was appointed by President Taylor to the U.S. Army as a major and was made a paymaster in December 1849. He served in that role for more than five years, making six tours, and traveling more than 4,000 miles annually on the Indian frontier of Texas. He served on the Texas frontier and elsewhere in the West. In 1855 President Franklin Pierce appointed him colonel of the new 2nd U.S. Cavalry (the unit that preceded the modern 5th U.S.), a new regiment, which he organized. As a key figure in the Utah War, he led U.S. troops who established a non-Mormon government in the formerly Mormon territory. He received a brevet promotion to brigadier general in 1857 for his service in Utah. He spent 1860 in Kentucky until December 21, when he sailed for California to take command of the Department of the Pacific.
Civil War.
At the outbreak of the Civil War, Johnston was the commander of the U.S. Army Department of the Pacific in California. He was approached by some Californians who urged him to take his forces east to join the Union against the Confederacy. He resigned his commission on April 9, 1861, as soon as he heard of the secession of Texas. He moved to Los Angeles where he had family and remained there until May when, suspected by local Union authorities, he evaded arrest and joined the Los Angeles Mounted Rifles as a private, leaving Warner's Ranch May 27. He participated in their trek across the southwestern deserts to Texas, crossing the Colorado River into the Confederate Territory of Arizona on July 4, 1861. He reached Richmond, Virginia, on or about September 1, 1861. There Johnston was appointed a full general by his friend, Jefferson Davis. On May 30, 1861, Johnston became the second highest ranking Confederate general (after the little-known Samuel Cooper) as commander of the Western Department. He raised the Army of Mississippi to defend Confederate lines from the Mississippi River to Kentucky and the Allegheny Mountains.
Although the Confederate States Army won a morale-boosting victory at First Battle of Bull Run in the East in 1861, matters in the West turned ugly by early 1862. Johnston's subordinate generals lost Fort Henry on February 6, 1862, and Fort Donelson on February 16, 1862, to Union Brig. Gen. Ulysses S. Grant. Johnston has been faulted for poor judgment in selecting Brig. Gens. Lloyd Tilghman and John B. Floyd for those crucial positions and for not supervising adequate construction of the forts. Union Maj. Gen. Don Carlos Buell subsequently captured the vital city of Nashville, Tennessee. Gen. P.G.T. Beauregard was sent west to join Johnston and they organized their forces at Corinth, Mississippi, planning to ambush Grant's forces at Pittsburg Landing, Tennessee.
Shiloh.
Johnston concentrated many of his forces from around the theater and launched a massive surprise attack against Grant at the Battle of Shiloh on April 6, 1862. As the Confederate forces overran the Union camps, Johnston seemed to be everywhere, personally leading and rallying troops up and down the line. At about 2:30 p.m., while leading one of those charges, he was wounded, taking a bullet behind his right knee. He did not think the wound serious at the time, and sent his personal physician to attend to some wounded Union soldiers instead. The bullet had in fact clipped his popliteal artery and his boot was filling up with blood. Within a few minutes Johnston was observed by his staff to be nearly fainting off his horse, and asked him if he was wounded, to which he replied "Yes, and I fear seriously." It is possible that Johnston's duel in 1837 had caused nerve damage or numbness to that leg and that he did not feel the wound to his leg as a result. Johnston was taken to a small ravine, where he bled to death in minutes.
It is probable that a Confederate soldier fired the fatal round. No Union soldiers were observed to have ever gotten behind Johnston during the fatal charge, while it is known that many Confederates were firing at the Union lines while Johnston charged well in advance of his soldiers. He was the highest-ranking casualty of the war on either side, and his death was a strong blow to the morale of the Confederacy. Jefferson Davis considered him the best general in the country; this was two months before the emergence of Robert E. Lee as the pre-eminent general of the Confederacy.
Epitaph.
Johnston was buried in New Orleans, Louisiana. In 1866, a joint resolution of the Texas Legislature was passed to have his body reinterred to the Texas State Cemetery in Austin The re-interment occurred in 1867. Forty years later, the state appointed Elisabet Ney to design a monument and sculpture of him to be erected at his gravesite.
The Texas Historical Commission has erected a historical marker near the entrance of what was once his plantation. An adjacent marker was erected by the San Jacinto Chapter of the Daughters of The Republic of Texas and the Lee, Roberts, and Davis Chapter of the United Daughters of the Confederate States of America.
The University of Texas at Austin has also recognized Johnston with a statue on the South Mall.
---END.OF.DOCUMENT---
Android.
An android is a robot or synthetic organism designed to look and act like a human. Until recently, androids have largely remained within the domain of science fiction, frequently seen in film and television. However, Honda and several other corporations and private enterprises have developed impressive androids although there is a long way to go to make them fully human like.
Etymology.
The word derives from ανδρός, the genitive of the Greek ανήρ "anēr", meaning "man", and the suffix "-eides", used to mean "of the species; alike" (from "eidos," "species"). Though the word derives from a gender-specific root, its usage in English is usually gender neutral. The term was first mentioned by St. Albertus Magnus in 1270 and was popularized by the French writer Villiers in his 1886 novel "L'Ève future", although the term "android" appears in US patents as early as 1863 in reference to miniature human-like toy automatons.
The term "droid", invented by George Lucas in "Star Wars" (1977) but now used widely within science fiction, originated as an abbreviation of "android", but has been used by Lucas and others to mean any robot, including distinctly non-humaniform machines like R2-D2. Another abbreviation, "andy", coined as a pejorative by writer Philip K. Dick in his novel "Do Androids Dream of Electric Sheep?", has seen some limited further currency, e.g., in the TV series "Total Recall 2070".
Projects.
Androids have been mainly an element of science fiction, yet it is increasingly becoming a reality in Japan and South Korea. The two countries are in a heated competition to make them a commercial success in the global market and have developed a handful of successful androids so far.
Japan.
The Intelligent Robotics Lab, directed by Hiroshi Ishiguro at Osaka University, and Kokoro Co., Ltd. have demonstrated the Actroid at Expo 2005 in Aichi Prefecture, Japan. In 2006, Kokoro Co. developed a new "DER 2" android. The height of the human body part of DER2 is 165 cm. There are 47 mobile points. DER2 can not only change its expression but also move its hands and feet and twist its body. The "air servosystem" which Kokoro Co. developed originally is used for the actuator. As a result of having an actuator controlled precisely with air pressure via a servosystem, the movement is very fluid and there is very little noise. DER2 realized a slimmer body than that of the former version by using a smaller cylinder. Outwardly DER2 has a more beautiful proportion. Compared to the previous model, DER2 has thinner arms and a wider repertoire of expressions. The smoothness of her movement has also been improved, making it now even more likely for the uninitiated to confuse her with an actual human being. Once programmed, she is able to choreograph her motions and gestures with her voice.
The Intelligent Mechatronics Lab, directed by Hiroshi Kobayashi at the Tokyo University of Science, has developed an android head called "Saya", which was exhibited at Robodex 2002 in Yokohama, Japan. There are several other initiatives around the world involving humanoid research and development at this time, which will hopefully introduce a broader spectrum of realized technology in the near future. Now Saya is "working" at the Science University of Tokyo as a guide.
The Waseda University (Japan) and NTT Docomo's manufacturers have succeeded in creating a shape-shifting robot "WD-2". It is capable of changing its face. At first, the creators decided the positions of the necessary points to express the outline, eyes, nose, and so on of a certain person. The robot expresses his/her face by moving all points to the decided positions, they say. The first version of the robot was first developed back in 2003. After that, a year later, they made a couple of major improvements to the design. The robot features an elastic mask made from the average head dummy. It uses a driving system with a 3DOF unit. The WD-2 robot can change its facial features by activating specific facial points on a mask, with each point possessing three degrees of freedom. This one has 17 facial points, for a total of 56 degrees of freedom. As for the materials they used, the WD-2's mask is fabricated with a highly elastic material called Septom, with bits of steel wool mixed in for added strength. Other technical features reveal a shaft driven behind the mask at the desired facial point, driven by a DC motor with a simple pulley and a slide screw. Apparently, the researchers can also modify the shape of the mask based on actual human faces. To "copy" a face, they need only a 3D scanner to determine the locations of an individual's 17 facial points. After that, they are then driven into position using a laptop and 56 motor control boards. In addition, the researchers also mention that the shifting robot can even display an individual's hair style and skin color if a photo of their face is projected onto the 3D mask.
Korea.
KITECH researched and developed EveR-1, an android interpersonal communications model capable of emulating human emotional expression via facial "musculature" and capable of rudimentary conversation, having a vocabulary of around 400 words. She is tall and weighs, matching the average figure of Korean women in their twenties. EveR-1's name derives from the Biblical Eve, plus the letter "r" for "robot". EveR-1's advanced computing processing power enables speech recognition and vocal synthesis, at the same time processing lip synchronization and visual recognition by 90-degree micro-CCD cameras with face recognition technology. An independent microchip inside her artificial brain handles gesture expression, body coordination, and emotion expression. Her whole body is made of highly advanced synthetic jelly silicon and with 60 artificial joints in her face, neck, and lower body; she is able to demonstrate realistic facial expressions and sing while simultaneously dancing. In South Korea, the Ministry of Information and Communication has an ambitious plan to put a robot in every household by 2020. Several robot cities have been planned for the country: the first will be built in 2009 at a cost of 500 billion won, of which 50 billion is direct government investment. The new robot city will feature research and development centers for manufacturers and part suppliers, as well as exhibition halls and a stadium for robot competitions. The country's new Robotics Ethics Charter will establish ground rules and laws for human interaction with robots in the future, setting standards for robotics users and manufacturers, as well as guidelines on ethical standards to be programmed into robots to prevent human abuse of robots and vice versa.
United States.
Hanson Robotics, Inc., of Texas and KAIST produced an android portrait of Albert Einstein, using Hanson's facial android technology mounted on KAIST's life-size walking bipedal robot body. This Einstein android, also called "Albert Hubo", thus represents the first full-body walking android in history (see video at). Hanson Robotics, the FedEx Institute of Technology, and the University of Texas at Arlington also developed the android portrait of sci-fi author Philip K. Dick (creator of "Do Androids Dream of Electric Sheep?", the basis for the film "Blade Runner"), with full conversational capabilities that incorporated thousands of pages of the author's works. In 2005, the PKD android won a first place artificial intelligence award from AAAI.
Usage and distinctions.
Although human morphology is not necessarily the ideal form for working robots, the fascination in developing robots that can mimic it can be found historically in the assimilation of two concepts: "simulacra" (devices that exhibit likeness) and "automata" (devices that have independence).
The term "android" was popularized by the French author Auguste Villiers de l'Isle-Adam in his work "Tomorrow's Eve" (1886), featuring an artificial humanlike robot named Hadaly. As said by the officer in the story, "In this age of Realien advancement, who knows what goes on in the mind of those responsible for these mechanical dolls."
Although Karel Čapek's robots in "R.U.R. (Rossum's Universal Robots)" (1921) - the play that introduced the word "robot" to the world - were organic artificial humans, the word "robot" has come to primarily refer to mechanical humans, animals, and other beings. The term "android" can mean either one of these, while a cyborg ("cybernetic organism" or "bionic man") would be a creature that is a combination of organic and mechanical parts.
The word "android" is a combination of Ancient Greek "andros" and the suffix "-oid", which literally means "in the form of a man (male human being)". This could be contrasted with the more general term "anthropoid", which means humanlike. According to this fashion, a female human-like robot would be a "gynoid".
Fiction.
Androids are a staple of science fiction. Authors have used the term "android" in more diverse ways than "robot" or "cyborg". In some fictional works, the difference between a robot and android is only their appearance, with androids being made to look like humans on the outside but with robot-like internal mechanics. In other stories, authors have used the word "android" to mean a wholly organic, yet artificial, creation. Other fictional depictions of androids fall somewhere in between.
One thing common to most fictional androids, though, is that the real-life technological challenges associated with creating thoroughly human-like robots – such as the creation of strong artificial intelligence – are assumed to have been solved. Fictional androids are generally depicted as mentally and physically equal or superior to humans – moving, thinking and speaking as fluidly as them.
The tension between the nonhuman substance and the human appearance – or even human ambitions – of androids is the dramatic impetus behind most of their fictional depictions. Some android heroes seek, like Pinocchio, to become human, as in the films "Bicentennial Man" and "A.I. Artificial Intelligence", or Data in the science-fiction show '. Others, as in the film "Westworld", rebel against abuse by careless humans. Android hunter Deckard in American writer Philip K. Dick's "Do Androids Dream of Electric Sheep?" discovers that his targets are, in some ways, more human than he is. Android stories, therefore, are not essentially stories "about" androids; they are stories about the human condition and what it means to be human.
One aspect of writing about the meaning of humanity is to use discrimination against androids as a mechanism for exploring racism in society, as in "Do Androids Dream of Electric Sheep?" and its film adaptation "Blade Runner". Perhaps the clearest example of such an exploration is John Brunner's 1968 novel "Into the Slave Nebula", where the blue-skinned android slaves are explicitly shown to be fully human. More recently, the androids Lance Bishop and Annalee Call in the films "Aliens" and "Alien Resurrection" are used as vehicles for exploring how humans deal with the presence of an "Other".
Female androids, or "gynoids", are often seen in science fiction, and can be viewed as a continuation of the long tradition of men attempting to create the stereotypical "perfect woman". Examples include the Greek myth of "Pygmalion", the fembots in the Austin Powers series, and the female robot Maria in Fritz Lang's "Metropolis". Some gynoids, like Pris in "Blade Runner", are designed as sex-objects, with the intent of "pleasing men's violent sexual desires". Fiction about gynoids or female cyborgs has therefore been described as reinforcing "essentialist ideas of femininity", although others have suggested that the treatment of female androids is a way of exploring racism and misogyny in society.
---END.OF.DOCUMENT---
List of anthropologists.
Please make no further additions to the list.
For scientists and scholars of anthropology, refer to the category '.
__NOTOC__
---END.OF.DOCUMENT---
Actinopterygii.
The Actinopterygii constitute the class or sub-class of the ray-finned fishes.
The ray-finned fishes are so called because they possess lepidotrichia or "fin rays", their fins being webs of skin supported by bony or horny spines ("rays"), as opposed to the fleshy, lobed fins that characterize the class Sarcopterygii which also, however, possess lepidotrichia. These actinopterygian fin rays attach directly to the proximal or basal skeletal elements, the radials, which represent the link or connection between these fins and the internal skeleton (e.g., pelvic and pectoral girdles).
In terms of numbers, actinopterygians are the dominant class of vertebrates, comprising nearly 95% of the 25,000 species of fish. They are ubiquitous throughout fresh water and marine environments from the deep sea to the highest mountain streams. Extant species can range in size from "Paedocypris", at, to the massive Ocean Sunfish, at, and the long-bodied Oarfish, to at least.
Fossil record.
The earliest known fossil Actinopterygiian is "Andreolepis hedei", dating back 420 million years (Late Silurian). This microvertebrate has been uncovered in Russia, Sweden, and Estonia.
Classification.
Traditionally three grades of actinopterygians have been recognised: the Chondrostei, Holostei, and Teleostei. Some morphological evidence suggests that the second is paraphyletic and should be abandoned; however, recent work based on more complete sampling of fossil taxa, and also an analysis of DNA sequence data from the complete mitochondrial genome, supports its recognition. Nearly all living bony fishes are teleosts.
A listing of the different groups is given below, down to the level of orders, arranged in what has been suggested to represent the evolutionary sequence down to the level of order based primarily on the long history of morphological studies. This classification, like any other taxonomy based on phylogenetic research is in a state of flux. Many of these ordinal and higher-level groupings have not been supported in both the recent morphological and molecular literature. Examples of demonstrably paraphyletic or unnatural groups include the Paracanthopterygii, Scorpaeniformes, and Perciformes. The listing follows FishBase with notes when this differs from Nelson and ITIS.
---END.OF.DOCUMENT---
Albert Einstein.
Albert Einstein (;; 14 March 1879–18 April 1955) was a German-born Swiss-American theoretical physicist, philosopher and author who is widely regarded as one of the most influential and best known scientists and intellectuals of all time. He is often regarded as the father of modern physics. He received the 1921 Nobel Prize in Physics "for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect."
His many contributions to physics include the special and general theories of relativity, the founding of relativistic cosmology, the first post-Newtonian expansion, explaining the perihelion advance of Mercury, prediction of the deflection of light by gravity and gravitational lensing, the first fluctuation dissipation theorem which explained the Brownian movement of molecules, the photon theory and wave-particle duality, the quantum theory of atomic motion in solids, the zero-point energy concept, the semiclassical version of the Schrödinger equation, and the quantum theory of a monatomic gas which predicted Bose–Einstein condensation.
Einstein published more than 300 scientific and over 150 non-scientific works. Einstein additionally wrote and commentated prolifically on numerous philosophical and political issues.
Early life and education.
Albert Einstein was born in Ulm, in the Kingdom of Württemberg in the German Empire on 14 March 1879. His father was Hermann Einstein, a salesman and engineer. His mother was Pauline Einstein (née Koch). In 1880, the family moved to Munich, where his father and his uncle founded " Elektrotechnische Fabrik J. Einstein & Cie," a company that manufactured electrical equipment based on direct current.
The Einsteins were non-observant Jews. Their son attended a Catholic elementary school from the age of five until ten. Although Einstein had early speech difficulties, he was a top student in elementary school. As he grew, Einstein built models and mechanical devices for fun and began to show a talent for mathematics. In 1889 Max Talmud (later changed to Max Talmey) introduced the ten-year old Einstein to key texts in science, mathematics and philosophy, including Kant’s "Critique of Pure Reason" and Euclid’s "Elements" (which Einstein called the "holy little geometry book"). Talmud was a poor Jewish medical student from Poland. The Jewish community arranged for Talmud to take meals with the Einsteins each week on Thursdays for six years. During this time Talmud wholeheartedly guided Einstein through many secular educational interests.
In 1894, his father’s company failed: Direct current (DC) lost the War of Currents to alternating current (AC). In search of business, the Einstein family moved to Italy, first to Milan and then, a few months later, to Pavia. When the family moved to Pavia, Einstein stayed in Munich to finish his studies at the Luitpold Gymnasium. His father intended for him to pursue electrical engineering, but Einstein clashed with authorities and resented the school’s regimen and teaching method. He later wrote that the spirit of learning and creative thought were lost in strict rote learning. In the spring of 1895, he withdrew to join his family in Pavia, convincing the school to let him go by using a doctor’s note. During this time, Einstein wrote his first scientific work, "The Investigation of the State of Aether in Magnetic Fields".
Einstein applied directly to the Eidgenössische Polytechnische Schule (ETH) in Zürich, Switzerland. Lacking the requisite Matura certificate, he took an entrance examination, which he failed, although he got exceptional marks in mathematics and physics.
The Einsteins sent Albert to Aarau, in northern Switzerland to finish secondary school. While lodging with the family of Professor Jost Winteler, he fell in love with the family’s daughter, Marie. (His sister Maja later married the Winteler son, Paul.) In Aarau, Einstein studied Maxwell’s electromagnetic theory. At age 17, he graduated, and, with his father’s approval, renounced his citizenship in the German Kingdom of Württemberg to avoid military service, and enrolled in 1896 in the mathematics and physics program at the Polytechnic in Zurich. Marie Winteler moved to Olsberg, Switzerland for a teaching post.
In the same year, Einstein’s future wife, Mileva Marić, also entered the Polytechnic to study mathematics and physics, the only woman in the academic cohort. Over the next few years, Einstein and Marić’s friendship developed into romance. In a letter to her, Einstein called Marić “a creature who is my equal and who is as strong and independent as I am.” Einstein graduated in 1900 from the Polytechnic with a diploma in mathematics and physics; Although historians have debated whether Marić influenced Einstein’s work, the majority of academic historians of science agree that she did not.
Marriages and children.
In early 1902, Einstein and Mileva Marić had a daughter they named Lieserl in their correspondence, who was born in Novi Sad where Marić's parents lived. Her full name is not known, and her fate is uncertain after 1903.
Einstein and Marić married in January 1903. In May 1904, the couple’s first son, Hans Albert Einstein, was born in Bern, Switzerland. Their second son, Eduard, was born in Zurich in July 1910. In 1914, Einstein moved to Berlin, while his wife remained in Zurich with their sons. Marić and Einstein divorced on 14 February 1919, having lived apart for five years.
Einstein married Elsa Löwenthal (née Einstein) on 2 June 1919, after having had a relationship with her since 1912. She was his first cousin maternally and his second cousin paternally. In 1933, they emigrated permanently to the United States. In 1935, Elsa Einstein was diagnosed with heart and kidney problems and died in December 1936.
Patent office.
After graduating, Einstein spent almost two frustrating years searching for a teaching post, but a former classmate’s father helped him secure a job in Bern, at the Federal Office for Intellectual Property, the patent office, as an assistant examiner. He evaluated patent applications for electromagnetic devices. In 1903, Einstein’s position at the Swiss Patent Office became permanent, although he was passed over for promotion until he "fully mastered machine technology".
Much of his work at the patent office related to questions about transmission of electric signals and electrical-mechanical synchronization of time, two technical problems that show up conspicuously in the thought experiments that eventually led Einstein to his radical conclusions about the nature of light and the fundamental connection between space and time.
With friends he met in Bern, Einstein formed a weekly discussion club on science and philosophy, which he jokingly named "The Olympia Academy." Their readings included the works of Henri Poincaré, Ernst Mach, and David Hume, which influenced his scientific and philosophical outlook.
Academic career.
In 1901, Einstein had a paper on the capillary forces of a straw published in the prestigious "Annalen der Physik". In 1905, he received his doctorate from the University of Zurich. His thesis was titled "On a new determination of molecular dimensions". That same year, which has been called Einstein's "annus mirabilis" or "miracle year", he published four groundbreaking papers, on the photoelectric effect, Brownian motion, special relativity, and the equivalence of matter and energy, which were to bring him to the notice of the academic world.
By 1908, he was recognized as a leading scientist, and he was appointed lecturer at the University of Berne. The following year, he quit the patent office and the lectureship to take the position of physics professor at the University of Zurich. He became a full professor at Karl-Ferdinand University in Prague in 1911. In 1914, he returned to Germany after being appointed director of the Kaiser Wilhelm Institute for Physics and professor at the University of Berlin.
In 1911, he had calculated that, based on his new theory of general relativity, light from another star would be bent by the Sun's gravity. That prediction was claimed confirmed by observations made by a British expedition led by Sir Arthur Eddington during the solar eclipse of May 29, 1919. International media reports of this made Einstein world famous. (Much later, questions were raised whether the measurements were accurate enough to support such a claim.)
In 1921, Einstein was awarded the Nobel Prize in Physics. Because relativity was still considered somewhat controversial, it was officially bestowed for his explanation of the photoelectric effect. He also received the Copley Medal from the Royal Society in 1925.
Emigration to the United States.
In 1933, Einstein emigrated because of the rise to power of the Nazis and took up a position at the Institute for Advanced Study at Princeton, New Jersey, an affiliation that lasted until his death in 1955. There, he tried unsuccessfully to develop a unified field theory and to refute the accepted interpretation of quantum physics.
He and Kurt Gödel, another Institute member, became close friends. They would take long walks together discussing their work.
Just prior to the beginning of World War II in Europe, Einstein was persuaded to lend his enormous prestige to a letter sent to President Franklin D. Roosevelt on August 2, 1939, alerting him to the possibility that Nazi Germany might be developing an atomic bomb.
In 1940, he became an American citizen.
In 1952, he was offered the position of President of Israel, but declined.
Death.
On 17 April 1955, Albert Einstein experienced internal bleeding caused by the rupture of an abdominal aortic aneurysm, which had previously been reinforced surgically by Dr. Rudolph Nissen in 1948. He took the draft of a speech he was preparing for a television appearance commemorating the State of Israel’s seventh anniversary with him to the hospital, but he did not live long enough to complete it. Einstein refused surgery, saying: "I want to go when I want. It is tasteless to prolong life artificially. I have done my share, it is time to go. I will do it elegantly." He died in Princeton Hospital early the next morning at the age of 76, having continued to work until near the end. Einstein’s remains were cremated and his ashes were scattered around the grounds of the Institute for Advanced Study, Princeton, New Jersey.
During the autopsy, the pathologist of Princeton Hospital, Thomas Stoltz Harvey removed Einstein’s brain for preservation, without the permission of his family, in hope that the neuroscience of the future would be able to discover what made Einstein so intelligent.
Scientific career.
Throughout his life, Einstein published hundreds of books and articles. Most were about physics, but a few expressed leftist political opinions about pacifism, socialism, and zionism. In addition to the work he did by himself he also collaborated with other scientists on additional projects including the Bose–Einstein statistics, the Einstein refrigerator and others.
Physics in 1900.
Einstein’s early papers all come from attempts to demonstrate that atoms exist and have a finite nonzero size. At the time of his first paper in 1902, it was not yet completely accepted by physicists that atoms were real, even though chemists had good evidence ever since Antoine Lavoisier’s work a century earlier. The reason physicists were skeptical was because no 19th century theory could fully explain the properties of matter from the properties of atoms.
Ludwig Boltzmann was a leading 19th century atomist physicist, who had struggled for years to gain acceptance for atoms. Boltzmann had given an interpretation of the laws of thermodynamics, suggesting that the law of entropy increase is statistical. In Boltzmann’s way of thinking, the entropy is the logarithm of the number of ways a system could be configured inside. The reason the entropy goes up is only because it is more likely for a system to go from a special state with only a few possible internal configurations to a more generic state with many. While Boltzmann’s statistical interpretation of entropy is universally accepted today, and Einstein believed it, at the turn of the 20th century it was a minority position.
The statistical idea was most successful in explaining the properties of gases. James Clerk Maxwell, another leading atomist, had found the distribution of velocities of atoms in a gas, and derived the surprising result that the viscosity of a gas should be independent of density. Intuitively, the friction in a gas would seem to go to zero as the density goes to zero, but this is not so, because the mean free path of atoms becomes large at low densities. A subsequent experiment by Maxwell and his wife confirmed this surprising prediction. Other experiments on gases and vacuum, using a rotating slitted drum, showed that atoms in a gas had velocities distributed according to Maxwell’s distribution law.
In addition to these successes, there were also inconsistencies. Maxwell noted that at cold temperatures, atomic theory predicted specific heats that are too large. In classical statistical mechanics, every spring-like motion has thermal energy "k"B"T" on average at temperature "T", so that the specific heat of every spring is Boltzmann’s constant "k"B. A monatomic solid with "N" atoms can be thought of as "N" little balls representing "N" atoms attached to each other in a box grid with 3"N" springs, so the specific heat of every solid is 3"Nk"B, a result which became known as the Dulong–Petit law. This law is true at room temperature, but not for colder temperatures. At temperatures near zero, the specific heat goes to zero.
Similarly, a gas made up of a molecule with two atoms can be thought of as two balls on a spring. This spring has energy "k"B"T" at high temperatures, and should contribute an extra "k"B to the specific heat. It does at temperatures of about 1000 degrees, but at lower temperature, this contribution disappears. At zero temperature, all other contributions to the specific heat from rotations and vibrations also disappear. This behavior was inconsistent with classical physics.
The most glaring inconsistency was in the theory of light waves. Continuous waves in a box can be thought of as infinitely many spring-like motions, one for each possible standing wave. Each standing wave has a specific heat of "k"B, so the total specific heat of a continuous wave like light should be infinite in classical mechanics. This is obviously wrong, because it would mean that all energy in the universe would be instantly sucked up into light waves, and everything would slow down and stop.
These inconsistencies led some people to say that atoms were not physical, but mathematical. Notable among the skeptics was Ernst Mach, whose positivist philosophy led him to demand that if atoms are real, it should be possible to see them directly. Mach believed that atoms were a useful fiction, that in reality they could be assumed to be infinitesimally small, that Avogadro’s number was infinite, or so large that it might as well be infinite, and "k"B was infinitesimally small. Certain experiments could then be explained by atomic theory, but other experiments could not, and this is the way it will always be.
Einstein opposed this position. Throughout his career, he was a realist. He believed that a single consistent theory should explain all observations, and that this theory would be a description of what was really going on, underneath it all. So he set out to show that the atomic point of view was correct. This led him first to thermodynamics, then to statistical physics, and to the theory of specific heats of solids.
In 1905, while he was working in the patent office, the leading German language physics journal "Annalen der Physik" published four of Einstein’s papers. The four papers eventually were recognized as revolutionary, and 1905 became known as Einstein’s "Miracle Year", and the papers as the "Annus Mirabilis Papers".
Thermodynamic fluctuations and statistical physics.
Einstein’s earliest papers were concerned with thermodynamics. He wrote a paper establishing a thermodynamic identity in 1902, and a few other papers which attempted to interpret phenomena from a statistical atomic point of view.
His research in 1903 and 1904 was mainly concerned with the effect of finite atomic size on diffusion phenomena. As in Maxwell’s work, the finite nonzero size of atoms leads to effects which can be observed. This research, and the thermodynamic identity, were well within the mainstream of physics in his time. They would eventually form the content of his PhD thesis.
His first major result in this field was the theory of thermodynamic fluctuations. When in equilibrium, a system has a maximum entropy and, according to the statistical interpretation, it can fluctuate a little bit. Einstein pointed out that the statistical fluctuations of a macroscopic object, like a mirror suspended on spring, would be completely determined by the second derivative of the entropy with respect to the position of the mirror.
Searching for ways to test this relation, his great breakthrough came in 1905. The theory of fluctuations, he realized, would have a visible effect for an object which could move around freely. Such an object would have a velocity which is random, and would move around randomly, just like an individual atom. The average kinetic energy of the object would be formula_1, and the time decay of the fluctuations would be entirely determined by the law of friction.
The law of friction for a small ball in a viscous fluid like water was discovered by George Stokes. He showed that for small velocities, the friction force would be proportional to the velocity, and to the radius of the particle (see Stokes’ law). This relation could be used to calculate how far a small ball in water would travel due to its random thermal motion, and Einstein noted that such a ball, of size about a micron, would travel about a few microns per second. This motion could be easily detected with a microscope and indeed, as Brownian motion, had actually been observed by the botanist Robert Brown. Einstein was able to identify this motion with that predicted by his theory. Since the fluctuations which give rise to Brownian motion are just the same as the fluctuations of the velocities of atoms, measuring the precise amount of Brownian motion using Einstein’s theory would show that Boltzmann’s constant is non-zero and would measure Avogadro’s number.
These experiments were carried out a few years later, and gave a rough estimate of Avogadro’s number consistent with the more accurate estimates due to Max Planck’s theory of blackbody light, and Robert Millikan’s measurement of the charge of the electron. Unlike the other methods, Einstein’s required very few theoretical assumptions or new physics, since it was directly measuring atomic motion on visible grains.
Einstein’s theory of Brownian motion was the first paper in the field of statistical physics. It established that thermodynamic fluctuations were related to dissipation. This was shown by Einstein to be true for time-independent fluctuations, but in the Brownian motion paper he showed that dynamical relaxation rates calculated from classical mechanics could be used as statistical relaxation rates to derive dynamical diffusion laws. These relations are known as Einstein relations.
The theory of Brownian motion was the least revolutionary of Einstein’s Annus mirabilis papers, but it had an important role in securing the acceptance of the atomic theory by physicists.
Thought experiments and a-priori physical principles.
Einstein’s thinking underwent a transformation in 1905. He had come to understand that quantum properties of light mean that Maxwell’s equations were only an approximation. He knew that new laws would have to replace these, but he did not know how to go about finding those laws. He felt that guessing formal relations would not go anywhere.
So he decided to focus on a-priori principles instead, which are statements about physical laws which can be understood to hold in a very broad sense even in domains where they have not yet been shown to apply. A well accepted example of an a-priori principle is rotational invariance. If a new force is discovered in physics, it is assumed to be rotationally invariant almost automatically, without thought. Einstein sought new principles of this sort, to guide the production of physical ideas. Once enough principles are found, then the new physics will be the simplest theory consistent with the principles and with previously known laws.
The first general a-priori principle he found was the principle of relativity, that uniform motion is indistinguishable from rest. This was understood by Hermann Minkowski to be a generalization of rotational invariance from space to space-time. Other principles postulated by Einstein and later vindicated are the principle of equivalence and the principle of adiabatic invariance of the quantum number. Another of Einstein’s general principles, Mach’s principle, is fiercely debated, and whether it holds in our world or not is still not definitively established.
The use of a-priori principles is a distinctive unique signature of Einstein’s early work, and has become a standard tool in modern theoretical physics.
Special relativity.
His 1905 paper on the electrodynamics of moving bodies introduced his theory of special relativity, which showed that the observed independence of the speed of light on the observer’s state of motion required fundamental changes to the notion of simultaneity. Consequences of this include the time-space frame of a moving body slowing down and contracting (in the direction of motion) relative to the frame of the observer. This paper also argued that the idea of a luminiferous aether – one of the leading theoretical entities in physics at the time – was superfluous.
In his paper on "mass–energy equivalence", which had previously been considered to be distinct concepts, Einstein deduced from his equations of special relativity what has been called the twentieth century’s best-known equation: "E" = "mc"2. This equation suggests that tiny amounts of mass could be converted into huge amounts of energy and presaged the development of nuclear power.
Einstein’s 1905 work on relativity remained controversial for many years, but was accepted by leading physicists, starting with Max Planck.
Photons.
In a 1905 paper, Einstein postulated that light itself consists of localized particles ("quanta"). Einstein’s light quanta were nearly universally rejected by all physicists, including Max Planck and Niels Bohr. This idea only became universally accepted in 1919, with Robert Millikan’s detailed experiments on the photoelectric effect, and with the measurement of Compton scattering.
Einstein’s paper on the light particles was almost entirely motivated by thermodynamic considerations. He was not at all motivated by the detailed experiments on the photoelectric effect, which did not confirm his theory until fifteen years later.
Einstein considers the entropy of light at temperature "T", and decomposes it into a low-frequency part and a high-frequency part. The high-frequency part, where the light is described by Wien’s law, has an entropy which looks exactly the same as the entropy of a gas of classical particles.
Since the entropy is the logarithm of the number of possible states, Einstein concludes that the number of states of short wavelength light waves in a box with volume "V" is equal to the number of states of a group of localizable particles in the same box. Since (unlike others) he was comfortable with the statistical interpretation, he confidently postulates that the light itself is made up of localized particles, as this is the only reasonable interpretation of the entropy.
This leads him to conclude that each wave of frequency "f" is associated with a collection of photons with energy "hf" each, where "h" is Planck’s constant. He does not say much more, because he is not sure how the particles are related to the wave. But he does suggest that this idea would explain certain experimental results, notably the photoelectric effect.
Quantized atomic vibrations.
Einstein continued his work on quantum mechanics in 1906, by explaining the specific heat anomaly in solids. This was the first application of quantum theory to a mechanical system.
Since Planck’s distribution for light oscillators had no problem with infinite specific heats, the same idea could be applied to solids to fix the specific heat problem there. Einstein showed in a simple model that the hypothesis that solid motion is quantized explains why the specific heat of a solid goes to zero at zero temperature.
Einstein’s model treats each atom as connected to a single spring. Instead of connecting all the atoms to each other, which leads to standing waves with all sorts of different frequencies, Einstein imagined that each atom was attached to a fixed point in space by a spring. This is not physically correct, but it still predicts that the specific heat is 3"Nk"B, since the number of independent oscillations stays the same.
Einstein then assumes that the motion in this model is quantized, according to the Planck law, so that each independent spring motion has energy which is an integer multiple of hf, where f is the frequency of oscillation. With this assumption, he applied Boltzmann’s statistical method to calculate the average energy of the spring. The result was the same as the one that Planck had derived for light: for temperatures where "k"B"T" is much smaller than "hf", the motion is frozen, and the specific heat goes to zero.
So Einstein concluded that quantum mechanics would solve the main problem of classical physics, the specific heat anomaly. The particles of sound implied by this formulation are now called phonons. Because all of Einstein’s springs have the same stiffness, they all freeze out at the same temperature, and this leads to a prediction that the specific heat should go to zero exponentially fast when the temperature is low. The solution to this problem is to solve for the independent normal modes individually, and to quantize those. Then each normal mode has a different frequency, and long wavelength vibration modes freeze out at colder temperatures than short wavelength ones. This was done by Debye, and after this modification Einstein’s quantization method reproduced quantitatively the behavior of the specific heats of solids at low temperatures.
This work was the foundation of condensed matter physics.
Adiabatic principle and action-angle variables.
Throughout the 1910s, quantum mechanics expanded in scope to cover many different systems. After Ernest Rutherford discovered the nucleus and proposed that electrons orbit like planets, Niels Bohr was able to show that the same quantum mechanical postulates introduced by Planck and developed by Einstein would explain the discrete motion of electrons in atoms, and the periodic table of the elements.
Einstein contributed to these developments by linking them with the 1898 arguments Wilhelm Wien had made. Wien had shown that the hypothesis of adiabatic invariance of a thermal equilibrium state allows all the blackbody curves at different temperature to be derived from one another by a simple shifting process. Einstein noted in 1911 that the same adiabatic principle shows that the quantity which is quantized in any mechanical motion must be an adiabatic invariant. Arnold Sommerfeld identified this adiabatic invariant as the action variable of classical mechanics. The law that the action variable is quantized was the basic principle of the quantum theory as it was known between 1900 and 1925.
Wave-particle duality.
Although the patent office promoted Einstein to Technical Examiner Second Class in 1906, he had not given up on "academia." In 1908, he became a "privatdozent" at the University of Bern.
In "über die Entwicklung unserer Anschauungen über das Wesen und die Konstitution der Strahlung" ("The Development of Our Views on the Composition and Essence of Radiation"), on the quantization of light, and in an earlier 1909 paper, Einstein showed that Max Planck’s energy quanta must have well-defined momenta and act in some respects as independent, point-like particles. This paper introduced the "photon" concept (although the name "photon" was introduced later by Gilbert N. Lewis in 1926) and inspired the notion of wave-particle duality in quantum mechanics.
Theory of Critical Opalescence.
Einstein returned to the problem of thermodynamic fluctuations, giving a treatment of the density variations in a fluid at its critical point. Ordinarily the density fluctuations are controlled by the second derivative of the free energy with respect to the density. At the critical point, this derivative is zero, leading to large fluctuations. The effect of density fluctuations is that light of all wavelengths is scattered, making the fluid look milky white. Einstein relates this to Raleigh scattering, which is what happens when the fluctuation size is much smaller than the wavelength, and which explains why the sky is blue.
Zero-point energy.
Einstein’s physical intuition led him to note that Planck’s oscillator energies had an incorrect zero point. He modified Planck’s hypothesis by stating that the lowest energy state of an oscillator is equal to "hf", to half the energy spacing between levels. This argument, which was made in 1913 in collaboration with Otto Stern, was based on the thermodynamics of a diatomic molecule which can split apart into two free atoms.
Principle of equivalence.
In 1907, while still working at the patent office, Einstein had what he would call his "happiest thought". He realized that the principle of relativity could be extended to gravitational fields.
He thought about the case of a uniformly accelerated box not in a gravitational field, and noted that it would be indistinguishable from a box sitting still in an unchanging gravitational field. He used special relativity to see that the rate of clocks at the top of a box accelerating upward would be faster than the rate of clocks at the bottom. He concludes that the rates of clocks depend on their position in a gravitational field, and that the difference in rate is proportional to the gravitational potential to first approximation.
Although this approximation is crude, it allowed him to calculate the deflection of light by gravity, and show that it is nonzero. This gave him confidence that the scalar theory of gravity proposed by Gunnar Nordström was incorrect. But the actual value for the deflection that he calculated was too small by a factor of two, because the approximation he used doesn’t work well for things moving at near the speed of light. When Einstein finished the full theory of general relativity, he would rectify this error and predict the correct amount of light deflection by the sun.
From Prague, Einstein published a paper about the effects of gravity on light, specifically the gravitational redshift and the gravitational deflection of light. The paper challenged astronomers to detect the deflection during a solar eclipse. German astronomer Erwin Finlay-Freundlich publicized Einstein’s challenge to scientists around the world.
Einstein thought about the nature of the gravitational field in the years 1909–1912, studying its properties by means of simple thought experiments. A notable one is the rotating disk. Einstein imagined an observer making experiments on a rotating turntable. He noted that such an observer would find a different value for the mathematical constant pi than the one predicted by Euclidean geometry. The reason is that the radius of a circle would be measured with an uncontracted ruler, but, according to special relativity, the circumference would seem to be longer because the ruler would be contracted.
Since Einstein believed that the laws of physics were local, described by local fields, he concluded from this that spacetime could be locally curved. This led him to study Riemannian geometry, and to formulate general relativity in this language.
Hole argument and Entwurf theory.
While developing general relativity, Einstein became confused about the gauge invariance in the theory. He formulated an argument that led him to conclude that a general relativistic field theory is impossible. He gave up looking for fully generally covariant tensor equations, and searched for equations that would be invariant under general linear transformations only.
The Entwurf ("draft") theory was the result of these investigations. As its name suggests, it was a sketch of a theory, with the equations of motion supplemented by additional gauge fixing conditions. Simultaneously less elegant and more difficult than general relativity, Einstein abandoned the theory after realizing that the hole argument was mistaken.
General relativity.
In 1912, Einstein returned to Switzerland to accept a professorship at his "alma mater," the ETH. Once back in Zurich, he immediately visited his old ETH classmate Marcel Grossmann, now a professor of mathematics, who introduced him to Riemannian geometry and, more generally, to differential geometry. On the recommendation of Italian mathematician Tullio Levi-Civita, Einstein began exploring the usefulness of general covariance (essentially the use of tensors) for his gravitational theory. For a while Einstein thought that there were problems with the approach, but he later returned to it and, by late 1915, had published his general theory of relativity in the form in which it is used today. This theory explains gravitation as distortion of the structure of spacetime by matter, affecting the inertial motion of other matter.
During World War I, the work of Central Powers scientists was available only to Central Powers academics, for national security reasons. Some of Einstein’s work did reach the United Kingdom and the United States through the efforts of the Austrian Paul Ehrenfest and physicists in the Netherlands, especially 1902 Nobel Prize-winner Hendrik Lorentz and Willem de Sitter of Leiden University. After the war ended, Einstein maintained his relationship with Leiden University, accepting a contract as an "Extraordinary Professor"; for ten years, from 1920 to 1930, he travelled to Holland regularly to lecture.
In 1917, several astronomers accepted Einstein ’s 1911 challenge from Prague. The Mount Wilson Observatory in California, U.S., published a solar spectroscopic analysis that showed no gravitational redshift. In 1918, the Lick Observatory, also in California, announced that it too had disproved Einstein’s prediction, although its findings were not published.
However, in May 1919, a team led by the British astronomer Arthur Stanley Eddington claimed to have confirmed Einstein’s prediction of gravitational deflection of starlight by the Sun while photographing a solar eclipse with dual expeditions in Sobral, northern Brazil, and Príncipe, a west African island. Nobel laureate Max Born praised general relativity as the "greatest feat of human thinking about nature"; fellow laureate Paul Dirac was quoted saying it was "probably the greatest scientific discovery ever made".
The international media guaranteed Einstein’s global renown.
There have been claims that scrutiny of the specific photographs taken on the Eddington expedition showed the experimental uncertainty to be comparable to the same magnitude as the effect Eddington claimed to have demonstrated, and that a 1962 British expedition concluded that the method was inherently unreliable. The deflection of light during a solar eclipse was confirmed by later, more accurate observations. Some resented the newcomer’s fame, notably among some German physicists, who later started the "Deutsche Physik" (German Physics) movement.
Cosmology.
In 1917, Einstein applied the General theory of relativity to model the structure of the universe as a whole. He wanted the universe to be eternal and unchanging, but this type of universe is not consistent with relativity. To fix this, Einstein modified the general theory by introducing a new notion, the cosmological constant. With a positive cosmological constant, the universe could be an eternal static sphere
Einstein believed a spherical static universe is philosophically preferred, because it would obey Mach’s principle. He had shown that general relativity incorporates Mach’s principle to a certain extent in frame dragging by gravitomagnetic fields, but he knew that Mach’s idea would not work if space goes on forever. In a closed universe, he believed that Mach’s principle would hold.
Mach’s principle has generated much controversy over the years.
Modern quantum theory.
In 1917, at the height of his work on relativity, Einstein published an article in "Physikalische Zeitschrift" that proposed the possibility of stimulated emission, the physical process that makes possible the maser and the laser.
This article showed that the statistics of absorption and emission of light would only be consistent with Planck’s distribution law if the emission of light into a mode with n photons would be enhanced statistically compared to the emission of light into an empty mode. This paper was enormously influential in the later development of quantum mechanics, because it was the first paper to show that the statistics of atomic transitions had simple laws.
Einstein discovered Louis de Broglie’s work, and supported his ideas, which were received skeptically at first. In another major paper from this era, Einstein gave a wave equation for de Broglie waves, which Einstein suggested was the Hamilton–Jacobi equation of mechanics. This paper would inspire Schrödinger’s work of 1926.
Bose–Einstein statistics.
In 1924, Einstein received a description of a statistical model from Indian physicist Satyendra Nath Bose, based on a counting method that assumed that light could be understood as a gas of indistinguishable particles. Einstein noted that Bose’s statistics applied to some atoms as well as to the proposed light particles, and submitted his translation of Bose’s paper to the "Zeitschrift für Physik". Einstein also published his own articles describing the model and its implications, among them the Bose–Einstein condensate phenomenon that some particulates should appear at very low temperatures. It was not until 1995 that the first such condensate was produced experimentally by Eric Allin Cornell and Carl Wieman using ultra-cooling equipment built at the NIST–JILA laboratory at the University of Colorado at Boulder. Bose–Einstein statistics are now used to describe the behaviors of any assembly of bosons. Einstein’s sketches for this project may be seen in the Einstein Archive in the library of the Leiden University.
Energy momentum pseudotensor.
General relativity includes a dynamical spacetime, so it is difficult to see how to identify the conserved energy and momentum. Noether’s theorem allows these quantities to be determined from a Lagrangian with translation invariance, but general covariance makes translation invariance into something of a gauge symmetry. The energy and momentum derived within general relativity by Noether’s presecriptions do not make a real tensor for this reason.
Einstein argued that this is true for fundamental reasons, because the gravitational field could be made to vanish by a choice of coordinates. He maintained that the non-covariant energy momentum pseudotensor was in fact the best description of the energy momentum distribution in a gravitational field. This approach has been echoed by Lev Landau and Evgeny Lifshitz, and others, and has become standard.
The use of non-covariant objects like pseudotensors was heavily criticized in 1917 by Erwin Schrödinger and others.
Unified field theory.
Following his research on general relativity, Einstein entered into a series of attempts to generalize his geometric theory of gravitation, which would allow the explanation of electromagnetism. In 1950, he described his "unified field theory" in a "Scientific American" article entitled "On the Generalized Theory of Gravitation." Although he continued to be lauded for his work, Einstein became increasingly isolated in his research, and his efforts were ultimately unsuccessful.
In his pursuit of a unification of the fundamental forces, Einstein ignored some mainstream developments in physics, most notably the strong and weak nuclear forces, which were not well understood until many years after his death. Mainstream physics, in turn, largely ignored Einstein’s approaches to unification. Einstein’s dream of unifying other laws of physics with gravity motivates modern quests for a theory of everything and in particular string theory, where geometrical fields emerge in a unified quantum-mechanical setting.
Wormholes.
Einstein collaborated with others to produce a model of a wormhole. His motivation was to model elementary particles with charge as a solution of gravitational field equations, in line with the program outlined in the paper "Do Gravitational Fields play an Important Role in the Constitution of the Elementary Particles?". These solutions cut and pasted Schwarzschild black holes to make a bridge between two patches.
If one end of a wormhole was positively charged, the other end would be negatively charged. These properties led Einstein to believe that pairs of particles and antiparticles could be described in this way.
Einstein–Cartan theory.
In order to incorporate spinning point particles into general relativity, the affine connection needed to be generalized to include an antisymmetric part, called the torsion. This modification was made by Einstein and Cartan in the 1920s.
Einstein–Podolsky–Rosen paradox.
In 1935, Einstein returned to the question of quantum mechanics. He considered how a measurement on one of two entangled particles would affect the other. He noted, along with his collaborators, that by performing different measurements on the distant particle, either of position or momentum, different properties of the entangled partner could be discovered without disturbing it in any way.
He then used a hypothesis of local realism to conclude that the other particle had these properties already determined. The principle he proposed is that if it is possible to determine what the answer to a position or momentum measurement would be, without in any way disturbing the particle, then the particle actually has values of position or momentum.
This principle distilled the essence of Einstein’s objection to quantum mechanics. As a physical principle, it has since been shown to be incompatible with experiments.
Equations of motion.
The theory of general relativity has two fundamental laws – the Einstein equations which describe how space curves, and the geodesic equation which describes how particles move.
Since the equations of general relativity are non-linear, a lump of energy made out of pure gravitational fields, like a black hole, would move on a trajectory which is determined by the Einstein equations themselves, not by a new law. So Einstein proposed that the path of a singular solution, like a black hole, would be determined to be a geodesic from general relativity itself.
This was established by Einstein, Infeld and Hoffmann for pointlike objects without angular momentum, and by Roy Kerr for spinning objects.
Einstein’s mistakes.
Einstein himself considered the use of the "fudge factor" lambda in his 1917 paper founding cosmology as a "blunder". The theory of general relativity predicted an expanding or contracting universe, but Einstein wanted a universe which is an unchanging three dimensional sphere, like the surface of a three dimensional ball in four dimensions. He wanted this for philosophical reasons, so as to incorporate Mach’s principle in a reasonable way. He stabilized his solution by introducing a cosmological constant, and when the universe was shown to be expanding, he retracted the constant as a blunder. This is not really much of a blunder – the cosmological constant is necessary within general relativity as it is currently understood, and it is widely believed to have a nonzero value today.
Einstein took the wrong side in a few scientific debates.
In addition to these well known mistakes, it is sometimes claimed that the general line of Einstein’s reasoning in the 1905 relativity paper is flawed, or the photon paper, or one or another of the most famous papers. None of these claims are widely accepted.
Collaboration with other scientists.
In addition to long time collaborators Leopold Infeld, Nathan Rosen, Peter Bergmann and others, Einstein also had some one-shot collaborations with various scientists.
Einstein-de Haas experiment.
Einstein and De Haas demonstrated that magnetization is due to the motion of electrons, nowadays known to be the spin. In order to show this, they reversed the magnetization in an iron bar suspended on a torsion pendulum. They confirmed that this leads the bar to rotate, because the electron’s angular momentum changes as the magnetization changes. This experiment needed to be sensitive, because the angular momentum associated with electrons is small, but it definitively established that electron motion of some kind is responsible for magnetization.
Schrödinger gas model.
Einstein suggested to Erwin Schrödinger that he might be able to reproduce the statistics of a Bose–Einstein gas by considering a box. Then to each possible quantum motion of a particle in a box associate an independent harmonic oscillator. Quantizing these oscillators, each level will have an integer occupation number, which will be the number of particles in it.
This formulation is a form of second quantization, but it predates modern quantum mechanics. Erwin Schrödinger applied this to derive the thermodynamic properties of a semiclassical ideal gas. Schrödinger urged Einstein to add his name as co-author, although Einstein declined the invitation.
Einstein refrigerator.
In 1926, Einstein and his former student Leó Szilárd co-invented (and in 1930, patented) the Einstein refrigerator. This Absorption refrigerator was then revolutionary for having no moving parts and using only heat as an input. On 11 November 1930, was awarded to Albert Einstein and Leó Szilárd for the refrigerator. Their invention was not immediately put into commercial production, as the most promising of their patents were quickly bought up by the Swedish company Electrolux to protect its refrigeration technology from competition.
Bohr versus Einstein.
In the 1920s, quantum mechanics developed into a more complete theory. Einstein was unhappy with the Copenhagen interpretation of quantum theory developed by Niels Bohr and Werner Heisenberg. In this interpretation, quantum phenomena are inherently probabilistic, with definite states resulting only upon interaction with classical systems. A public debate between Einstein and Bohr followed, lasting on and off for many years (including during the Solvay Conferences). Einstein formulated thought experiments against the Copenhagen interpretation, which were all rebutted by Bohr. In a 1926 letter to Max Born, Einstein wrote: "I, at any rate, am convinced that He [God] does not throw dice."
Einstein was never satisfied by what he perceived to be quantum theory’s intrinsically incomplete description of nature, and in 1935 he further explored the issue in collaboration with Boris Podolsky and Nathan Rosen, noting that the theory seems to require non-local interactions; this is known as the EPR paradox. The EPR experiment has since been performed, with results confirming quantum theory’s predictions. Repercussions of the Einstein–Bohr debate have found their way into philosophical discourse.
Religious views.
The question of scientific determinism gave rise to questions about Einstein’s position on theological determinism, and whether or not he believed in God, or in a god. In 1929, Einstein told Rabbi Herbert S. Goldstein "I believe in Spinoza’s God, who reveals Himself in the lawful harmony of the world, not in a God Who concerns Himself with the fate and the doings of mankind." In a 1954 letter, he wrote, "I do not believe in a personal God and I have never denied this but have expressed it clearly.” In a letter to philosopher Erik Gutkind, Einstein remarked, "The word God is for me nothing more than the expression and product of human weakness, the Bible a collection of honorable, but still purely primitive, legends which are nevertheless pretty childish."
Political views.
Throughout the November Revolution in Germany Einstein signed an appeal for the foundation of a nationwide liberal and democratic party, which was published in the Berliner Tageblatt on 16 November 1918, and became a member of the German Democratic Party.
Einstein flouted the ascendant Nazi movement, tried to be a voice of moderation in the tumultuous formation of the State of Israel and braved anti-communist politics and resistance to the civil rights movement in the United States. He participated in the 1927 congress of the League against Imperialism in Brussels. He was a socialist Zionist who supported the creation of a Jewish national homeland in the British mandate of Palestine.
After World War II, as enmity between the former allies became a serious issue, Einstein wrote, “I do not know how the third World War will be fought, but I can tell you what they will use in the Fourth – rocks!” In a 1949 "Monthly Review" article entitled “Why Socialism?” Albert Einstein described a chaotic capitalist society, a source of evil to be overcome, as the “predatory phase of human development”. With Albert Schweitzer and Bertrand Russell, Einstein lobbied to stop nuclear testing and future bombs. Days before his death, Einstein signed the Russell–Einstein Manifesto, which led to the Pugwash Conferences on Science and World Affairs.
Einstein was a member of several civil rights groups, including the Princeton chapter of the NAACP. When the aged W. E. B. Du Bois was accused of being a Communist spy, Einstein volunteered as a character witness, and the case was dismissed shortly afterward. Einstein’s friendship with activist Paul Robeson, with whom he served as co-chair of the American Crusade to End Lynching, lasted twenty years.
Non-scientific legacy.
While travelling, Einstein wrote daily to his wife Elsa and adopted stepdaughters Margot and Ilse. The letters were included in the papers bequeathed to The Hebrew University. Margot Einstein permitted the personal letters to be made available to the public, but requested that it not be done until twenty years after her death (she died in 1986). Barbara Wolff, of The Hebrew University’s Albert Einstein Archives, told the BBC that there are about 3,500 pages of private correspondence written between 1912 and 1955.
Einstein bequeathed the royalties from use of his image to The Hebrew University of Jerusalem. Corbis, successor to The Roger Richman Agency, licenses the use of his name and associated imagery, as agent for the university.
In popular culture.
In the period before World War II, Albert Einstein was so well-known in America that he would be stopped on the street by people wanting him to explain "that theory." He finally figured out a way to handle the incessant inquiries. He told his inquirers "Pardon me, sorry! Always I am mistaken for Professor Einstein."
Albert Einstein has been the subject of or inspiration for many novels, films, and plays. Einstein is a favorite model for depictions of mad scientists and absent-minded professors; his expressive face and distinctive hairstyle have been widely copied and exaggerated. "Time" magazine’s Frederic Golden wrote that Einstein was "a cartoonist’s dream come true."
Einstein’s association with great intelligence and originality has made the name "Einstein" synonymous with genius.
Awards.
In 1922, Einstein was awarded the 1921 Nobel Prize in Physics, "for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect". This refers to his 1905 paper on the photoelectric effect, "On a Heuristic Viewpoint Concerning the Production and Transformation of Light", which was well supported by the experimental evidence by that time. The presentation speech began by mentioning "his theory of relativity [which had] been the subject of lively debate in philosophical circles [and] also has astrophysical implications which are being rigorously examined at the present time."
It was long reported that Einstein gave the Nobel prize money directly to his first wife, Mileva Marić, in compliance with their 1919 divorce settlement. However, personal correspondence made public in 2006 shows that he invested much of it in the United States, and saw much of it wiped out in the Great Depression.
Einstein traveled to New York City in the United States for the first time on 2 April 1921. When asked where he got his scientific ideas, Einstein explained that he believed scientific work best proceeds from an examination of physical reality and a search for underlying axioms, with consistent explanations that apply in all instances and avoid contradicting each other. He also recommended theories with visualizable results.
In 1999, Albert Einstein was named Person of the Century by "Time" magazine.
---END.OF.DOCUMENT---
Afghanistan.
The Islamic Republic of Afghanistan is a landlocked country in South-Central Asia. It is variously described as being located within Central Asia, South Asia, Western Asia, or the Middle East. It is bordered by Iran in the west, Pakistan in the south and east, Turkmenistan, Uzbekistan and Tajikistan in the north, and China in the far northeast.
Afghanistan has a long history, and has been an ancient focal point of the Silk Road and migration. It is an important geostrategic location, connecting East and West Asia or the Middle East. The land has been a target of various invaders, as well as a source from which local powers invaded neighboring regions to form their own empires. Ahmad Shah Durrani created the Durrani Empire in 1747, which is considered the beginning of modern Afghanistan. Its capital was shifted in 1776 from Kandahar to Kabul and most of its territories ceded to neighboring empires. In the late 19th century, Afghanistan became a buffer state in "The Great Game" played between the British Empire and Russian Empire. On August 19, 1919, following the third Anglo-Afghan war, the country regained independence from the United Kingdom over its foreign affairs.
